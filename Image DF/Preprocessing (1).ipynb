{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# importing Libraries"
      ],
      "metadata": {
        "id": "8DeYwuL2UHmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255., # rescaling\n",
        "                                   rotation_range = 40,  # for augmentation\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   validation_split = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1.0/255.,validation_split = 0.2)\n",
        "\n",
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1.0/255.)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\"/content/drive/MyDrive/Image/real_vs_fake/real-vs-fake/train/\",\n",
        "                                                    batch_size = 32,\n",
        "                                                    subset=\"training\",\n",
        "                                                    class_mode = 'binary',\n",
        "                                                    target_size = (224, 224))\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\"/content/drive/MyDrive/Image/real_vs_fake/real-vs-fake/test/\",\n",
        "                                                    batch_size = 32,\n",
        "                                                    class_mode = 'binary',\n",
        "                                                    target_size = (224, 224))\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\"/content/drive/MyDrive/Image/real_vs_fake/real-vs-fake/valid/\",\n",
        "                                                subset = \"validation\",\n",
        "                                                    batch_size = 32,\n",
        "                                                    class_mode = 'binary',\n",
        "                                                    target_size = (224, 224))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_IeOvlOcIkar",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5c104d5-60ad-4ee4-805b-2aa79aa64582"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 35180 images belonging to 2 classes.\n",
            "Found 20000 images belonging to 2 classes.\n",
            "Found 0 images belonging to 0 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "6Jx7ATKdmiIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sequential Model"
      ],
      "metadata": {
        "id": "EAGRtbwYdez6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Binary classification output\n",
        "])"
      ],
      "metadata": {
        "id": "IjElT1fAoyeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/drive/MyDrive/Image/my_model.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HROR1N_veP1F",
        "outputId": "a2ecd9ae-a5d0-4ad3-88d1-270d7c94efdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "w-bodtSKo4r7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "ysaIqq_4UXS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=test_generator,  # Ideally, use a separate validation set\n",
        "    epochs=10,\n",
        "    verbose=2,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.LambdaCallback(\n",
        "            on_epoch_begin=lambda epoch, logs: print(f\"Epoch {epoch + 1}/{10} started:\")\n",
        "        ),\n",
        "        tf.keras.callbacks.LambdaCallback(\n",
        "            on_epoch_end=lambda epoch, logs: print(f\"Epoch {epoch + 1}/{10} completed.\")\n",
        "        ),\n",
        "        tf.keras.callbacks.LambdaCallback(\n",
        "            on_train_batch_begin=lambda batch, logs: print(f\"Training batch {batch} started.\")\n",
        "        ),\n",
        "        tf.keras.callbacks.LambdaCallback(\n",
        "            on_train_batch_end=lambda batch, logs: print(\n",
        "                f\"Training batch {batch} completed. Loss: {logs['loss']:.4f}, Accuracy: {logs['accuracy']:.4f}\"\n",
        "            )\n",
        "        ),\n",
        "        tf.keras.callbacks.LambdaCallback(\n",
        "            on_test_batch_begin=lambda batch, logs: print(f\"Validation batch {batch} started.\")\n",
        "        ),\n",
        "        tf.keras.callbacks.LambdaCallback(\n",
        "            on_test_batch_end=lambda batch, logs: print(\n",
        "                f\"Validation batch {batch} completed. Loss: {logs['loss']:.4f}, Accuracy: {logs['accuracy']:.4f}\"\n",
        "            )\n",
        "        ),\n",
        "        tf.keras.callbacks.LambdaCallback(\n",
        "            on_train_begin=lambda logs: print(\"Training started.\")\n",
        "        ),\n",
        "        tf.keras.callbacks.LambdaCallback(\n",
        "            on_train_end=lambda logs: print(\"Training completed.\")\n",
        "        ),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Shl6bykPpHdO",
        "outputId": "e58504fc-ad7d-45ef-e746-191987626d6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training started.\n",
            "Epoch 1/10 started:\n",
            "Epoch 1/10\n",
            "Training batch 0 started.\n",
            "Training batch 0 completed. Loss: 0.6879, Accuracy: 0.5312\n",
            "Training batch 1 started.\n",
            "Training batch 2 completed. Loss: 3.6996, Accuracy: 0.5833\n",
            "Training batch 3 started.\n",
            "Training batch 3 completed. Loss: 4.5526, Accuracy: 0.5547\n",
            "Training batch 4 started.\n",
            "Training batch 4 completed. Loss: 4.1101, Accuracy: 0.5562\n",
            "Training batch 5 started.\n",
            "Training batch 5 completed. Loss: 3.5493, Accuracy: 0.5365\n",
            "Training batch 6 started.\n",
            "Training batch 6 completed. Loss: 3.1813, Accuracy: 0.5446\n",
            "Training batch 7 started.\n",
            "Training batch 7 completed. Loss: 2.9652, Accuracy: 0.5352\n",
            "Training batch 8 started.\n",
            "Training batch 8 completed. Loss: 2.7610, Accuracy: 0.5278\n",
            "Training batch 9 started.\n",
            "Training batch 9 completed. Loss: 2.5578, Accuracy: 0.5312\n",
            "Training batch 10 started.\n",
            "Training batch 10 completed. Loss: 2.3886, Accuracy: 0.5284\n",
            "Training batch 11 started.\n",
            "Training batch 11 completed. Loss: 2.2485, Accuracy: 0.5130\n",
            "Training batch 12 started.\n",
            "Training batch 12 completed. Loss: 2.1288, Accuracy: 0.5240\n",
            "Training batch 13 started.\n",
            "Training batch 13 completed. Loss: 2.0260, Accuracy: 0.5223\n",
            "Training batch 14 started.\n",
            "Training batch 14 completed. Loss: 1.9370, Accuracy: 0.5229\n",
            "Training batch 15 started.\n",
            "Training batch 15 completed. Loss: 1.8593, Accuracy: 0.5137\n",
            "Training batch 16 started.\n",
            "Training batch 16 completed. Loss: 1.7907, Accuracy: 0.5165\n",
            "Training batch 17 started.\n",
            "Training batch 17 completed. Loss: 1.7297, Accuracy: 0.5191\n",
            "Training batch 18 started.\n",
            "Training batch 18 completed. Loss: 1.6752, Accuracy: 0.5132\n",
            "Training batch 19 started.\n",
            "Training batch 19 completed. Loss: 1.6260, Accuracy: 0.5219\n",
            "Training batch 20 started.\n",
            "Training batch 20 completed. Loss: 1.5815, Accuracy: 0.5208\n",
            "Training batch 21 started.\n",
            "Training batch 21 completed. Loss: 1.5411, Accuracy: 0.5227\n",
            "Training batch 22 started.\n",
            "Training batch 22 completed. Loss: 1.5043, Accuracy: 0.5245\n",
            "Training batch 23 started.\n",
            "Training batch 23 completed. Loss: 1.4704, Accuracy: 0.5286\n",
            "Training batch 24 started.\n",
            "Training batch 24 completed. Loss: 1.4394, Accuracy: 0.5300\n",
            "Training batch 25 started.\n",
            "Training batch 25 completed. Loss: 1.4107, Accuracy: 0.5300\n",
            "Training batch 26 started.\n",
            "Training batch 26 completed. Loss: 1.3842, Accuracy: 0.5266\n",
            "Training batch 27 started.\n",
            "Training batch 27 completed. Loss: 1.3594, Accuracy: 0.5324\n",
            "Training batch 28 started.\n",
            "Training batch 28 completed. Loss: 1.3364, Accuracy: 0.5302\n",
            "Training batch 29 started.\n",
            "Training batch 29 completed. Loss: 1.3149, Accuracy: 0.5292\n",
            "Training batch 30 started.\n",
            "Training batch 30 completed. Loss: 1.2948, Accuracy: 0.5302\n",
            "Training batch 31 started.\n",
            "Training batch 31 completed. Loss: 1.2760, Accuracy: 0.5303\n",
            "Training batch 32 started.\n",
            "Training batch 32 completed. Loss: 1.2583, Accuracy: 0.5350\n",
            "Training batch 33 started.\n",
            "Training batch 33 completed. Loss: 1.2417, Accuracy: 0.5331\n",
            "Training batch 34 started.\n",
            "Training batch 34 completed. Loss: 1.2260, Accuracy: 0.5330\n",
            "Training batch 35 started.\n",
            "Training batch 35 completed. Loss: 1.2112, Accuracy: 0.5347\n",
            "Training batch 36 started.\n",
            "Training batch 36 completed. Loss: 1.1972, Accuracy: 0.5329\n",
            "Training batch 37 started.\n",
            "Training batch 37 completed. Loss: 1.1841, Accuracy: 0.5304\n",
            "Training batch 38 started.\n",
            "Training batch 38 completed. Loss: 1.1715, Accuracy: 0.5288\n",
            "Training batch 39 started.\n",
            "Training batch 39 completed. Loss: 1.1595, Accuracy: 0.5297\n",
            "Training batch 40 started.\n",
            "Training batch 40 completed. Loss: 1.1481, Accuracy: 0.5290\n",
            "Training batch 41 started.\n",
            "Training batch 41 completed. Loss: 1.1373, Accuracy: 0.5283\n",
            "Training batch 42 started.\n",
            "Training batch 42 completed. Loss: 1.1269, Accuracy: 0.5291\n",
            "Training batch 43 started.\n",
            "Training batch 43 completed. Loss: 1.1170, Accuracy: 0.5305\n",
            "Training batch 44 started.\n",
            "Training batch 44 completed. Loss: 1.1076, Accuracy: 0.5312\n",
            "Training batch 45 started.\n",
            "Training batch 45 completed. Loss: 1.0986, Accuracy: 0.5319\n",
            "Training batch 46 started.\n",
            "Training batch 46 completed. Loss: 1.0899, Accuracy: 0.5339\n",
            "Training batch 47 started.\n",
            "Training batch 47 completed. Loss: 1.0816, Accuracy: 0.5352\n",
            "Training batch 48 started.\n",
            "Training batch 48 completed. Loss: 1.0737, Accuracy: 0.5344\n",
            "Training batch 49 started.\n",
            "Training batch 49 completed. Loss: 1.0661, Accuracy: 0.5312\n",
            "Training batch 50 started.\n",
            "Training batch 50 completed. Loss: 1.0587, Accuracy: 0.5319\n",
            "Training batch 51 started.\n",
            "Training batch 51 completed. Loss: 1.0517, Accuracy: 0.5319\n",
            "Training batch 52 started.\n",
            "Training batch 52 completed. Loss: 1.0449, Accuracy: 0.5324\n",
            "Training batch 53 started.\n",
            "Training batch 53 completed. Loss: 1.0385, Accuracy: 0.5284\n",
            "Training batch 54 started.\n",
            "Training batch 54 completed. Loss: 1.0322, Accuracy: 0.5284\n",
            "Training batch 55 started.\n",
            "Training batch 55 completed. Loss: 1.0262, Accuracy: 0.5273\n",
            "Training batch 56 started.\n",
            "Training batch 56 completed. Loss: 1.0203, Accuracy: 0.5285\n",
            "Training batch 57 started.\n",
            "Training batch 57 completed. Loss: 1.0147, Accuracy: 0.5280\n",
            "Training batch 58 started.\n",
            "Training batch 58 completed. Loss: 1.0092, Accuracy: 0.5286\n",
            "Training batch 59 started.\n",
            "Training batch 59 completed. Loss: 1.0039, Accuracy: 0.5286\n",
            "Training batch 60 started.\n",
            "Training batch 60 completed. Loss: 0.9987, Accuracy: 0.5318\n",
            "Training batch 61 started.\n",
            "Training batch 61 completed. Loss: 0.9937, Accuracy: 0.5338\n",
            "Training batch 62 started.\n",
            "Training batch 62 completed. Loss: 0.9890, Accuracy: 0.5332\n",
            "Training batch 63 started.\n",
            "Training batch 63 completed. Loss: 0.9843, Accuracy: 0.5356\n",
            "Training batch 64 started.\n",
            "Training batch 64 completed. Loss: 0.9797, Accuracy: 0.5365\n",
            "Training batch 65 started.\n",
            "Training batch 65 completed. Loss: 0.9753, Accuracy: 0.5379\n",
            "Training batch 66 started.\n",
            "Training batch 66 completed. Loss: 0.9710, Accuracy: 0.5396\n",
            "Training batch 67 started.\n",
            "Training batch 67 completed. Loss: 0.9670, Accuracy: 0.5386\n",
            "Training batch 68 started.\n",
            "Training batch 68 completed. Loss: 0.9629, Accuracy: 0.5403\n",
            "Training batch 69 started.\n",
            "Training batch 69 completed. Loss: 0.9590, Accuracy: 0.5411\n",
            "Training batch 70 started.\n",
            "Training batch 70 completed. Loss: 0.9552, Accuracy: 0.5431\n",
            "Training batch 71 started.\n",
            "Training batch 71 completed. Loss: 0.9515, Accuracy: 0.5430\n",
            "Training batch 72 started.\n",
            "Training batch 72 completed. Loss: 0.9480, Accuracy: 0.5407\n",
            "Training batch 73 started.\n",
            "Training batch 73 completed. Loss: 0.9447, Accuracy: 0.5389\n",
            "Training batch 74 started.\n",
            "Training batch 74 completed. Loss: 0.9414, Accuracy: 0.5367\n",
            "Training batch 75 started.\n",
            "Training batch 75 completed. Loss: 0.9381, Accuracy: 0.5366\n",
            "Training batch 76 started.\n",
            "Training batch 76 completed. Loss: 0.9349, Accuracy: 0.5377\n",
            "Training batch 77 started.\n",
            "Training batch 77 completed. Loss: 0.9317, Accuracy: 0.5385\n",
            "Training batch 78 started.\n",
            "Training batch 78 completed. Loss: 0.9286, Accuracy: 0.5396\n",
            "Training batch 79 started.\n",
            "Training batch 79 completed. Loss: 0.9257, Accuracy: 0.5391\n",
            "Training batch 80 started.\n",
            "Training batch 80 completed. Loss: 0.9228, Accuracy: 0.5386\n",
            "Training batch 81 started.\n",
            "Training batch 81 completed. Loss: 0.9201, Accuracy: 0.5370\n",
            "Training batch 82 started.\n",
            "Training batch 82 completed. Loss: 0.9173, Accuracy: 0.5365\n",
            "Training batch 83 started.\n",
            "Training batch 83 completed. Loss: 0.9146, Accuracy: 0.5368\n",
            "Training batch 84 started.\n",
            "Training batch 84 completed. Loss: 0.9121, Accuracy: 0.5346\n",
            "Training batch 85 started.\n",
            "Training batch 85 completed. Loss: 0.9095, Accuracy: 0.5349\n",
            "Training batch 86 started.\n",
            "Training batch 86 completed. Loss: 0.9071, Accuracy: 0.5338\n",
            "Training batch 87 started.\n",
            "Training batch 87 completed. Loss: 0.9046, Accuracy: 0.5337\n",
            "Training batch 88 started.\n",
            "Training batch 88 completed. Loss: 0.9022, Accuracy: 0.5341\n",
            "Training batch 89 started.\n",
            "Training batch 89 completed. Loss: 0.8999, Accuracy: 0.5337\n",
            "Training batch 90 started.\n",
            "Training batch 90 completed. Loss: 0.8977, Accuracy: 0.5333\n",
            "Training batch 91 started.\n",
            "Training batch 91 completed. Loss: 0.8954, Accuracy: 0.5333\n",
            "Training batch 92 started.\n",
            "Training batch 92 completed. Loss: 0.8933, Accuracy: 0.5312\n",
            "Training batch 93 started.\n",
            "Training batch 93 completed. Loss: 0.8911, Accuracy: 0.5322\n",
            "Training batch 94 started.\n",
            "Training batch 94 completed. Loss: 0.8890, Accuracy: 0.5322\n",
            "Training batch 95 started.\n",
            "Training batch 95 completed. Loss: 0.8871, Accuracy: 0.5309\n",
            "Training batch 96 started.\n",
            "Training batch 96 completed. Loss: 0.8850, Accuracy: 0.5312\n",
            "Training batch 97 started.\n",
            "Training batch 97 completed. Loss: 0.8831, Accuracy: 0.5309\n",
            "Training batch 98 started.\n",
            "Training batch 98 completed. Loss: 0.8812, Accuracy: 0.5294\n",
            "Training batch 99 started.\n",
            "Training batch 99 completed. Loss: 0.8793, Accuracy: 0.5291\n",
            "Training batch 100 started.\n",
            "Training batch 100 completed. Loss: 0.8775, Accuracy: 0.5294\n",
            "Training batch 101 started.\n",
            "Training batch 101 completed. Loss: 0.8757, Accuracy: 0.5285\n",
            "Training batch 102 started.\n",
            "Training batch 102 completed. Loss: 0.8740, Accuracy: 0.5282\n",
            "Training batch 103 started.\n",
            "Training batch 103 completed. Loss: 0.8722, Accuracy: 0.5279\n",
            "Training batch 104 started.\n",
            "Training batch 104 completed. Loss: 0.8704, Accuracy: 0.5295\n",
            "Training batch 105 started.\n",
            "Training batch 105 completed. Loss: 0.8687, Accuracy: 0.5304\n",
            "Training batch 106 started.\n",
            "Training batch 106 completed. Loss: 0.8671, Accuracy: 0.5304\n",
            "Training batch 107 started.\n",
            "Training batch 107 completed. Loss: 0.8655, Accuracy: 0.5307\n",
            "Training batch 108 started.\n",
            "Training batch 108 completed. Loss: 0.8639, Accuracy: 0.5292\n",
            "Training batch 109 started.\n",
            "Training batch 109 completed. Loss: 0.8624, Accuracy: 0.5298\n",
            "Training batch 110 started.\n",
            "Training batch 110 completed. Loss: 0.8608, Accuracy: 0.5307\n",
            "Training batch 111 started.\n",
            "Training batch 111 completed. Loss: 0.8592, Accuracy: 0.5312\n",
            "Training batch 112 started.\n",
            "Training batch 112 completed. Loss: 0.8578, Accuracy: 0.5310\n",
            "Training batch 113 started.\n",
            "Training batch 113 completed. Loss: 0.8564, Accuracy: 0.5312\n",
            "Training batch 114 started.\n",
            "Training batch 114 completed. Loss: 0.8550, Accuracy: 0.5302\n",
            "Training batch 115 started.\n",
            "Training batch 115 completed. Loss: 0.8536, Accuracy: 0.5299\n",
            "Training batch 116 started.\n",
            "Training batch 116 completed. Loss: 0.8522, Accuracy: 0.5299\n",
            "Training batch 117 started.\n",
            "Training batch 117 completed. Loss: 0.8509, Accuracy: 0.5305\n",
            "Training batch 118 started.\n",
            "Training batch 118 completed. Loss: 0.8495, Accuracy: 0.5307\n",
            "Training batch 119 started.\n",
            "Training batch 119 completed. Loss: 0.8481, Accuracy: 0.5315\n",
            "Training batch 120 started.\n",
            "Training batch 120 completed. Loss: 0.8468, Accuracy: 0.5325\n",
            "Training batch 121 started.\n",
            "Training batch 121 completed. Loss: 0.8455, Accuracy: 0.5325\n",
            "Training batch 122 started.\n",
            "Training batch 122 completed. Loss: 0.8442, Accuracy: 0.5338\n",
            "Training batch 123 started.\n",
            "Training batch 123 completed. Loss: 0.8430, Accuracy: 0.5343\n",
            "Training batch 124 started.\n",
            "Training batch 124 completed. Loss: 0.8418, Accuracy: 0.5332\n",
            "Training batch 125 started.\n",
            "Training batch 125 completed. Loss: 0.8406, Accuracy: 0.5340\n",
            "Training batch 126 started.\n",
            "Training batch 126 completed. Loss: 0.8393, Accuracy: 0.5340\n",
            "Training batch 127 started.\n",
            "Training batch 127 completed. Loss: 0.8380, Accuracy: 0.5354\n",
            "Training batch 128 started.\n",
            "Training batch 128 completed. Loss: 0.8367, Accuracy: 0.5356\n",
            "Training batch 129 started.\n",
            "Training batch 129 completed. Loss: 0.8360, Accuracy: 0.5353\n",
            "Training batch 130 started.\n",
            "Training batch 130 completed. Loss: 0.8348, Accuracy: 0.5360\n",
            "Training batch 131 started.\n",
            "Training batch 131 completed. Loss: 0.8336, Accuracy: 0.5360\n",
            "Training batch 132 started.\n",
            "Training batch 132 completed. Loss: 0.8325, Accuracy: 0.5369\n",
            "Training batch 133 started.\n",
            "Training batch 133 completed. Loss: 0.8314, Accuracy: 0.5366\n",
            "Training batch 134 started.\n",
            "Training batch 134 completed. Loss: 0.8303, Accuracy: 0.5373\n",
            "Training batch 135 started.\n",
            "Training batch 135 completed. Loss: 0.8292, Accuracy: 0.5375\n",
            "Training batch 136 started.\n",
            "Training batch 136 completed. Loss: 0.8282, Accuracy: 0.5372\n",
            "Training batch 137 started.\n",
            "Training batch 137 completed. Loss: 0.8273, Accuracy: 0.5376\n",
            "Training batch 138 started.\n",
            "Training batch 138 completed. Loss: 0.8263, Accuracy: 0.5373\n",
            "Training batch 139 started.\n",
            "Training batch 139 completed. Loss: 0.8253, Accuracy: 0.5384\n",
            "Training batch 140 started.\n",
            "Training batch 140 completed. Loss: 0.8243, Accuracy: 0.5383\n",
            "Training batch 141 started.\n",
            "Training batch 141 completed. Loss: 0.8234, Accuracy: 0.5385\n",
            "Training batch 142 started.\n",
            "Training batch 142 completed. Loss: 0.8224, Accuracy: 0.5385\n",
            "Training batch 143 started.\n",
            "Training batch 143 completed. Loss: 0.8216, Accuracy: 0.5382\n",
            "Training batch 144 started.\n",
            "Training batch 144 completed. Loss: 0.8207, Accuracy: 0.5381\n",
            "Training batch 145 started.\n",
            "Training batch 145 completed. Loss: 0.8197, Accuracy: 0.5392\n",
            "Training batch 146 started.\n",
            "Training batch 146 completed. Loss: 0.8189, Accuracy: 0.5391\n",
            "Training batch 147 started.\n",
            "Training batch 147 completed. Loss: 0.8180, Accuracy: 0.5397\n",
            "Training batch 148 started.\n",
            "Training batch 148 completed. Loss: 0.8171, Accuracy: 0.5388\n",
            "Training batch 149 started.\n",
            "Training batch 149 completed. Loss: 0.8163, Accuracy: 0.5392\n",
            "Training batch 150 started.\n",
            "Training batch 150 completed. Loss: 0.8154, Accuracy: 0.5391\n",
            "Training batch 151 started.\n",
            "Training batch 151 completed. Loss: 0.8145, Accuracy: 0.5393\n",
            "Training batch 152 started.\n",
            "Training batch 152 completed. Loss: 0.8136, Accuracy: 0.5400\n",
            "Training batch 153 started.\n",
            "Training batch 153 completed. Loss: 0.8128, Accuracy: 0.5400\n",
            "Training batch 154 started.\n",
            "Training batch 154 completed. Loss: 0.8119, Accuracy: 0.5407\n",
            "Training batch 155 started.\n",
            "Training batch 155 completed. Loss: 0.8114, Accuracy: 0.5409\n",
            "Training batch 156 started.\n",
            "Training batch 156 completed. Loss: 0.8107, Accuracy: 0.5406\n",
            "Training batch 157 started.\n",
            "Training batch 157 completed. Loss: 0.8099, Accuracy: 0.5407\n",
            "Training batch 158 started.\n",
            "Training batch 158 completed. Loss: 0.8093, Accuracy: 0.5401\n",
            "Training batch 159 started.\n",
            "Training batch 159 completed. Loss: 0.8089, Accuracy: 0.5395\n",
            "Training batch 160 started.\n",
            "Training batch 160 completed. Loss: 0.8081, Accuracy: 0.5396\n",
            "Training batch 161 started.\n",
            "Training batch 161 completed. Loss: 0.8074, Accuracy: 0.5397\n",
            "Training batch 162 started.\n",
            "Training batch 162 completed. Loss: 0.8067, Accuracy: 0.5401\n",
            "Training batch 163 started.\n",
            "Training batch 163 completed. Loss: 0.8060, Accuracy: 0.5398\n",
            "Training batch 164 started.\n",
            "Training batch 164 completed. Loss: 0.8054, Accuracy: 0.5392\n",
            "Training batch 165 started.\n",
            "Training batch 165 completed. Loss: 0.8046, Accuracy: 0.5397\n",
            "Training batch 166 started.\n",
            "Training batch 166 completed. Loss: 0.8039, Accuracy: 0.5395\n",
            "Training batch 167 started.\n",
            "Training batch 167 completed. Loss: 0.8033, Accuracy: 0.5392\n",
            "Training batch 168 started.\n",
            "Training batch 168 completed. Loss: 0.8026, Accuracy: 0.5390\n",
            "Training batch 169 started.\n",
            "Training batch 169 completed. Loss: 0.8020, Accuracy: 0.5386\n",
            "Training batch 170 started.\n",
            "Training batch 170 completed. Loss: 0.8014, Accuracy: 0.5386\n",
            "Training batch 171 started.\n",
            "Training batch 171 completed. Loss: 0.8007, Accuracy: 0.5389\n",
            "Training batch 172 started.\n",
            "Training batch 172 completed. Loss: 0.8001, Accuracy: 0.5387\n",
            "Training batch 173 started.\n",
            "Training batch 173 completed. Loss: 0.7995, Accuracy: 0.5384\n",
            "Training batch 174 started.\n",
            "Training batch 174 completed. Loss: 0.7989, Accuracy: 0.5384\n",
            "Training batch 175 started.\n",
            "Training batch 175 completed. Loss: 0.7983, Accuracy: 0.5380\n",
            "Training batch 176 started.\n",
            "Training batch 176 completed. Loss: 0.7977, Accuracy: 0.5376\n",
            "Training batch 177 started.\n",
            "Training batch 177 completed. Loss: 0.7971, Accuracy: 0.5377\n",
            "Training batch 178 started.\n",
            "Training batch 178 completed. Loss: 0.7965, Accuracy: 0.5374\n",
            "Training batch 179 started.\n",
            "Training batch 179 completed. Loss: 0.7959, Accuracy: 0.5377\n",
            "Training batch 180 started.\n",
            "Training batch 180 completed. Loss: 0.7954, Accuracy: 0.5373\n",
            "Training batch 181 started.\n",
            "Training batch 181 completed. Loss: 0.7948, Accuracy: 0.5373\n",
            "Training batch 182 started.\n",
            "Training batch 182 completed. Loss: 0.7943, Accuracy: 0.5365\n",
            "Training batch 183 started.\n",
            "Training batch 183 completed. Loss: 0.7937, Accuracy: 0.5365\n",
            "Training batch 184 started.\n",
            "Training batch 184 completed. Loss: 0.7932, Accuracy: 0.5360\n",
            "Training batch 185 started.\n",
            "Training batch 185 completed. Loss: 0.7926, Accuracy: 0.5365\n",
            "Training batch 186 started.\n",
            "Training batch 186 completed. Loss: 0.7921, Accuracy: 0.5368\n",
            "Training batch 187 started.\n",
            "Training batch 187 completed. Loss: 0.7915, Accuracy: 0.5367\n",
            "Training batch 188 started.\n",
            "Training batch 188 completed. Loss: 0.7910, Accuracy: 0.5365\n",
            "Training batch 189 started.\n",
            "Training batch 189 completed. Loss: 0.7906, Accuracy: 0.5355\n",
            "Training batch 190 started.\n",
            "Training batch 190 completed. Loss: 0.7901, Accuracy: 0.5352\n",
            "Training batch 191 started.\n",
            "Training batch 191 completed. Loss: 0.7897, Accuracy: 0.5342\n",
            "Training batch 192 started.\n",
            "Training batch 192 completed. Loss: 0.7892, Accuracy: 0.5334\n",
            "Training batch 193 started.\n",
            "Training batch 193 completed. Loss: 0.7887, Accuracy: 0.5333\n",
            "Training batch 194 started.\n",
            "Training batch 194 completed. Loss: 0.7882, Accuracy: 0.5330\n",
            "Training batch 195 started.\n",
            "Training batch 195 completed. Loss: 0.7877, Accuracy: 0.5330\n",
            "Training batch 196 started.\n",
            "Training batch 196 completed. Loss: 0.7873, Accuracy: 0.5327\n",
            "Training batch 197 started.\n",
            "Training batch 197 completed. Loss: 0.7868, Accuracy: 0.5322\n",
            "Training batch 198 started.\n",
            "Training batch 198 completed. Loss: 0.7863, Accuracy: 0.5330\n",
            "Training batch 199 started.\n",
            "Training batch 199 completed. Loss: 0.7858, Accuracy: 0.5333\n",
            "Training batch 200 started.\n",
            "Training batch 200 completed. Loss: 0.7853, Accuracy: 0.5330\n",
            "Training batch 201 started.\n",
            "Training batch 201 completed. Loss: 0.7851, Accuracy: 0.5328\n",
            "Training batch 202 started.\n",
            "Training batch 202 completed. Loss: 0.7848, Accuracy: 0.5312\n",
            "Training batch 203 started.\n",
            "Training batch 203 completed. Loss: 0.7843, Accuracy: 0.5317\n",
            "Training batch 204 started.\n",
            "Training batch 204 completed. Loss: 0.7839, Accuracy: 0.5316\n",
            "Training batch 205 started.\n",
            "Training batch 205 completed. Loss: 0.7834, Accuracy: 0.5312\n",
            "Training batch 206 started.\n",
            "Training batch 206 completed. Loss: 0.7830, Accuracy: 0.5316\n",
            "Training batch 207 started.\n",
            "Training batch 207 completed. Loss: 0.7825, Accuracy: 0.5322\n",
            "Training batch 208 started.\n",
            "Training batch 208 completed. Loss: 0.7820, Accuracy: 0.5324\n",
            "Training batch 209 started.\n",
            "Training batch 209 completed. Loss: 0.7816, Accuracy: 0.5321\n",
            "Training batch 210 started.\n",
            "Training batch 210 completed. Loss: 0.7812, Accuracy: 0.5318\n",
            "Training batch 211 started.\n",
            "Training batch 211 completed. Loss: 0.7808, Accuracy: 0.5321\n",
            "Training batch 212 started.\n",
            "Training batch 212 completed. Loss: 0.7803, Accuracy: 0.5321\n",
            "Training batch 213 started.\n",
            "Training batch 213 completed. Loss: 0.7799, Accuracy: 0.5321\n",
            "Training batch 214 started.\n",
            "Training batch 214 completed. Loss: 0.7795, Accuracy: 0.5324\n",
            "Training batch 215 started.\n",
            "Training batch 215 completed. Loss: 0.7791, Accuracy: 0.5315\n",
            "Training batch 216 started.\n",
            "Training batch 216 completed. Loss: 0.7787, Accuracy: 0.5318\n",
            "Training batch 217 started.\n",
            "Training batch 217 completed. Loss: 0.7783, Accuracy: 0.5317\n",
            "Training batch 218 started.\n",
            "Training batch 218 completed. Loss: 0.7779, Accuracy: 0.5318\n",
            "Training batch 219 started.\n",
            "Training batch 219 completed. Loss: 0.7775, Accuracy: 0.5317\n",
            "Training batch 220 started.\n",
            "Training batch 220 completed. Loss: 0.7770, Accuracy: 0.5317\n",
            "Training batch 221 started.\n",
            "Training batch 221 completed. Loss: 0.7766, Accuracy: 0.5321\n",
            "Training batch 222 started.\n",
            "Training batch 222 completed. Loss: 0.7761, Accuracy: 0.5325\n",
            "Training batch 223 started.\n",
            "Training batch 223 completed. Loss: 0.7768, Accuracy: 0.5315\n",
            "Training batch 224 started.\n",
            "Training batch 224 completed. Loss: 0.7764, Accuracy: 0.5311\n",
            "Training batch 225 started.\n",
            "Training batch 225 completed. Loss: 0.7762, Accuracy: 0.5312\n",
            "Training batch 226 started.\n",
            "Training batch 226 completed. Loss: 0.7759, Accuracy: 0.5314\n",
            "Training batch 227 started.\n",
            "Training batch 227 completed. Loss: 0.7755, Accuracy: 0.5314\n",
            "Training batch 228 started.\n",
            "Training batch 228 completed. Loss: 0.7752, Accuracy: 0.5308\n",
            "Training batch 229 started.\n",
            "Training batch 229 completed. Loss: 0.7748, Accuracy: 0.5310\n",
            "Training batch 230 started.\n",
            "Training batch 230 completed. Loss: 0.7744, Accuracy: 0.5314\n",
            "Training batch 231 started.\n",
            "Training batch 231 completed. Loss: 0.7741, Accuracy: 0.5315\n",
            "Training batch 232 started.\n",
            "Training batch 232 completed. Loss: 0.7738, Accuracy: 0.5310\n",
            "Training batch 233 started.\n",
            "Training batch 233 completed. Loss: 0.7734, Accuracy: 0.5310\n",
            "Training batch 234 started.\n",
            "Training batch 234 completed. Loss: 0.7731, Accuracy: 0.5303\n",
            "Training batch 235 started.\n",
            "Training batch 235 completed. Loss: 0.7727, Accuracy: 0.5307\n",
            "Training batch 236 started.\n",
            "Training batch 236 completed. Loss: 0.7724, Accuracy: 0.5306\n",
            "Training batch 237 started.\n",
            "Training batch 237 completed. Loss: 0.7721, Accuracy: 0.5302\n",
            "Training batch 238 started.\n",
            "Training batch 238 completed. Loss: 0.7718, Accuracy: 0.5302\n",
            "Training batch 239 started.\n",
            "Training batch 239 completed. Loss: 0.7714, Accuracy: 0.5299\n",
            "Training batch 240 started.\n",
            "Training batch 240 completed. Loss: 0.7711, Accuracy: 0.5297\n",
            "Training batch 241 started.\n",
            "Training batch 241 completed. Loss: 0.7708, Accuracy: 0.5294\n",
            "Training batch 242 started.\n",
            "Training batch 242 completed. Loss: 0.7705, Accuracy: 0.5296\n",
            "Training batch 243 started.\n",
            "Training batch 243 completed. Loss: 0.7701, Accuracy: 0.5300\n",
            "Training batch 244 started.\n",
            "Training batch 244 completed. Loss: 0.7698, Accuracy: 0.5301\n",
            "Training batch 245 started.\n",
            "Training batch 245 completed. Loss: 0.7695, Accuracy: 0.5304\n",
            "Training batch 246 started.\n",
            "Training batch 246 completed. Loss: 0.7691, Accuracy: 0.5307\n",
            "Training batch 247 started.\n",
            "Training batch 247 completed. Loss: 0.7688, Accuracy: 0.5312\n",
            "Training batch 248 started.\n",
            "Training batch 248 completed. Loss: 0.7685, Accuracy: 0.5309\n",
            "Training batch 249 started.\n",
            "Training batch 249 completed. Loss: 0.7681, Accuracy: 0.5314\n",
            "Training batch 250 started.\n",
            "Training batch 250 completed. Loss: 0.7678, Accuracy: 0.5316\n",
            "Training batch 251 started.\n",
            "Training batch 251 completed. Loss: 0.7675, Accuracy: 0.5310\n",
            "Training batch 252 started.\n",
            "Training batch 252 completed. Loss: 0.7672, Accuracy: 0.5314\n",
            "Training batch 253 started.\n",
            "Training batch 253 completed. Loss: 0.7668, Accuracy: 0.5317\n",
            "Training batch 254 started.\n",
            "Training batch 254 completed. Loss: 0.7665, Accuracy: 0.5319\n",
            "Training batch 255 started.\n",
            "Training batch 255 completed. Loss: 0.7662, Accuracy: 0.5321\n",
            "Training batch 256 started.\n",
            "Training batch 256 completed. Loss: 0.7659, Accuracy: 0.5321\n",
            "Training batch 257 started.\n",
            "Training batch 257 completed. Loss: 0.7658, Accuracy: 0.5320\n",
            "Training batch 258 started.\n",
            "Training batch 258 completed. Loss: 0.7656, Accuracy: 0.5311\n",
            "Training batch 259 started.\n",
            "Training batch 259 completed. Loss: 0.7652, Accuracy: 0.5311\n",
            "Training batch 260 started.\n",
            "Training batch 260 completed. Loss: 0.7650, Accuracy: 0.5307\n",
            "Training batch 261 started.\n",
            "Training batch 261 completed. Loss: 0.7647, Accuracy: 0.5307\n",
            "Training batch 262 started.\n",
            "Training batch 262 completed. Loss: 0.7643, Accuracy: 0.5310\n",
            "Training batch 263 started.\n",
            "Training batch 263 completed. Loss: 0.7641, Accuracy: 0.5311\n",
            "Training batch 264 started.\n",
            "Training batch 264 completed. Loss: 0.7639, Accuracy: 0.5304\n",
            "Training batch 265 started.\n",
            "Training batch 265 completed. Loss: 0.7637, Accuracy: 0.5303\n",
            "Training batch 266 started.\n",
            "Training batch 266 completed. Loss: 0.7634, Accuracy: 0.5302\n",
            "Training batch 267 started.\n",
            "Training batch 267 completed. Loss: 0.7631, Accuracy: 0.5299\n",
            "Training batch 268 started.\n",
            "Training batch 268 completed. Loss: 0.7629, Accuracy: 0.5296\n",
            "Training batch 269 started.\n",
            "Training batch 269 completed. Loss: 0.7625, Accuracy: 0.5304\n",
            "Training batch 270 started.\n",
            "Training batch 270 completed. Loss: 0.7623, Accuracy: 0.5301\n",
            "Training batch 271 started.\n",
            "Training batch 271 completed. Loss: 0.7620, Accuracy: 0.5303\n",
            "Training batch 272 started.\n",
            "Training batch 272 completed. Loss: 0.7616, Accuracy: 0.5310\n",
            "Training batch 273 started.\n",
            "Training batch 273 completed. Loss: 0.7614, Accuracy: 0.5303\n",
            "Training batch 274 started.\n",
            "Training batch 274 completed. Loss: 0.7611, Accuracy: 0.5309\n",
            "Training batch 275 started.\n",
            "Training batch 275 completed. Loss: 0.7609, Accuracy: 0.5306\n",
            "Training batch 276 started.\n",
            "Training batch 276 completed. Loss: 0.7607, Accuracy: 0.5307\n",
            "Training batch 277 started.\n",
            "Training batch 277 completed. Loss: 0.7605, Accuracy: 0.5301\n",
            "Training batch 278 started.\n",
            "Training batch 278 completed. Loss: 0.7603, Accuracy: 0.5296\n",
            "Training batch 279 started.\n",
            "Training batch 279 completed. Loss: 0.7600, Accuracy: 0.5292\n",
            "Training batch 280 started.\n",
            "Training batch 280 completed. Loss: 0.7598, Accuracy: 0.5291\n",
            "Training batch 281 started.\n",
            "Training batch 281 completed. Loss: 0.7596, Accuracy: 0.5287\n",
            "Training batch 282 started.\n",
            "Training batch 282 completed. Loss: 0.7593, Accuracy: 0.5288\n",
            "Training batch 283 started.\n",
            "Training batch 283 completed. Loss: 0.7591, Accuracy: 0.5287\n",
            "Training batch 284 started.\n",
            "Training batch 284 completed. Loss: 0.7588, Accuracy: 0.5287\n",
            "Training batch 285 started.\n",
            "Training batch 285 completed. Loss: 0.7586, Accuracy: 0.5290\n",
            "Training batch 286 started.\n",
            "Training batch 286 completed. Loss: 0.7583, Accuracy: 0.5289\n",
            "Training batch 287 started.\n",
            "Training batch 287 completed. Loss: 0.7581, Accuracy: 0.5286\n",
            "Training batch 288 started.\n",
            "Training batch 288 completed. Loss: 0.7579, Accuracy: 0.5290\n",
            "Training batch 289 started.\n",
            "Training batch 289 completed. Loss: 0.7576, Accuracy: 0.5289\n",
            "Training batch 290 started.\n",
            "Training batch 290 completed. Loss: 0.7574, Accuracy: 0.5289\n",
            "Training batch 291 started.\n",
            "Training batch 291 completed. Loss: 0.7573, Accuracy: 0.5289\n",
            "Training batch 292 started.\n",
            "Training batch 292 completed. Loss: 0.7570, Accuracy: 0.5293\n",
            "Training batch 293 started.\n",
            "Training batch 293 completed. Loss: 0.7568, Accuracy: 0.5292\n",
            "Training batch 294 started.\n",
            "Training batch 294 completed. Loss: 0.7566, Accuracy: 0.5290\n",
            "Training batch 295 started.\n",
            "Training batch 295 completed. Loss: 0.7565, Accuracy: 0.5288\n",
            "Training batch 296 started.\n",
            "Training batch 296 completed. Loss: 0.7563, Accuracy: 0.5290\n",
            "Training batch 297 started.\n",
            "Training batch 297 completed. Loss: 0.7560, Accuracy: 0.5290\n",
            "Training batch 298 started.\n",
            "Training batch 298 completed. Loss: 0.7560, Accuracy: 0.5291\n",
            "Training batch 299 started.\n",
            "Training batch 299 completed. Loss: 0.7559, Accuracy: 0.5290\n",
            "Training batch 300 started.\n",
            "Training batch 300 completed. Loss: 0.7556, Accuracy: 0.5289\n",
            "Training batch 301 started.\n",
            "Training batch 301 completed. Loss: 0.7554, Accuracy: 0.5288\n",
            "Training batch 302 started.\n",
            "Training batch 302 completed. Loss: 0.7552, Accuracy: 0.5287\n",
            "Training batch 303 started.\n",
            "Training batch 303 completed. Loss: 0.7550, Accuracy: 0.5284\n",
            "Training batch 304 started.\n",
            "Training batch 304 completed. Loss: 0.7548, Accuracy: 0.5285\n",
            "Training batch 305 started.\n",
            "Training batch 305 completed. Loss: 0.7545, Accuracy: 0.5288\n",
            "Training batch 306 started.\n",
            "Training batch 306 completed. Loss: 0.7543, Accuracy: 0.5287\n",
            "Training batch 307 started.\n",
            "Training batch 307 completed. Loss: 0.7541, Accuracy: 0.5286\n",
            "Training batch 308 started.\n",
            "Training batch 308 completed. Loss: 0.7539, Accuracy: 0.5286\n",
            "Training batch 309 started.\n",
            "Training batch 309 completed. Loss: 0.7537, Accuracy: 0.5282\n",
            "Training batch 310 started.\n",
            "Training batch 310 completed. Loss: 0.7535, Accuracy: 0.5283\n",
            "Training batch 311 started.\n",
            "Training batch 311 completed. Loss: 0.7534, Accuracy: 0.5280\n",
            "Training batch 312 started.\n",
            "Training batch 312 completed. Loss: 0.7532, Accuracy: 0.5282\n",
            "Training batch 313 started.\n",
            "Training batch 313 completed. Loss: 0.7530, Accuracy: 0.5276\n",
            "Training batch 314 started.\n",
            "Training batch 314 completed. Loss: 0.7528, Accuracy: 0.5275\n",
            "Training batch 315 started.\n",
            "Training batch 315 completed. Loss: 0.7526, Accuracy: 0.5280\n",
            "Training batch 316 started.\n",
            "Training batch 316 completed. Loss: 0.7524, Accuracy: 0.5283\n",
            "Training batch 317 started.\n",
            "Training batch 317 completed. Loss: 0.7522, Accuracy: 0.5281\n",
            "Training batch 318 started.\n",
            "Training batch 318 completed. Loss: 0.7521, Accuracy: 0.5279\n",
            "Training batch 319 started.\n",
            "Training batch 319 completed. Loss: 0.7518, Accuracy: 0.5279\n",
            "Training batch 320 started.\n",
            "Training batch 320 completed. Loss: 0.7517, Accuracy: 0.5276\n",
            "Training batch 321 started.\n",
            "Training batch 321 completed. Loss: 0.7514, Accuracy: 0.5283\n",
            "Training batch 322 started.\n",
            "Training batch 322 completed. Loss: 0.7512, Accuracy: 0.5287\n",
            "Training batch 323 started.\n",
            "Training batch 323 completed. Loss: 0.7511, Accuracy: 0.5289\n",
            "Training batch 324 started.\n",
            "Training batch 324 completed. Loss: 0.7509, Accuracy: 0.5288\n",
            "Training batch 325 started.\n",
            "Training batch 325 completed. Loss: 0.7507, Accuracy: 0.5291\n",
            "Training batch 326 started.\n",
            "Training batch 326 completed. Loss: 0.7505, Accuracy: 0.5295\n",
            "Training batch 327 started.\n",
            "Training batch 327 completed. Loss: 0.7503, Accuracy: 0.5299\n",
            "Training batch 328 started.\n",
            "Training batch 328 completed. Loss: 0.7501, Accuracy: 0.5299\n",
            "Training batch 329 started.\n",
            "Training batch 329 completed. Loss: 0.7499, Accuracy: 0.5301\n",
            "Training batch 330 started.\n",
            "Training batch 330 completed. Loss: 0.7497, Accuracy: 0.5297\n",
            "Training batch 331 started.\n",
            "Training batch 331 completed. Loss: 0.7496, Accuracy: 0.5296\n",
            "Training batch 332 started.\n",
            "Training batch 332 completed. Loss: 0.7494, Accuracy: 0.5297\n",
            "Training batch 333 started.\n",
            "Training batch 333 completed. Loss: 0.7492, Accuracy: 0.5294\n",
            "Training batch 334 started.\n",
            "Training batch 334 completed. Loss: 0.7490, Accuracy: 0.5295\n",
            "Training batch 335 started.\n",
            "Training batch 335 completed. Loss: 0.7489, Accuracy: 0.5292\n",
            "Training batch 336 started.\n",
            "Training batch 336 completed. Loss: 0.7487, Accuracy: 0.5292\n",
            "Training batch 337 started.\n",
            "Training batch 337 completed. Loss: 0.7486, Accuracy: 0.5292\n",
            "Training batch 338 started.\n",
            "Training batch 338 completed. Loss: 0.7483, Accuracy: 0.5297\n",
            "Training batch 339 started.\n",
            "Training batch 339 completed. Loss: 0.7481, Accuracy: 0.5302\n",
            "Training batch 340 started.\n",
            "Training batch 340 completed. Loss: 0.7479, Accuracy: 0.5303\n",
            "Training batch 341 started.\n",
            "Training batch 341 completed. Loss: 0.7477, Accuracy: 0.5308\n",
            "Training batch 342 started.\n",
            "Training batch 342 completed. Loss: 0.7475, Accuracy: 0.5311\n",
            "Training batch 343 started.\n",
            "Training batch 343 completed. Loss: 0.7472, Accuracy: 0.5314\n",
            "Training batch 344 started.\n",
            "Training batch 344 completed. Loss: 0.7472, Accuracy: 0.5314\n",
            "Training batch 345 started.\n",
            "Training batch 345 completed. Loss: 0.7469, Accuracy: 0.5317\n",
            "Training batch 346 started.\n",
            "Training batch 346 completed. Loss: 0.7467, Accuracy: 0.5314\n",
            "Training batch 347 started.\n",
            "Training batch 347 completed. Loss: 0.7465, Accuracy: 0.5318\n",
            "Training batch 348 started.\n",
            "Training batch 348 completed. Loss: 0.7463, Accuracy: 0.5321\n",
            "Training batch 349 started.\n",
            "Training batch 349 completed. Loss: 0.7460, Accuracy: 0.5325\n",
            "Training batch 350 started.\n",
            "Training batch 350 completed. Loss: 0.7459, Accuracy: 0.5323\n",
            "Training batch 351 started.\n",
            "Training batch 351 completed. Loss: 0.7457, Accuracy: 0.5328\n",
            "Training batch 352 started.\n",
            "Training batch 352 completed. Loss: 0.7457, Accuracy: 0.5323\n",
            "Training batch 353 started.\n",
            "Training batch 353 completed. Loss: 0.7455, Accuracy: 0.5323\n",
            "Training batch 354 started.\n",
            "Training batch 354 completed. Loss: 0.7453, Accuracy: 0.5327\n",
            "Training batch 355 started.\n",
            "Training batch 355 completed. Loss: 0.7451, Accuracy: 0.5328\n",
            "Training batch 356 started.\n",
            "Training batch 356 completed. Loss: 0.7449, Accuracy: 0.5332\n",
            "Training batch 357 started.\n",
            "Training batch 357 completed. Loss: 0.7446, Accuracy: 0.5335\n",
            "Training batch 358 started.\n",
            "Training batch 358 completed. Loss: 0.7446, Accuracy: 0.5338\n",
            "Training batch 359 started.\n",
            "Training batch 359 completed. Loss: 0.7445, Accuracy: 0.5338\n",
            "Training batch 360 started.\n",
            "Training batch 360 completed. Loss: 0.7443, Accuracy: 0.5340\n",
            "Training batch 361 started.\n",
            "Training batch 361 completed. Loss: 0.7441, Accuracy: 0.5343\n",
            "Training batch 362 started.\n",
            "Training batch 362 completed. Loss: 0.7440, Accuracy: 0.5342\n",
            "Training batch 363 started.\n",
            "Training batch 363 completed. Loss: 0.7437, Accuracy: 0.5341\n",
            "Training batch 364 started.\n",
            "Training batch 364 completed. Loss: 0.7435, Accuracy: 0.5341\n",
            "Training batch 365 started.\n",
            "Training batch 365 completed. Loss: 0.7433, Accuracy: 0.5346\n",
            "Training batch 366 started.\n",
            "Training batch 366 completed. Loss: 0.7431, Accuracy: 0.5347\n",
            "Training batch 367 started.\n",
            "Training batch 367 completed. Loss: 0.7430, Accuracy: 0.5344\n",
            "Training batch 368 started.\n",
            "Training batch 368 completed. Loss: 0.7429, Accuracy: 0.5343\n",
            "Training batch 369 started.\n",
            "Training batch 369 completed. Loss: 0.7427, Accuracy: 0.5343\n",
            "Training batch 370 started.\n",
            "Training batch 370 completed. Loss: 0.7425, Accuracy: 0.5341\n",
            "Training batch 371 started.\n",
            "Training batch 371 completed. Loss: 0.7424, Accuracy: 0.5341\n",
            "Training batch 372 started.\n",
            "Training batch 372 completed. Loss: 0.7422, Accuracy: 0.5344\n",
            "Training batch 373 started.\n",
            "Training batch 373 completed. Loss: 0.7421, Accuracy: 0.5342\n",
            "Training batch 374 started.\n",
            "Training batch 374 completed. Loss: 0.7419, Accuracy: 0.5345\n",
            "Training batch 375 started.\n",
            "Training batch 375 completed. Loss: 0.7418, Accuracy: 0.5343\n",
            "Training batch 376 started.\n",
            "Training batch 376 completed. Loss: 0.7418, Accuracy: 0.5341\n",
            "Training batch 377 started.\n",
            "Training batch 377 completed. Loss: 0.7415, Accuracy: 0.5346\n",
            "Training batch 378 started.\n",
            "Training batch 378 completed. Loss: 0.7413, Accuracy: 0.5347\n",
            "Training batch 379 started.\n",
            "Training batch 379 completed. Loss: 0.7413, Accuracy: 0.5344\n",
            "Training batch 380 started.\n",
            "Training batch 380 completed. Loss: 0.7411, Accuracy: 0.5346\n",
            "Training batch 381 started.\n",
            "Training batch 381 completed. Loss: 0.7412, Accuracy: 0.5344\n",
            "Training batch 382 started.\n",
            "Training batch 382 completed. Loss: 0.7410, Accuracy: 0.5346\n",
            "Training batch 383 started.\n",
            "Training batch 383 completed. Loss: 0.7408, Accuracy: 0.5350\n",
            "Training batch 384 started.\n",
            "Training batch 384 completed. Loss: 0.7407, Accuracy: 0.5355\n",
            "Training batch 385 started.\n",
            "Training batch 385 completed. Loss: 0.7405, Accuracy: 0.5355\n",
            "Training batch 386 started.\n",
            "Training batch 386 completed. Loss: 0.7404, Accuracy: 0.5356\n",
            "Training batch 387 started.\n",
            "Training batch 387 completed. Loss: 0.7403, Accuracy: 0.5356\n",
            "Training batch 388 started.\n",
            "Training batch 388 completed. Loss: 0.7401, Accuracy: 0.5357\n",
            "Training batch 389 started.\n",
            "Training batch 389 completed. Loss: 0.7400, Accuracy: 0.5357\n",
            "Training batch 390 started.\n",
            "Training batch 390 completed. Loss: 0.7398, Accuracy: 0.5362\n",
            "Training batch 391 started.\n",
            "Training batch 391 completed. Loss: 0.7397, Accuracy: 0.5360\n",
            "Training batch 392 started.\n",
            "Training batch 392 completed. Loss: 0.7395, Accuracy: 0.5361\n",
            "Training batch 393 started.\n",
            "Training batch 393 completed. Loss: 0.7394, Accuracy: 0.5360\n",
            "Training batch 394 started.\n",
            "Training batch 394 completed. Loss: 0.7393, Accuracy: 0.5362\n",
            "Training batch 395 started.\n",
            "Training batch 395 completed. Loss: 0.7392, Accuracy: 0.5362\n",
            "Training batch 396 started.\n",
            "Training batch 396 completed. Loss: 0.7391, Accuracy: 0.5361\n",
            "Training batch 397 started.\n",
            "Training batch 397 completed. Loss: 0.7390, Accuracy: 0.5360\n",
            "Training batch 398 started.\n",
            "Training batch 398 completed. Loss: 0.7388, Accuracy: 0.5364\n",
            "Training batch 399 started.\n",
            "Training batch 399 completed. Loss: 0.7387, Accuracy: 0.5362\n",
            "Training batch 400 started.\n",
            "Training batch 400 completed. Loss: 0.7385, Accuracy: 0.5365\n",
            "Training batch 401 started.\n",
            "Training batch 401 completed. Loss: 0.7384, Accuracy: 0.5361\n",
            "Training batch 402 started.\n",
            "Training batch 402 completed. Loss: 0.7384, Accuracy: 0.5357\n",
            "Training batch 403 started.\n",
            "Training batch 403 completed. Loss: 0.7382, Accuracy: 0.5361\n",
            "Training batch 404 started.\n",
            "Training batch 404 completed. Loss: 0.7381, Accuracy: 0.5362\n",
            "Training batch 405 started.\n",
            "Training batch 405 completed. Loss: 0.7380, Accuracy: 0.5359\n",
            "Training batch 406 started.\n",
            "Training batch 406 completed. Loss: 0.7379, Accuracy: 0.5358\n",
            "Training batch 407 started.\n",
            "Training batch 407 completed. Loss: 0.7378, Accuracy: 0.5358\n",
            "Training batch 408 started.\n",
            "Training batch 408 completed. Loss: 0.7376, Accuracy: 0.5362\n",
            "Training batch 409 started.\n",
            "Training batch 409 completed. Loss: 0.7375, Accuracy: 0.5360\n",
            "Training batch 410 started.\n",
            "Training batch 410 completed. Loss: 0.7374, Accuracy: 0.5360\n",
            "Training batch 411 started.\n",
            "Training batch 411 completed. Loss: 0.7373, Accuracy: 0.5360\n",
            "Training batch 412 started.\n",
            "Training batch 412 completed. Loss: 0.7372, Accuracy: 0.5362\n",
            "Training batch 413 started.\n",
            "Training batch 413 completed. Loss: 0.7370, Accuracy: 0.5362\n",
            "Training batch 414 started.\n",
            "Training batch 414 completed. Loss: 0.7370, Accuracy: 0.5361\n",
            "Training batch 415 started.\n",
            "Training batch 415 completed. Loss: 0.7369, Accuracy: 0.5359\n",
            "Training batch 416 started.\n",
            "Training batch 416 completed. Loss: 0.7368, Accuracy: 0.5360\n",
            "Training batch 417 started.\n",
            "Training batch 417 completed. Loss: 0.7367, Accuracy: 0.5360\n",
            "Training batch 418 started.\n",
            "Training batch 418 completed. Loss: 0.7366, Accuracy: 0.5357\n",
            "Training batch 419 started.\n",
            "Training batch 419 completed. Loss: 0.7365, Accuracy: 0.5358\n",
            "Training batch 420 started.\n",
            "Training batch 420 completed. Loss: 0.7364, Accuracy: 0.5356\n",
            "Training batch 421 started.\n",
            "Training batch 421 completed. Loss: 0.7363, Accuracy: 0.5355\n",
            "Training batch 422 started.\n",
            "Training batch 422 completed. Loss: 0.7361, Accuracy: 0.5360\n",
            "Training batch 423 started.\n",
            "Training batch 423 completed. Loss: 0.7360, Accuracy: 0.5360\n",
            "Training batch 424 started.\n",
            "Training batch 424 completed. Loss: 0.7359, Accuracy: 0.5362\n",
            "Training batch 425 started.\n",
            "Training batch 425 completed. Loss: 0.7358, Accuracy: 0.5359\n",
            "Training batch 426 started.\n",
            "Training batch 426 completed. Loss: 0.7358, Accuracy: 0.5356\n",
            "Training batch 427 started.\n",
            "Training batch 427 completed. Loss: 0.7356, Accuracy: 0.5357\n",
            "Training batch 428 started.\n",
            "Training batch 428 completed. Loss: 0.7356, Accuracy: 0.5354\n",
            "Training batch 429 started.\n",
            "Training batch 429 completed. Loss: 0.7355, Accuracy: 0.5352\n",
            "Training batch 430 started.\n",
            "Training batch 430 completed. Loss: 0.7354, Accuracy: 0.5352\n",
            "Training batch 431 started.\n",
            "Training batch 431 completed. Loss: 0.7353, Accuracy: 0.5352\n",
            "Training batch 432 started.\n",
            "Training batch 432 completed. Loss: 0.7352, Accuracy: 0.5355\n",
            "Training batch 433 started.\n",
            "Training batch 433 completed. Loss: 0.7351, Accuracy: 0.5355\n",
            "Training batch 434 started.\n",
            "Training batch 434 completed. Loss: 0.7349, Accuracy: 0.5354\n",
            "Training batch 435 started.\n",
            "Training batch 435 completed. Loss: 0.7349, Accuracy: 0.5352\n",
            "Training batch 436 started.\n",
            "Training batch 436 completed. Loss: 0.7348, Accuracy: 0.5350\n",
            "Training batch 437 started.\n",
            "Training batch 437 completed. Loss: 0.7347, Accuracy: 0.5350\n",
            "Training batch 438 started.\n",
            "Training batch 438 completed. Loss: 0.7346, Accuracy: 0.5349\n",
            "Training batch 439 started.\n",
            "Training batch 439 completed. Loss: 0.7345, Accuracy: 0.5352\n",
            "Training batch 440 started.\n",
            "Training batch 440 completed. Loss: 0.7344, Accuracy: 0.5353\n",
            "Training batch 441 started.\n",
            "Training batch 441 completed. Loss: 0.7343, Accuracy: 0.5349\n",
            "Training batch 442 started.\n",
            "Training batch 442 completed. Loss: 0.7342, Accuracy: 0.5353\n",
            "Training batch 443 started.\n",
            "Training batch 443 completed. Loss: 0.7341, Accuracy: 0.5353\n",
            "Training batch 444 started.\n",
            "Training batch 444 completed. Loss: 0.7340, Accuracy: 0.5353\n",
            "Training batch 445 started.\n",
            "Training batch 445 completed. Loss: 0.7339, Accuracy: 0.5355\n",
            "Training batch 446 started.\n",
            "Training batch 446 completed. Loss: 0.7337, Accuracy: 0.5355\n",
            "Training batch 447 started.\n",
            "Training batch 447 completed. Loss: 0.7336, Accuracy: 0.5356\n",
            "Training batch 448 started.\n",
            "Training batch 448 completed. Loss: 0.7335, Accuracy: 0.5357\n",
            "Training batch 449 started.\n",
            "Training batch 449 completed. Loss: 0.7334, Accuracy: 0.5354\n",
            "Training batch 450 started.\n",
            "Training batch 450 completed. Loss: 0.7334, Accuracy: 0.5353\n",
            "Training batch 451 started.\n",
            "Training batch 451 completed. Loss: 0.7333, Accuracy: 0.5350\n",
            "Training batch 452 started.\n",
            "Training batch 452 completed. Loss: 0.7333, Accuracy: 0.5349\n",
            "Training batch 453 started.\n",
            "Training batch 453 completed. Loss: 0.7332, Accuracy: 0.5351\n",
            "Training batch 454 started.\n",
            "Training batch 454 completed. Loss: 0.7331, Accuracy: 0.5348\n",
            "Training batch 455 started.\n",
            "Training batch 455 completed. Loss: 0.7330, Accuracy: 0.5350\n",
            "Training batch 456 started.\n",
            "Training batch 456 completed. Loss: 0.7329, Accuracy: 0.5352\n",
            "Training batch 457 started.\n",
            "Training batch 457 completed. Loss: 0.7327, Accuracy: 0.5355\n",
            "Training batch 458 started.\n",
            "Training batch 458 completed. Loss: 0.7326, Accuracy: 0.5356\n",
            "Training batch 459 started.\n",
            "Training batch 459 completed. Loss: 0.7325, Accuracy: 0.5356\n",
            "Training batch 460 started.\n",
            "Training batch 460 completed. Loss: 0.7325, Accuracy: 0.5353\n",
            "Training batch 461 started.\n",
            "Training batch 461 completed. Loss: 0.7324, Accuracy: 0.5352\n",
            "Training batch 462 started.\n",
            "Training batch 462 completed. Loss: 0.7323, Accuracy: 0.5354\n",
            "Training batch 463 started.\n",
            "Training batch 463 completed. Loss: 0.7322, Accuracy: 0.5352\n",
            "Training batch 464 started.\n",
            "Training batch 464 completed. Loss: 0.7322, Accuracy: 0.5349\n",
            "Training batch 465 started.\n",
            "Training batch 465 completed. Loss: 0.7321, Accuracy: 0.5349\n",
            "Training batch 466 started.\n",
            "Training batch 466 completed. Loss: 0.7320, Accuracy: 0.5351\n",
            "Training batch 467 started.\n",
            "Training batch 467 completed. Loss: 0.7319, Accuracy: 0.5350\n",
            "Training batch 468 started.\n",
            "Training batch 468 completed. Loss: 0.7319, Accuracy: 0.5348\n",
            "Training batch 469 started.\n",
            "Training batch 469 completed. Loss: 0.7317, Accuracy: 0.5352\n",
            "Training batch 470 started.\n",
            "Training batch 470 completed. Loss: 0.7317, Accuracy: 0.5348\n",
            "Training batch 471 started.\n",
            "Training batch 471 completed. Loss: 0.7316, Accuracy: 0.5348\n",
            "Training batch 472 started.\n",
            "Training batch 472 completed. Loss: 0.7315, Accuracy: 0.5349\n",
            "Training batch 473 started.\n",
            "Training batch 473 completed. Loss: 0.7314, Accuracy: 0.5348\n",
            "Training batch 474 started.\n",
            "Training batch 474 completed. Loss: 0.7313, Accuracy: 0.5349\n",
            "Training batch 475 started.\n",
            "Training batch 475 completed. Loss: 0.7313, Accuracy: 0.5349\n",
            "Training batch 476 started.\n",
            "Training batch 476 completed. Loss: 0.7312, Accuracy: 0.5349\n",
            "Training batch 477 started.\n",
            "Training batch 477 completed. Loss: 0.7311, Accuracy: 0.5348\n",
            "Training batch 478 started.\n",
            "Training batch 478 completed. Loss: 0.7310, Accuracy: 0.5348\n",
            "Training batch 479 started.\n",
            "Training batch 479 completed. Loss: 0.7309, Accuracy: 0.5350\n",
            "Training batch 480 started.\n",
            "Training batch 480 completed. Loss: 0.7308, Accuracy: 0.5352\n",
            "Training batch 481 started.\n",
            "Training batch 481 completed. Loss: 0.7307, Accuracy: 0.5353\n",
            "Training batch 482 started.\n",
            "Training batch 482 completed. Loss: 0.7306, Accuracy: 0.5353\n",
            "Training batch 483 started.\n",
            "Training batch 483 completed. Loss: 0.7305, Accuracy: 0.5351\n",
            "Training batch 484 started.\n",
            "Training batch 484 completed. Loss: 0.7304, Accuracy: 0.5353\n",
            "Training batch 485 started.\n",
            "Training batch 485 completed. Loss: 0.7303, Accuracy: 0.5352\n",
            "Training batch 486 started.\n",
            "Training batch 486 completed. Loss: 0.7302, Accuracy: 0.5353\n",
            "Training batch 487 started.\n",
            "Training batch 487 completed. Loss: 0.7301, Accuracy: 0.5354\n",
            "Training batch 488 started.\n",
            "Training batch 488 completed. Loss: 0.7300, Accuracy: 0.5356\n",
            "Training batch 489 started.\n",
            "Training batch 489 completed. Loss: 0.7300, Accuracy: 0.5354\n",
            "Training batch 490 started.\n",
            "Training batch 490 completed. Loss: 0.7299, Accuracy: 0.5355\n",
            "Training batch 491 started.\n",
            "Training batch 491 completed. Loss: 0.7298, Accuracy: 0.5357\n",
            "Training batch 492 started.\n",
            "Training batch 492 completed. Loss: 0.7297, Accuracy: 0.5356\n",
            "Training batch 493 started.\n",
            "Training batch 493 completed. Loss: 0.7297, Accuracy: 0.5354\n",
            "Training batch 494 started.\n",
            "Training batch 494 completed. Loss: 0.7295, Accuracy: 0.5356\n",
            "Training batch 495 started.\n",
            "Training batch 495 completed. Loss: 0.7295, Accuracy: 0.5358\n",
            "Training batch 496 started.\n",
            "Training batch 496 completed. Loss: 0.7295, Accuracy: 0.5357\n",
            "Training batch 497 started.\n",
            "Training batch 497 completed. Loss: 0.7294, Accuracy: 0.5359\n",
            "Training batch 498 started.\n",
            "Training batch 498 completed. Loss: 0.7293, Accuracy: 0.5360\n",
            "Training batch 499 started.\n",
            "Training batch 499 completed. Loss: 0.7292, Accuracy: 0.5361\n",
            "Training batch 500 started.\n",
            "Training batch 500 completed. Loss: 0.7291, Accuracy: 0.5362\n",
            "Training batch 501 started.\n",
            "Training batch 501 completed. Loss: 0.7290, Accuracy: 0.5362\n",
            "Training batch 502 started.\n",
            "Training batch 502 completed. Loss: 0.7290, Accuracy: 0.5359\n",
            "Training batch 503 started.\n",
            "Training batch 503 completed. Loss: 0.7289, Accuracy: 0.5358\n",
            "Training batch 504 started.\n",
            "Training batch 504 completed. Loss: 0.7288, Accuracy: 0.5358\n",
            "Training batch 505 started.\n",
            "Training batch 505 completed. Loss: 0.7287, Accuracy: 0.5360\n",
            "Training batch 506 started.\n",
            "Training batch 506 completed. Loss: 0.7287, Accuracy: 0.5359\n",
            "Training batch 507 started.\n",
            "Training batch 507 completed. Loss: 0.7285, Accuracy: 0.5361\n",
            "Training batch 508 started.\n",
            "Training batch 508 completed. Loss: 0.7284, Accuracy: 0.5363\n",
            "Training batch 509 started.\n",
            "Training batch 509 completed. Loss: 0.7283, Accuracy: 0.5365\n",
            "Training batch 510 started.\n",
            "Training batch 510 completed. Loss: 0.7282, Accuracy: 0.5366\n",
            "Training batch 511 started.\n",
            "Training batch 511 completed. Loss: 0.7282, Accuracy: 0.5364\n",
            "Training batch 512 started.\n",
            "Training batch 512 completed. Loss: 0.7281, Accuracy: 0.5364\n",
            "Training batch 513 started.\n",
            "Training batch 513 completed. Loss: 0.7280, Accuracy: 0.5366\n",
            "Training batch 514 started.\n",
            "Training batch 514 completed. Loss: 0.7279, Accuracy: 0.5366\n",
            "Training batch 515 started.\n",
            "Training batch 515 completed. Loss: 0.7279, Accuracy: 0.5366\n",
            "Training batch 516 started.\n",
            "Training batch 516 completed. Loss: 0.7278, Accuracy: 0.5368\n",
            "Training batch 517 started.\n",
            "Training batch 517 completed. Loss: 0.7277, Accuracy: 0.5370\n",
            "Training batch 518 started.\n",
            "Training batch 518 completed. Loss: 0.7276, Accuracy: 0.5371\n",
            "Training batch 519 started.\n",
            "Training batch 519 completed. Loss: 0.7275, Accuracy: 0.5368\n",
            "Training batch 520 started.\n",
            "Training batch 520 completed. Loss: 0.7275, Accuracy: 0.5368\n",
            "Training batch 521 started.\n",
            "Training batch 521 completed. Loss: 0.7274, Accuracy: 0.5369\n",
            "Training batch 522 started.\n",
            "Training batch 522 completed. Loss: 0.7273, Accuracy: 0.5368\n",
            "Training batch 523 started.\n",
            "Training batch 523 completed. Loss: 0.7272, Accuracy: 0.5369\n",
            "Training batch 524 started.\n",
            "Training batch 524 completed. Loss: 0.7271, Accuracy: 0.5372\n",
            "Training batch 525 started.\n",
            "Training batch 525 completed. Loss: 0.7270, Accuracy: 0.5375\n",
            "Training batch 526 started.\n",
            "Training batch 526 completed. Loss: 0.7270, Accuracy: 0.5372\n",
            "Training batch 527 started.\n",
            "Training batch 527 completed. Loss: 0.7270, Accuracy: 0.5369\n",
            "Training batch 528 started.\n",
            "Training batch 528 completed. Loss: 0.7268, Accuracy: 0.5372\n",
            "Training batch 529 started.\n",
            "Training batch 529 completed. Loss: 0.7268, Accuracy: 0.5372\n",
            "Training batch 530 started.\n",
            "Training batch 530 completed. Loss: 0.7267, Accuracy: 0.5371\n",
            "Training batch 531 started.\n",
            "Training batch 531 completed. Loss: 0.7266, Accuracy: 0.5372\n",
            "Training batch 532 started.\n",
            "Training batch 532 completed. Loss: 0.7266, Accuracy: 0.5372\n",
            "Training batch 533 started.\n",
            "Training batch 533 completed. Loss: 0.7265, Accuracy: 0.5374\n",
            "Training batch 534 started.\n",
            "Training batch 534 completed. Loss: 0.7264, Accuracy: 0.5374\n",
            "Training batch 535 started.\n",
            "Training batch 535 completed. Loss: 0.7263, Accuracy: 0.5374\n",
            "Training batch 536 started.\n",
            "Training batch 536 completed. Loss: 0.7262, Accuracy: 0.5375\n",
            "Training batch 537 started.\n",
            "Training batch 537 completed. Loss: 0.7261, Accuracy: 0.5377\n",
            "Training batch 538 started.\n",
            "Training batch 538 completed. Loss: 0.7261, Accuracy: 0.5376\n",
            "Training batch 539 started.\n",
            "Training batch 539 completed. Loss: 0.7261, Accuracy: 0.5374\n",
            "Training batch 540 started.\n",
            "Training batch 540 completed. Loss: 0.7260, Accuracy: 0.5374\n",
            "Training batch 541 started.\n",
            "Training batch 541 completed. Loss: 0.7259, Accuracy: 0.5373\n",
            "Training batch 542 started.\n",
            "Training batch 542 completed. Loss: 0.7259, Accuracy: 0.5372\n",
            "Training batch 543 started.\n",
            "Training batch 543 completed. Loss: 0.7258, Accuracy: 0.5373\n",
            "Training batch 544 started.\n",
            "Training batch 544 completed. Loss: 0.7257, Accuracy: 0.5374\n",
            "Training batch 545 started.\n",
            "Training batch 545 completed. Loss: 0.7257, Accuracy: 0.5373\n",
            "Training batch 546 started.\n",
            "Training batch 546 completed. Loss: 0.7256, Accuracy: 0.5374\n",
            "Training batch 547 started.\n",
            "Training batch 547 completed. Loss: 0.7256, Accuracy: 0.5372\n",
            "Training batch 548 started.\n",
            "Training batch 548 completed. Loss: 0.7255, Accuracy: 0.5372\n",
            "Training batch 549 started.\n",
            "Training batch 549 completed. Loss: 0.7254, Accuracy: 0.5373\n",
            "Training batch 550 started.\n",
            "Training batch 550 completed. Loss: 0.7254, Accuracy: 0.5371\n",
            "Training batch 551 started.\n",
            "Training batch 551 completed. Loss: 0.7253, Accuracy: 0.5372\n",
            "Training batch 552 started.\n",
            "Training batch 552 completed. Loss: 0.7252, Accuracy: 0.5373\n",
            "Training batch 553 started.\n",
            "Training batch 553 completed. Loss: 0.7252, Accuracy: 0.5372\n",
            "Training batch 554 started.\n",
            "Training batch 554 completed. Loss: 0.7251, Accuracy: 0.5370\n",
            "Training batch 555 started.\n",
            "Training batch 555 completed. Loss: 0.7251, Accuracy: 0.5369\n",
            "Training batch 556 started.\n",
            "Training batch 556 completed. Loss: 0.7250, Accuracy: 0.5371\n",
            "Training batch 557 started.\n",
            "Training batch 557 completed. Loss: 0.7249, Accuracy: 0.5371\n",
            "Training batch 558 started.\n",
            "Training batch 558 completed. Loss: 0.7248, Accuracy: 0.5373\n",
            "Training batch 559 started.\n",
            "Training batch 559 completed. Loss: 0.7247, Accuracy: 0.5376\n",
            "Training batch 560 started.\n",
            "Training batch 560 completed. Loss: 0.7246, Accuracy: 0.5379\n",
            "Training batch 561 started.\n",
            "Training batch 561 completed. Loss: 0.7245, Accuracy: 0.5378\n",
            "Training batch 562 started.\n",
            "Training batch 562 completed. Loss: 0.7245, Accuracy: 0.5379\n",
            "Training batch 563 started.\n",
            "Training batch 563 completed. Loss: 0.7246, Accuracy: 0.5377\n",
            "Training batch 564 started.\n",
            "Training batch 564 completed. Loss: 0.7245, Accuracy: 0.5377\n",
            "Training batch 565 started.\n",
            "Training batch 565 completed. Loss: 0.7245, Accuracy: 0.5374\n",
            "Training batch 566 started.\n",
            "Training batch 566 completed. Loss: 0.7245, Accuracy: 0.5374\n",
            "Training batch 567 started.\n",
            "Training batch 567 completed. Loss: 0.7244, Accuracy: 0.5374\n",
            "Training batch 568 started.\n",
            "Training batch 568 completed. Loss: 0.7244, Accuracy: 0.5376\n",
            "Training batch 569 started.\n",
            "Training batch 569 completed. Loss: 0.7243, Accuracy: 0.5376\n",
            "Training batch 570 started.\n",
            "Training batch 570 completed. Loss: 0.7242, Accuracy: 0.5374\n",
            "Training batch 571 started.\n",
            "Training batch 571 completed. Loss: 0.7242, Accuracy: 0.5376\n",
            "Training batch 572 started.\n",
            "Training batch 572 completed. Loss: 0.7241, Accuracy: 0.5375\n",
            "Training batch 573 started.\n",
            "Training batch 573 completed. Loss: 0.7241, Accuracy: 0.5373\n",
            "Training batch 574 started.\n",
            "Training batch 574 completed. Loss: 0.7241, Accuracy: 0.5372\n",
            "Training batch 575 started.\n",
            "Training batch 575 completed. Loss: 0.7240, Accuracy: 0.5374\n",
            "Training batch 576 started.\n",
            "Training batch 576 completed. Loss: 0.7239, Accuracy: 0.5374\n",
            "Training batch 577 started.\n",
            "Training batch 577 completed. Loss: 0.7238, Accuracy: 0.5375\n",
            "Training batch 578 started.\n",
            "Training batch 578 completed. Loss: 0.7237, Accuracy: 0.5377\n",
            "Training batch 579 started.\n",
            "Training batch 579 completed. Loss: 0.7236, Accuracy: 0.5379\n",
            "Training batch 580 started.\n",
            "Training batch 580 completed. Loss: 0.7236, Accuracy: 0.5377\n",
            "Training batch 581 started.\n",
            "Training batch 581 completed. Loss: 0.7236, Accuracy: 0.5374\n",
            "Training batch 582 started.\n",
            "Training batch 582 completed. Loss: 0.7235, Accuracy: 0.5375\n",
            "Training batch 583 started.\n",
            "Training batch 583 completed. Loss: 0.7243, Accuracy: 0.5374\n",
            "Training batch 584 started.\n",
            "Training batch 584 completed. Loss: 0.7242, Accuracy: 0.5374\n",
            "Training batch 585 started.\n",
            "Training batch 585 completed. Loss: 0.7241, Accuracy: 0.5371\n",
            "Training batch 586 started.\n",
            "Training batch 586 completed. Loss: 0.7241, Accuracy: 0.5371\n",
            "Training batch 587 started.\n",
            "Training batch 587 completed. Loss: 0.7240, Accuracy: 0.5370\n",
            "Training batch 588 started.\n",
            "Training batch 588 completed. Loss: 0.7240, Accuracy: 0.5370\n",
            "Training batch 589 started.\n",
            "Training batch 589 completed. Loss: 0.7240, Accuracy: 0.5368\n",
            "Training batch 590 started.\n",
            "Training batch 590 completed. Loss: 0.7239, Accuracy: 0.5367\n",
            "Training batch 591 started.\n",
            "Training batch 591 completed. Loss: 0.7239, Accuracy: 0.5367\n",
            "Training batch 592 started.\n",
            "Training batch 592 completed. Loss: 0.7238, Accuracy: 0.5368\n",
            "Training batch 593 started.\n",
            "Training batch 593 completed. Loss: 0.7237, Accuracy: 0.5368\n",
            "Training batch 594 started.\n",
            "Training batch 594 completed. Loss: 0.7237, Accuracy: 0.5367\n",
            "Training batch 595 started.\n",
            "Training batch 595 completed. Loss: 0.7236, Accuracy: 0.5367\n",
            "Training batch 596 started.\n",
            "Training batch 596 completed. Loss: 0.7236, Accuracy: 0.5368\n",
            "Training batch 597 started.\n",
            "Training batch 597 completed. Loss: 0.7235, Accuracy: 0.5368\n",
            "Training batch 598 started.\n",
            "Training batch 598 completed. Loss: 0.7234, Accuracy: 0.5368\n",
            "Training batch 599 started.\n",
            "Training batch 599 completed. Loss: 0.7234, Accuracy: 0.5367\n",
            "Training batch 600 started.\n",
            "Training batch 600 completed. Loss: 0.7234, Accuracy: 0.5366\n",
            "Training batch 601 started.\n",
            "Training batch 601 completed. Loss: 0.7233, Accuracy: 0.5364\n",
            "Training batch 602 started.\n",
            "Training batch 602 completed. Loss: 0.7233, Accuracy: 0.5365\n",
            "Training batch 603 started.\n",
            "Training batch 603 completed. Loss: 0.7232, Accuracy: 0.5365\n",
            "Training batch 604 started.\n",
            "Training batch 604 completed. Loss: 0.7232, Accuracy: 0.5365\n",
            "Training batch 605 started.\n",
            "Training batch 605 completed. Loss: 0.7231, Accuracy: 0.5364\n",
            "Training batch 606 started.\n",
            "Training batch 606 completed. Loss: 0.7231, Accuracy: 0.5361\n",
            "Training batch 607 started.\n",
            "Training batch 607 completed. Loss: 0.7230, Accuracy: 0.5363\n",
            "Training batch 608 started.\n",
            "Training batch 608 completed. Loss: 0.7229, Accuracy: 0.5365\n",
            "Training batch 609 started.\n",
            "Training batch 609 completed. Loss: 0.7229, Accuracy: 0.5366\n",
            "Training batch 610 started.\n",
            "Training batch 610 completed. Loss: 0.7228, Accuracy: 0.5366\n",
            "Training batch 611 started.\n",
            "Training batch 611 completed. Loss: 0.7227, Accuracy: 0.5368\n",
            "Training batch 612 started.\n",
            "Training batch 612 completed. Loss: 0.7227, Accuracy: 0.5370\n",
            "Training batch 613 started.\n",
            "Training batch 613 completed. Loss: 0.7226, Accuracy: 0.5373\n",
            "Training batch 614 started.\n",
            "Training batch 614 completed. Loss: 0.7225, Accuracy: 0.5371\n",
            "Training batch 615 started.\n",
            "Training batch 615 completed. Loss: 0.7225, Accuracy: 0.5372\n",
            "Training batch 616 started.\n",
            "Training batch 616 completed. Loss: 0.7224, Accuracy: 0.5371\n",
            "Training batch 617 started.\n",
            "Training batch 617 completed. Loss: 0.7224, Accuracy: 0.5369\n",
            "Training batch 618 started.\n",
            "Training batch 618 completed. Loss: 0.7223, Accuracy: 0.5371\n",
            "Training batch 619 started.\n",
            "Training batch 619 completed. Loss: 0.7222, Accuracy: 0.5372\n",
            "Training batch 620 started.\n",
            "Training batch 620 completed. Loss: 0.7222, Accuracy: 0.5373\n",
            "Training batch 621 started.\n",
            "Training batch 621 completed. Loss: 0.7221, Accuracy: 0.5373\n",
            "Training batch 622 started.\n",
            "Training batch 622 completed. Loss: 0.7221, Accuracy: 0.5373\n",
            "Training batch 623 started.\n",
            "Training batch 623 completed. Loss: 0.7220, Accuracy: 0.5373\n",
            "Training batch 624 started.\n",
            "Training batch 624 completed. Loss: 0.7220, Accuracy: 0.5372\n",
            "Training batch 625 started.\n",
            "Training batch 625 completed. Loss: 0.7220, Accuracy: 0.5371\n",
            "Training batch 626 started.\n",
            "Training batch 626 completed. Loss: 0.7219, Accuracy: 0.5369\n",
            "Training batch 627 started.\n",
            "Training batch 627 completed. Loss: 0.7219, Accuracy: 0.5368\n",
            "Training batch 628 started.\n",
            "Training batch 628 completed. Loss: 0.7219, Accuracy: 0.5368\n",
            "Training batch 629 started.\n",
            "Training batch 629 completed. Loss: 0.7218, Accuracy: 0.5368\n",
            "Training batch 630 started.\n",
            "Training batch 630 completed. Loss: 0.7218, Accuracy: 0.5369\n",
            "Training batch 631 started.\n",
            "Training batch 631 completed. Loss: 0.7217, Accuracy: 0.5370\n",
            "Training batch 632 started.\n",
            "Training batch 632 completed. Loss: 0.7216, Accuracy: 0.5370\n",
            "Training batch 633 started.\n",
            "Training batch 633 completed. Loss: 0.7216, Accuracy: 0.5371\n",
            "Training batch 634 started.\n",
            "Training batch 634 completed. Loss: 0.7215, Accuracy: 0.5370\n",
            "Training batch 635 started.\n",
            "Training batch 635 completed. Loss: 0.7215, Accuracy: 0.5369\n",
            "Training batch 636 started.\n",
            "Training batch 636 completed. Loss: 0.7214, Accuracy: 0.5373\n",
            "Training batch 637 started.\n",
            "Training batch 637 completed. Loss: 0.7213, Accuracy: 0.5373\n",
            "Training batch 638 started.\n",
            "Training batch 638 completed. Loss: 0.7213, Accuracy: 0.5371\n",
            "Training batch 639 started.\n",
            "Training batch 639 completed. Loss: 0.7212, Accuracy: 0.5371\n",
            "Training batch 640 started.\n",
            "Training batch 640 completed. Loss: 0.7212, Accuracy: 0.5370\n",
            "Training batch 641 started.\n",
            "Training batch 641 completed. Loss: 0.7212, Accuracy: 0.5368\n",
            "Training batch 642 started.\n",
            "Training batch 642 completed. Loss: 0.7211, Accuracy: 0.5367\n",
            "Training batch 643 started.\n",
            "Training batch 643 completed. Loss: 0.7211, Accuracy: 0.5370\n",
            "Training batch 644 started.\n",
            "Training batch 644 completed. Loss: 0.7210, Accuracy: 0.5372\n",
            "Training batch 645 started.\n",
            "Training batch 645 completed. Loss: 0.7209, Accuracy: 0.5371\n",
            "Training batch 646 started.\n",
            "Training batch 646 completed. Loss: 0.7209, Accuracy: 0.5373\n",
            "Training batch 647 started.\n",
            "Training batch 647 completed. Loss: 0.7208, Accuracy: 0.5373\n",
            "Training batch 648 started.\n",
            "Training batch 648 completed. Loss: 0.7208, Accuracy: 0.5374\n",
            "Training batch 649 started.\n",
            "Training batch 649 completed. Loss: 0.7207, Accuracy: 0.5375\n",
            "Training batch 650 started.\n",
            "Training batch 650 completed. Loss: 0.7207, Accuracy: 0.5374\n",
            "Training batch 651 started.\n",
            "Training batch 651 completed. Loss: 0.7206, Accuracy: 0.5375\n",
            "Training batch 652 started.\n",
            "Training batch 652 completed. Loss: 0.7206, Accuracy: 0.5374\n",
            "Training batch 653 started.\n",
            "Training batch 653 completed. Loss: 0.7205, Accuracy: 0.5374\n",
            "Training batch 654 started.\n",
            "Training batch 654 completed. Loss: 0.7205, Accuracy: 0.5376\n",
            "Training batch 655 started.\n",
            "Training batch 655 completed. Loss: 0.7204, Accuracy: 0.5374\n",
            "Training batch 656 started.\n",
            "Training batch 656 completed. Loss: 0.7204, Accuracy: 0.5375\n",
            "Training batch 657 started.\n",
            "Training batch 657 completed. Loss: 0.7203, Accuracy: 0.5374\n",
            "Training batch 658 started.\n",
            "Training batch 658 completed. Loss: 0.7203, Accuracy: 0.5376\n",
            "Training batch 659 started.\n",
            "Training batch 659 completed. Loss: 0.7202, Accuracy: 0.5375\n",
            "Training batch 660 started.\n",
            "Training batch 660 completed. Loss: 0.7202, Accuracy: 0.5375\n",
            "Training batch 661 started.\n",
            "Training batch 661 completed. Loss: 0.7201, Accuracy: 0.5375\n",
            "Training batch 662 started.\n",
            "Training batch 662 completed. Loss: 0.7201, Accuracy: 0.5373\n",
            "Training batch 663 started.\n",
            "Training batch 663 completed. Loss: 0.7201, Accuracy: 0.5374\n",
            "Training batch 664 started.\n",
            "Training batch 664 completed. Loss: 0.7200, Accuracy: 0.5373\n",
            "Training batch 665 started.\n",
            "Training batch 665 completed. Loss: 0.7200, Accuracy: 0.5374\n",
            "Training batch 666 started.\n",
            "Training batch 666 completed. Loss: 0.7200, Accuracy: 0.5372\n",
            "Training batch 667 started.\n",
            "Training batch 667 completed. Loss: 0.7199, Accuracy: 0.5371\n",
            "Training batch 668 started.\n",
            "Training batch 668 completed. Loss: 0.7199, Accuracy: 0.5369\n",
            "Training batch 669 started.\n",
            "Training batch 669 completed. Loss: 0.7199, Accuracy: 0.5370\n",
            "Training batch 670 started.\n",
            "Training batch 670 completed. Loss: 0.7198, Accuracy: 0.5372\n",
            "Training batch 671 started.\n",
            "Training batch 671 completed. Loss: 0.7197, Accuracy: 0.5373\n",
            "Training batch 672 started.\n",
            "Training batch 672 completed. Loss: 0.7197, Accuracy: 0.5372\n",
            "Training batch 673 started.\n",
            "Training batch 673 completed. Loss: 0.7197, Accuracy: 0.5372\n",
            "Training batch 674 started.\n",
            "Training batch 674 completed. Loss: 0.7196, Accuracy: 0.5372\n",
            "Training batch 675 started.\n",
            "Training batch 675 completed. Loss: 0.7196, Accuracy: 0.5368\n",
            "Training batch 676 started.\n",
            "Training batch 676 completed. Loss: 0.7196, Accuracy: 0.5369\n",
            "Training batch 677 started.\n",
            "Training batch 677 completed. Loss: 0.7195, Accuracy: 0.5371\n",
            "Training batch 678 started.\n",
            "Training batch 678 completed. Loss: 0.7195, Accuracy: 0.5371\n",
            "Training batch 679 started.\n",
            "Training batch 679 completed. Loss: 0.7194, Accuracy: 0.5371\n",
            "Training batch 680 started.\n",
            "Training batch 680 completed. Loss: 0.7194, Accuracy: 0.5370\n",
            "Training batch 681 started.\n",
            "Training batch 681 completed. Loss: 0.7193, Accuracy: 0.5370\n",
            "Training batch 682 started.\n",
            "Training batch 682 completed. Loss: 0.7193, Accuracy: 0.5371\n",
            "Training batch 683 started.\n",
            "Training batch 683 completed. Loss: 0.7192, Accuracy: 0.5371\n",
            "Training batch 684 started.\n",
            "Training batch 684 completed. Loss: 0.7192, Accuracy: 0.5371\n",
            "Training batch 685 started.\n",
            "Training batch 685 completed. Loss: 0.7191, Accuracy: 0.5374\n",
            "Training batch 686 started.\n",
            "Training batch 686 completed. Loss: 0.7191, Accuracy: 0.5375\n",
            "Training batch 687 started.\n",
            "Training batch 687 completed. Loss: 0.7190, Accuracy: 0.5377\n",
            "Training batch 688 started.\n",
            "Training batch 688 completed. Loss: 0.7189, Accuracy: 0.5377\n",
            "Training batch 689 started.\n",
            "Training batch 689 completed. Loss: 0.7189, Accuracy: 0.5377\n",
            "Training batch 690 started.\n",
            "Training batch 690 completed. Loss: 0.7188, Accuracy: 0.5378\n",
            "Training batch 691 started.\n",
            "Training batch 691 completed. Loss: 0.7188, Accuracy: 0.5380\n",
            "Training batch 692 started.\n",
            "Training batch 692 completed. Loss: 0.7187, Accuracy: 0.5380\n",
            "Training batch 693 started.\n",
            "Training batch 693 completed. Loss: 0.7187, Accuracy: 0.5380\n",
            "Training batch 694 started.\n",
            "Training batch 694 completed. Loss: 0.7186, Accuracy: 0.5382\n",
            "Training batch 695 started.\n",
            "Training batch 695 completed. Loss: 0.7185, Accuracy: 0.5382\n",
            "Training batch 696 started.\n",
            "Training batch 696 completed. Loss: 0.7185, Accuracy: 0.5383\n",
            "Training batch 697 started.\n",
            "Training batch 697 completed. Loss: 0.7185, Accuracy: 0.5381\n",
            "Training batch 698 started.\n",
            "Training batch 698 completed. Loss: 0.7184, Accuracy: 0.5382\n",
            "Training batch 699 started.\n",
            "Training batch 699 completed. Loss: 0.7184, Accuracy: 0.5384\n",
            "Training batch 700 started.\n",
            "Training batch 700 completed. Loss: 0.7183, Accuracy: 0.5383\n",
            "Training batch 701 started.\n",
            "Training batch 701 completed. Loss: 0.7183, Accuracy: 0.5382\n",
            "Training batch 702 started.\n",
            "Training batch 702 completed. Loss: 0.7182, Accuracy: 0.5384\n",
            "Training batch 703 started.\n",
            "Training batch 703 completed. Loss: 0.7182, Accuracy: 0.5383\n",
            "Training batch 704 started.\n",
            "Training batch 704 completed. Loss: 0.7181, Accuracy: 0.5386\n",
            "Training batch 705 started.\n",
            "Training batch 705 completed. Loss: 0.7181, Accuracy: 0.5386\n",
            "Training batch 706 started.\n",
            "Training batch 706 completed. Loss: 0.7180, Accuracy: 0.5385\n",
            "Training batch 707 started.\n",
            "Training batch 707 completed. Loss: 0.7180, Accuracy: 0.5384\n",
            "Training batch 708 started.\n",
            "Training batch 708 completed. Loss: 0.7180, Accuracy: 0.5384\n",
            "Training batch 709 started.\n",
            "Training batch 709 completed. Loss: 0.7179, Accuracy: 0.5387\n",
            "Training batch 710 started.\n",
            "Training batch 710 completed. Loss: 0.7179, Accuracy: 0.5385\n",
            "Training batch 711 started.\n",
            "Training batch 711 completed. Loss: 0.7178, Accuracy: 0.5386\n",
            "Training batch 712 started.\n",
            "Training batch 712 completed. Loss: 0.7178, Accuracy: 0.5387\n",
            "Training batch 713 started.\n",
            "Training batch 713 completed. Loss: 0.7177, Accuracy: 0.5386\n",
            "Training batch 714 started.\n",
            "Training batch 714 completed. Loss: 0.7177, Accuracy: 0.5385\n",
            "Training batch 715 started.\n",
            "Training batch 715 completed. Loss: 0.7177, Accuracy: 0.5385\n",
            "Training batch 716 started.\n",
            "Training batch 716 completed. Loss: 0.7177, Accuracy: 0.5385\n",
            "Training batch 717 started.\n",
            "Training batch 717 completed. Loss: 0.7176, Accuracy: 0.5386\n",
            "Training batch 718 started.\n",
            "Training batch 718 completed. Loss: 0.7176, Accuracy: 0.5387\n",
            "Training batch 719 started.\n",
            "Training batch 719 completed. Loss: 0.7176, Accuracy: 0.5385\n",
            "Training batch 720 started.\n",
            "Training batch 720 completed. Loss: 0.7175, Accuracy: 0.5384\n",
            "Training batch 721 started.\n",
            "Training batch 721 completed. Loss: 0.7175, Accuracy: 0.5384\n",
            "Training batch 722 started.\n",
            "Training batch 722 completed. Loss: 0.7175, Accuracy: 0.5384\n",
            "Training batch 723 started.\n",
            "Training batch 723 completed. Loss: 0.7175, Accuracy: 0.5383\n",
            "Training batch 724 started.\n",
            "Training batch 724 completed. Loss: 0.7174, Accuracy: 0.5382\n",
            "Training batch 725 started.\n",
            "Training batch 725 completed. Loss: 0.7174, Accuracy: 0.5382\n",
            "Training batch 726 started.\n",
            "Training batch 726 completed. Loss: 0.7174, Accuracy: 0.5383\n",
            "Training batch 727 started.\n",
            "Training batch 727 completed. Loss: 0.7173, Accuracy: 0.5383\n",
            "Training batch 728 started.\n",
            "Training batch 728 completed. Loss: 0.7173, Accuracy: 0.5384\n",
            "Training batch 729 started.\n",
            "Training batch 729 completed. Loss: 0.7172, Accuracy: 0.5384\n",
            "Training batch 730 started.\n",
            "Training batch 730 completed. Loss: 0.7172, Accuracy: 0.5384\n",
            "Training batch 731 started.\n",
            "Training batch 731 completed. Loss: 0.7171, Accuracy: 0.5385\n",
            "Training batch 732 started.\n",
            "Training batch 732 completed. Loss: 0.7171, Accuracy: 0.5387\n",
            "Training batch 733 started.\n",
            "Training batch 733 completed. Loss: 0.7170, Accuracy: 0.5387\n",
            "Training batch 734 started.\n",
            "Training batch 734 completed. Loss: 0.7170, Accuracy: 0.5388\n",
            "Training batch 735 started.\n",
            "Training batch 735 completed. Loss: 0.7169, Accuracy: 0.5389\n",
            "Training batch 736 started.\n",
            "Training batch 736 completed. Loss: 0.7169, Accuracy: 0.5388\n",
            "Training batch 737 started.\n",
            "Training batch 737 completed. Loss: 0.7168, Accuracy: 0.5387\n",
            "Training batch 738 started.\n",
            "Training batch 738 completed. Loss: 0.7168, Accuracy: 0.5389\n",
            "Training batch 739 started.\n",
            "Training batch 739 completed. Loss: 0.7167, Accuracy: 0.5390\n",
            "Training batch 740 started.\n",
            "Training batch 740 completed. Loss: 0.7167, Accuracy: 0.5391\n",
            "Training batch 741 started.\n",
            "Training batch 741 completed. Loss: 0.7166, Accuracy: 0.5390\n",
            "Training batch 742 started.\n",
            "Training batch 742 completed. Loss: 0.7166, Accuracy: 0.5391\n",
            "Training batch 743 started.\n",
            "Training batch 743 completed. Loss: 0.7166, Accuracy: 0.5389\n",
            "Training batch 744 started.\n",
            "Training batch 744 completed. Loss: 0.7166, Accuracy: 0.5387\n",
            "Training batch 745 started.\n",
            "Training batch 745 completed. Loss: 0.7166, Accuracy: 0.5387\n",
            "Training batch 746 started.\n",
            "Training batch 746 completed. Loss: 0.7166, Accuracy: 0.5386\n",
            "Training batch 747 started.\n",
            "Training batch 747 completed. Loss: 0.7165, Accuracy: 0.5385\n",
            "Training batch 748 started.\n",
            "Training batch 748 completed. Loss: 0.7165, Accuracy: 0.5383\n",
            "Training batch 749 started.\n",
            "Training batch 749 completed. Loss: 0.7165, Accuracy: 0.5385\n",
            "Training batch 750 started.\n",
            "Training batch 750 completed. Loss: 0.7165, Accuracy: 0.5384\n",
            "Training batch 751 started.\n",
            "Training batch 751 completed. Loss: 0.7164, Accuracy: 0.5383\n",
            "Training batch 752 started.\n",
            "Training batch 752 completed. Loss: 0.7164, Accuracy: 0.5383\n",
            "Training batch 753 started.\n",
            "Training batch 753 completed. Loss: 0.7163, Accuracy: 0.5384\n",
            "Training batch 754 started.\n",
            "Training batch 754 completed. Loss: 0.7163, Accuracy: 0.5385\n",
            "Training batch 755 started.\n",
            "Training batch 755 completed. Loss: 0.7163, Accuracy: 0.5384\n",
            "Training batch 756 started.\n",
            "Training batch 756 completed. Loss: 0.7162, Accuracy: 0.5383\n",
            "Training batch 757 started.\n",
            "Training batch 757 completed. Loss: 0.7162, Accuracy: 0.5385\n",
            "Training batch 758 started.\n",
            "Training batch 758 completed. Loss: 0.7161, Accuracy: 0.5385\n",
            "Training batch 759 started.\n",
            "Training batch 759 completed. Loss: 0.7161, Accuracy: 0.5384\n",
            "Training batch 760 started.\n",
            "Training batch 760 completed. Loss: 0.7161, Accuracy: 0.5384\n",
            "Training batch 761 started.\n",
            "Training batch 761 completed. Loss: 0.7161, Accuracy: 0.5384\n",
            "Training batch 762 started.\n",
            "Training batch 762 completed. Loss: 0.7160, Accuracy: 0.5384\n",
            "Training batch 763 started.\n",
            "Training batch 763 completed. Loss: 0.7160, Accuracy: 0.5384\n",
            "Training batch 764 started.\n",
            "Training batch 764 completed. Loss: 0.7160, Accuracy: 0.5385\n",
            "Training batch 765 started.\n",
            "Training batch 765 completed. Loss: 0.7159, Accuracy: 0.5386\n",
            "Training batch 766 started.\n",
            "Training batch 766 completed. Loss: 0.7159, Accuracy: 0.5387\n",
            "Training batch 767 started.\n",
            "Training batch 767 completed. Loss: 0.7158, Accuracy: 0.5387\n",
            "Training batch 768 started.\n",
            "Training batch 768 completed. Loss: 0.7158, Accuracy: 0.5388\n",
            "Training batch 769 started.\n",
            "Training batch 769 completed. Loss: 0.7158, Accuracy: 0.5385\n",
            "Training batch 770 started.\n",
            "Training batch 770 completed. Loss: 0.7157, Accuracy: 0.5388\n",
            "Training batch 771 started.\n",
            "Training batch 771 completed. Loss: 0.7157, Accuracy: 0.5387\n",
            "Training batch 772 started.\n",
            "Training batch 772 completed. Loss: 0.7156, Accuracy: 0.5389\n",
            "Training batch 773 started.\n",
            "Training batch 773 completed. Loss: 0.7156, Accuracy: 0.5388\n",
            "Training batch 774 started.\n",
            "Training batch 774 completed. Loss: 0.7156, Accuracy: 0.5388\n",
            "Training batch 775 started.\n",
            "Training batch 775 completed. Loss: 0.7156, Accuracy: 0.5387\n",
            "Training batch 776 started.\n",
            "Training batch 776 completed. Loss: 0.7155, Accuracy: 0.5387\n",
            "Training batch 777 started.\n",
            "Training batch 777 completed. Loss: 0.7155, Accuracy: 0.5386\n",
            "Training batch 778 started.\n",
            "Training batch 778 completed. Loss: 0.7156, Accuracy: 0.5384\n",
            "Training batch 779 started.\n",
            "Training batch 779 completed. Loss: 0.7156, Accuracy: 0.5383\n",
            "Training batch 780 started.\n",
            "Training batch 780 completed. Loss: 0.7155, Accuracy: 0.5385\n",
            "Training batch 781 started.\n",
            "Training batch 781 completed. Loss: 0.7155, Accuracy: 0.5384\n",
            "Training batch 782 started.\n",
            "Training batch 782 completed. Loss: 0.7154, Accuracy: 0.5386\n",
            "Training batch 783 started.\n",
            "Training batch 783 completed. Loss: 0.7154, Accuracy: 0.5386\n",
            "Training batch 784 started.\n",
            "Training batch 784 completed. Loss: 0.7153, Accuracy: 0.5389\n",
            "Training batch 785 started.\n",
            "Training batch 785 completed. Loss: 0.7153, Accuracy: 0.5391\n",
            "Training batch 786 started.\n",
            "Training batch 786 completed. Loss: 0.7152, Accuracy: 0.5391\n",
            "Training batch 787 started.\n",
            "Training batch 787 completed. Loss: 0.7152, Accuracy: 0.5390\n",
            "Training batch 788 started.\n",
            "Training batch 788 completed. Loss: 0.7152, Accuracy: 0.5390\n",
            "Training batch 789 started.\n",
            "Training batch 789 completed. Loss: 0.7151, Accuracy: 0.5390\n",
            "Training batch 790 started.\n",
            "Training batch 790 completed. Loss: 0.7151, Accuracy: 0.5391\n",
            "Training batch 791 started.\n",
            "Training batch 791 completed. Loss: 0.7151, Accuracy: 0.5389\n",
            "Training batch 792 started.\n",
            "Training batch 792 completed. Loss: 0.7150, Accuracy: 0.5389\n",
            "Training batch 793 started.\n",
            "Training batch 793 completed. Loss: 0.7150, Accuracy: 0.5388\n",
            "Training batch 794 started.\n",
            "Training batch 794 completed. Loss: 0.7150, Accuracy: 0.5389\n",
            "Training batch 795 started.\n",
            "Training batch 795 completed. Loss: 0.7149, Accuracy: 0.5391\n",
            "Training batch 796 started.\n",
            "Training batch 796 completed. Loss: 0.7149, Accuracy: 0.5391\n",
            "Training batch 797 started.\n",
            "Training batch 797 completed. Loss: 0.7148, Accuracy: 0.5393\n",
            "Training batch 798 started.\n",
            "Training batch 798 completed. Loss: 0.7149, Accuracy: 0.5390\n",
            "Training batch 799 started.\n",
            "Training batch 799 completed. Loss: 0.7149, Accuracy: 0.5390\n",
            "Training batch 800 started.\n",
            "Training batch 800 completed. Loss: 0.7148, Accuracy: 0.5391\n",
            "Training batch 801 started.\n",
            "Training batch 801 completed. Loss: 0.7148, Accuracy: 0.5391\n",
            "Training batch 802 started.\n",
            "Training batch 802 completed. Loss: 0.7148, Accuracy: 0.5388\n",
            "Training batch 803 started.\n",
            "Training batch 803 completed. Loss: 0.7148, Accuracy: 0.5388\n",
            "Training batch 804 started.\n",
            "Training batch 804 completed. Loss: 0.7148, Accuracy: 0.5388\n",
            "Training batch 805 started.\n",
            "Training batch 805 completed. Loss: 0.7147, Accuracy: 0.5390\n",
            "Training batch 806 started.\n",
            "Training batch 806 completed. Loss: 0.7146, Accuracy: 0.5391\n",
            "Training batch 807 started.\n",
            "Training batch 807 completed. Loss: 0.7147, Accuracy: 0.5390\n",
            "Training batch 808 started.\n",
            "Training batch 808 completed. Loss: 0.7146, Accuracy: 0.5391\n",
            "Training batch 809 started.\n",
            "Training batch 809 completed. Loss: 0.7146, Accuracy: 0.5390\n",
            "Training batch 810 started.\n",
            "Training batch 810 completed. Loss: 0.7146, Accuracy: 0.5390\n",
            "Training batch 811 started.\n",
            "Training batch 811 completed. Loss: 0.7146, Accuracy: 0.5388\n",
            "Training batch 812 started.\n",
            "Training batch 812 completed. Loss: 0.7145, Accuracy: 0.5388\n",
            "Training batch 813 started.\n",
            "Training batch 813 completed. Loss: 0.7145, Accuracy: 0.5389\n",
            "Training batch 814 started.\n",
            "Training batch 814 completed. Loss: 0.7145, Accuracy: 0.5388\n",
            "Training batch 815 started.\n",
            "Training batch 815 completed. Loss: 0.7144, Accuracy: 0.5388\n",
            "Training batch 816 started.\n",
            "Training batch 816 completed. Loss: 0.7144, Accuracy: 0.5390\n",
            "Training batch 817 started.\n",
            "Training batch 817 completed. Loss: 0.7143, Accuracy: 0.5391\n",
            "Training batch 818 started.\n",
            "Training batch 818 completed. Loss: 0.7142, Accuracy: 0.5392\n",
            "Training batch 819 started.\n",
            "Training batch 819 completed. Loss: 0.7142, Accuracy: 0.5394\n",
            "Training batch 820 started.\n",
            "Training batch 820 completed. Loss: 0.7142, Accuracy: 0.5394\n",
            "Training batch 821 started.\n",
            "Training batch 821 completed. Loss: 0.7141, Accuracy: 0.5394\n",
            "Training batch 822 started.\n",
            "Training batch 822 completed. Loss: 0.7141, Accuracy: 0.5393\n",
            "Training batch 823 started.\n",
            "Training batch 823 completed. Loss: 0.7141, Accuracy: 0.5393\n",
            "Training batch 824 started.\n",
            "Training batch 824 completed. Loss: 0.7140, Accuracy: 0.5392\n",
            "Training batch 825 started.\n",
            "Training batch 825 completed. Loss: 0.7140, Accuracy: 0.5393\n",
            "Training batch 826 started.\n",
            "Training batch 826 completed. Loss: 0.7139, Accuracy: 0.5394\n",
            "Training batch 827 started.\n",
            "Training batch 827 completed. Loss: 0.7139, Accuracy: 0.5393\n",
            "Training batch 828 started.\n",
            "Training batch 828 completed. Loss: 0.7139, Accuracy: 0.5394\n",
            "Training batch 829 started.\n",
            "Training batch 829 completed. Loss: 0.7139, Accuracy: 0.5395\n",
            "Training batch 830 started.\n",
            "Training batch 830 completed. Loss: 0.7139, Accuracy: 0.5394\n",
            "Training batch 831 started.\n",
            "Training batch 831 completed. Loss: 0.7138, Accuracy: 0.5395\n",
            "Training batch 832 started.\n",
            "Training batch 832 completed. Loss: 0.7138, Accuracy: 0.5395\n",
            "Training batch 833 started.\n",
            "Training batch 833 completed. Loss: 0.7137, Accuracy: 0.5393\n",
            "Training batch 834 started.\n",
            "Training batch 834 completed. Loss: 0.7137, Accuracy: 0.5394\n",
            "Training batch 835 started.\n",
            "Training batch 835 completed. Loss: 0.7137, Accuracy: 0.5394\n",
            "Training batch 836 started.\n",
            "Training batch 836 completed. Loss: 0.7137, Accuracy: 0.5395\n",
            "Training batch 837 started.\n",
            "Training batch 837 completed. Loss: 0.7136, Accuracy: 0.5396\n",
            "Training batch 838 started.\n",
            "Training batch 838 completed. Loss: 0.7136, Accuracy: 0.5395\n",
            "Training batch 839 started.\n",
            "Training batch 839 completed. Loss: 0.7135, Accuracy: 0.5396\n",
            "Training batch 840 started.\n",
            "Training batch 840 completed. Loss: 0.7135, Accuracy: 0.5397\n",
            "Training batch 841 started.\n",
            "Training batch 841 completed. Loss: 0.7135, Accuracy: 0.5396\n",
            "Training batch 842 started.\n",
            "Training batch 842 completed. Loss: 0.7135, Accuracy: 0.5397\n",
            "Training batch 843 started.\n",
            "Training batch 843 completed. Loss: 0.7135, Accuracy: 0.5397\n",
            "Training batch 844 started.\n",
            "Training batch 844 completed. Loss: 0.7135, Accuracy: 0.5396\n",
            "Training batch 845 started.\n",
            "Training batch 845 completed. Loss: 0.7134, Accuracy: 0.5395\n",
            "Training batch 846 started.\n",
            "Training batch 846 completed. Loss: 0.7134, Accuracy: 0.5394\n",
            "Training batch 847 started.\n",
            "Training batch 847 completed. Loss: 0.7134, Accuracy: 0.5394\n",
            "Training batch 848 started.\n",
            "Training batch 848 completed. Loss: 0.7134, Accuracy: 0.5395\n",
            "Training batch 849 started.\n",
            "Training batch 849 completed. Loss: 0.7133, Accuracy: 0.5397\n",
            "Training batch 850 started.\n",
            "Training batch 850 completed. Loss: 0.7133, Accuracy: 0.5397\n",
            "Training batch 851 started.\n",
            "Training batch 851 completed. Loss: 0.7132, Accuracy: 0.5397\n",
            "Training batch 852 started.\n",
            "Training batch 852 completed. Loss: 0.7132, Accuracy: 0.5396\n",
            "Training batch 853 started.\n",
            "Training batch 853 completed. Loss: 0.7132, Accuracy: 0.5396\n",
            "Training batch 854 started.\n",
            "Training batch 854 completed. Loss: 0.7132, Accuracy: 0.5394\n",
            "Training batch 855 started.\n",
            "Training batch 855 completed. Loss: 0.7131, Accuracy: 0.5395\n",
            "Training batch 856 started.\n",
            "Training batch 856 completed. Loss: 0.7131, Accuracy: 0.5395\n",
            "Training batch 857 started.\n",
            "Training batch 857 completed. Loss: 0.7131, Accuracy: 0.5396\n",
            "Training batch 858 started.\n",
            "Training batch 858 completed. Loss: 0.7130, Accuracy: 0.5397\n",
            "Training batch 859 started.\n",
            "Training batch 859 completed. Loss: 0.7130, Accuracy: 0.5398\n",
            "Training batch 860 started.\n",
            "Training batch 860 completed. Loss: 0.7130, Accuracy: 0.5399\n",
            "Training batch 861 started.\n",
            "Training batch 861 completed. Loss: 0.7129, Accuracy: 0.5397\n",
            "Training batch 862 started.\n",
            "Training batch 862 completed. Loss: 0.7129, Accuracy: 0.5396\n",
            "Training batch 863 started.\n",
            "Training batch 863 completed. Loss: 0.7129, Accuracy: 0.5394\n",
            "Training batch 864 started.\n",
            "Training batch 864 completed. Loss: 0.7129, Accuracy: 0.5393\n",
            "Training batch 865 started.\n",
            "Training batch 865 completed. Loss: 0.7129, Accuracy: 0.5393\n",
            "Training batch 866 started.\n",
            "Training batch 866 completed. Loss: 0.7129, Accuracy: 0.5393\n",
            "Training batch 867 started.\n",
            "Training batch 867 completed. Loss: 0.7129, Accuracy: 0.5393\n",
            "Training batch 868 started.\n",
            "Training batch 868 completed. Loss: 0.7128, Accuracy: 0.5394\n",
            "Training batch 869 started.\n",
            "Training batch 869 completed. Loss: 0.7128, Accuracy: 0.5394\n",
            "Training batch 870 started.\n",
            "Training batch 870 completed. Loss: 0.7127, Accuracy: 0.5394\n",
            "Training batch 871 started.\n",
            "Training batch 871 completed. Loss: 0.7127, Accuracy: 0.5395\n",
            "Training batch 872 started.\n",
            "Training batch 872 completed. Loss: 0.7127, Accuracy: 0.5396\n",
            "Training batch 873 started.\n",
            "Training batch 873 completed. Loss: 0.7126, Accuracy: 0.5395\n",
            "Training batch 874 started.\n",
            "Training batch 874 completed. Loss: 0.7126, Accuracy: 0.5396\n",
            "Training batch 875 started.\n",
            "Training batch 875 completed. Loss: 0.7126, Accuracy: 0.5395\n",
            "Training batch 876 started.\n",
            "Training batch 876 completed. Loss: 0.7126, Accuracy: 0.5394\n",
            "Training batch 877 started.\n",
            "Training batch 877 completed. Loss: 0.7125, Accuracy: 0.5395\n",
            "Training batch 878 started.\n",
            "Training batch 878 completed. Loss: 0.7125, Accuracy: 0.5392\n",
            "Training batch 879 started.\n",
            "Training batch 879 completed. Loss: 0.7126, Accuracy: 0.5392\n",
            "Training batch 880 started.\n",
            "Training batch 880 completed. Loss: 0.7126, Accuracy: 0.5390\n",
            "Training batch 881 started.\n",
            "Training batch 881 completed. Loss: 0.7126, Accuracy: 0.5389\n",
            "Training batch 882 started.\n",
            "Training batch 882 completed. Loss: 0.7125, Accuracy: 0.5390\n",
            "Training batch 883 started.\n",
            "Training batch 883 completed. Loss: 0.7126, Accuracy: 0.5389\n",
            "Training batch 884 started.\n",
            "Training batch 885 completed. Loss: 0.7125, Accuracy: 0.5388\n",
            "Training batch 886 started.\n",
            "Training batch 886 completed. Loss: 0.7124, Accuracy: 0.5390\n",
            "Training batch 887 started.\n",
            "Training batch 887 completed. Loss: 0.7124, Accuracy: 0.5391\n",
            "Training batch 888 started.\n",
            "Training batch 888 completed. Loss: 0.7124, Accuracy: 0.5392\n",
            "Training batch 889 started.\n",
            "Training batch 889 completed. Loss: 0.7123, Accuracy: 0.5393\n",
            "Training batch 890 started.\n",
            "Training batch 890 completed. Loss: 0.7123, Accuracy: 0.5392\n",
            "Training batch 891 started.\n",
            "Training batch 891 completed. Loss: 0.7123, Accuracy: 0.5394\n",
            "Training batch 892 started.\n",
            "Training batch 892 completed. Loss: 0.7123, Accuracy: 0.5394\n",
            "Training batch 893 started.\n",
            "Training batch 893 completed. Loss: 0.7122, Accuracy: 0.5395\n",
            "Training batch 894 started.\n",
            "Training batch 894 completed. Loss: 0.7122, Accuracy: 0.5396\n",
            "Training batch 895 started.\n",
            "Training batch 895 completed. Loss: 0.7121, Accuracy: 0.5397\n",
            "Training batch 896 started.\n",
            "Training batch 896 completed. Loss: 0.7121, Accuracy: 0.5398\n",
            "Training batch 897 started.\n",
            "Training batch 897 completed. Loss: 0.7121, Accuracy: 0.5397\n",
            "Training batch 898 started.\n",
            "Training batch 898 completed. Loss: 0.7120, Accuracy: 0.5398\n",
            "Training batch 899 started.\n",
            "Training batch 899 completed. Loss: 0.7120, Accuracy: 0.5398\n",
            "Training batch 900 started.\n",
            "Training batch 900 completed. Loss: 0.7120, Accuracy: 0.5399\n",
            "Training batch 901 started.\n",
            "Training batch 901 completed. Loss: 0.7119, Accuracy: 0.5400\n",
            "Training batch 902 started.\n",
            "Training batch 902 completed. Loss: 0.7119, Accuracy: 0.5399\n",
            "Training batch 903 started.\n",
            "Training batch 903 completed. Loss: 0.7119, Accuracy: 0.5399\n",
            "Training batch 904 started.\n",
            "Training batch 904 completed. Loss: 0.7119, Accuracy: 0.5400\n",
            "Training batch 905 started.\n",
            "Training batch 905 completed. Loss: 0.7119, Accuracy: 0.5399\n",
            "Training batch 906 started.\n",
            "Training batch 906 completed. Loss: 0.7119, Accuracy: 0.5398\n",
            "Training batch 907 started.\n",
            "Training batch 907 completed. Loss: 0.7119, Accuracy: 0.5397\n",
            "Training batch 908 started.\n",
            "Training batch 908 completed. Loss: 0.7118, Accuracy: 0.5397\n",
            "Training batch 909 started.\n",
            "Training batch 909 completed. Loss: 0.7118, Accuracy: 0.5397\n",
            "Training batch 910 started.\n",
            "Training batch 910 completed. Loss: 0.7118, Accuracy: 0.5395\n",
            "Training batch 911 started.\n",
            "Training batch 911 completed. Loss: 0.7118, Accuracy: 0.5396\n",
            "Training batch 912 started.\n",
            "Training batch 912 completed. Loss: 0.7118, Accuracy: 0.5395\n",
            "Training batch 913 started.\n",
            "Training batch 913 completed. Loss: 0.7117, Accuracy: 0.5396\n",
            "Training batch 914 started.\n",
            "Training batch 914 completed. Loss: 0.7117, Accuracy: 0.5395\n",
            "Training batch 915 started.\n",
            "Training batch 915 completed. Loss: 0.7117, Accuracy: 0.5396\n",
            "Training batch 916 started.\n",
            "Training batch 916 completed. Loss: 0.7117, Accuracy: 0.5396\n",
            "Training batch 917 started.\n",
            "Training batch 917 completed. Loss: 0.7116, Accuracy: 0.5396\n",
            "Training batch 918 started.\n",
            "Training batch 918 completed. Loss: 0.7116, Accuracy: 0.5396\n",
            "Training batch 919 started.\n",
            "Training batch 919 completed. Loss: 0.7116, Accuracy: 0.5396\n",
            "Training batch 920 started.\n",
            "Training batch 920 completed. Loss: 0.7116, Accuracy: 0.5396\n",
            "Training batch 921 started.\n",
            "Training batch 921 completed. Loss: 0.7116, Accuracy: 0.5395\n",
            "Training batch 922 started.\n",
            "Training batch 922 completed. Loss: 0.7115, Accuracy: 0.5394\n",
            "Training batch 923 started.\n",
            "Training batch 923 completed. Loss: 0.7115, Accuracy: 0.5394\n",
            "Training batch 924 started.\n",
            "Training batch 924 completed. Loss: 0.7115, Accuracy: 0.5394\n",
            "Training batch 925 started.\n",
            "Training batch 925 completed. Loss: 0.7115, Accuracy: 0.5394\n",
            "Training batch 926 started.\n",
            "Training batch 926 completed. Loss: 0.7114, Accuracy: 0.5395\n",
            "Training batch 927 started.\n",
            "Training batch 927 completed. Loss: 0.7114, Accuracy: 0.5395\n",
            "Training batch 928 started.\n",
            "Training batch 928 completed. Loss: 0.7114, Accuracy: 0.5394\n",
            "Training batch 929 started.\n",
            "Training batch 929 completed. Loss: 0.7113, Accuracy: 0.5393\n",
            "Training batch 930 started.\n",
            "Training batch 930 completed. Loss: 0.7113, Accuracy: 0.5394\n",
            "Training batch 931 started.\n",
            "Training batch 931 completed. Loss: 0.7113, Accuracy: 0.5394\n",
            "Training batch 932 started.\n",
            "Training batch 932 completed. Loss: 0.7113, Accuracy: 0.5394\n",
            "Training batch 933 started.\n",
            "Training batch 933 completed. Loss: 0.7112, Accuracy: 0.5394\n",
            "Training batch 934 started.\n",
            "Training batch 934 completed. Loss: 0.7112, Accuracy: 0.5393\n",
            "Training batch 935 started.\n",
            "Training batch 935 completed. Loss: 0.7112, Accuracy: 0.5395\n",
            "Training batch 936 started.\n",
            "Training batch 936 completed. Loss: 0.7112, Accuracy: 0.5395\n",
            "Training batch 937 started.\n",
            "Training batch 937 completed. Loss: 0.7112, Accuracy: 0.5394\n",
            "Training batch 938 started.\n",
            "Training batch 938 completed. Loss: 0.7112, Accuracy: 0.5392\n",
            "Training batch 939 started.\n",
            "Training batch 939 completed. Loss: 0.7111, Accuracy: 0.5392\n",
            "Training batch 940 started.\n",
            "Training batch 940 completed. Loss: 0.7111, Accuracy: 0.5391\n",
            "Training batch 941 started.\n",
            "Training batch 941 completed. Loss: 0.7111, Accuracy: 0.5390\n",
            "Training batch 942 started.\n",
            "Training batch 942 completed. Loss: 0.7111, Accuracy: 0.5389\n",
            "Training batch 943 started.\n",
            "Training batch 943 completed. Loss: 0.7111, Accuracy: 0.5389\n",
            "Training batch 944 started.\n",
            "Training batch 944 completed. Loss: 0.7110, Accuracy: 0.5390\n",
            "Training batch 945 started.\n",
            "Training batch 945 completed. Loss: 0.7110, Accuracy: 0.5391\n",
            "Training batch 946 started.\n",
            "Training batch 946 completed. Loss: 0.7110, Accuracy: 0.5391\n",
            "Training batch 947 started.\n",
            "Training batch 947 completed. Loss: 0.7109, Accuracy: 0.5391\n",
            "Training batch 948 started.\n",
            "Training batch 948 completed. Loss: 0.7109, Accuracy: 0.5393\n",
            "Training batch 949 started.\n",
            "Training batch 949 completed. Loss: 0.7109, Accuracy: 0.5393\n",
            "Training batch 950 started.\n",
            "Training batch 950 completed. Loss: 0.7108, Accuracy: 0.5394\n",
            "Training batch 951 started.\n",
            "Training batch 951 completed. Loss: 0.7108, Accuracy: 0.5395\n",
            "Training batch 952 started.\n",
            "Training batch 952 completed. Loss: 0.7108, Accuracy: 0.5394\n",
            "Training batch 953 started.\n",
            "Training batch 953 completed. Loss: 0.7108, Accuracy: 0.5395\n",
            "Training batch 954 started.\n",
            "Training batch 954 completed. Loss: 0.7107, Accuracy: 0.5395\n",
            "Training batch 955 started.\n",
            "Training batch 955 completed. Loss: 0.7107, Accuracy: 0.5395\n",
            "Training batch 956 started.\n",
            "Training batch 956 completed. Loss: 0.7107, Accuracy: 0.5396\n",
            "Training batch 957 started.\n",
            "Training batch 957 completed. Loss: 0.7107, Accuracy: 0.5395\n",
            "Training batch 958 started.\n",
            "Training batch 958 completed. Loss: 0.7106, Accuracy: 0.5395\n",
            "Training batch 959 started.\n",
            "Training batch 959 completed. Loss: 0.7106, Accuracy: 0.5394\n",
            "Training batch 960 started.\n",
            "Training batch 960 completed. Loss: 0.7106, Accuracy: 0.5395\n",
            "Training batch 961 started.\n",
            "Training batch 961 completed. Loss: 0.7106, Accuracy: 0.5396\n",
            "Training batch 962 started.\n",
            "Training batch 962 completed. Loss: 0.7106, Accuracy: 0.5395\n",
            "Training batch 963 started.\n",
            "Training batch 963 completed. Loss: 0.7105, Accuracy: 0.5396\n",
            "Training batch 964 started.\n",
            "Training batch 964 completed. Loss: 0.7105, Accuracy: 0.5397\n",
            "Training batch 965 started.\n",
            "Training batch 965 completed. Loss: 0.7104, Accuracy: 0.5398\n",
            "Training batch 966 started.\n",
            "Training batch 966 completed. Loss: 0.7104, Accuracy: 0.5399\n",
            "Training batch 967 started.\n",
            "Training batch 967 completed. Loss: 0.7103, Accuracy: 0.5401\n",
            "Training batch 968 started.\n",
            "Training batch 968 completed. Loss: 0.7103, Accuracy: 0.5403\n",
            "Training batch 969 started.\n",
            "Training batch 969 completed. Loss: 0.7103, Accuracy: 0.5404\n",
            "Training batch 970 started.\n",
            "Training batch 970 completed. Loss: 0.7102, Accuracy: 0.5404\n",
            "Training batch 971 started.\n",
            "Training batch 971 completed. Loss: 0.7102, Accuracy: 0.5403\n",
            "Training batch 972 started.\n",
            "Training batch 972 completed. Loss: 0.7102, Accuracy: 0.5404\n",
            "Training batch 973 started.\n",
            "Training batch 973 completed. Loss: 0.7101, Accuracy: 0.5405\n",
            "Training batch 974 started.\n",
            "Training batch 974 completed. Loss: 0.7101, Accuracy: 0.5405\n",
            "Training batch 975 started.\n",
            "Training batch 975 completed. Loss: 0.7101, Accuracy: 0.5404\n",
            "Training batch 976 started.\n",
            "Training batch 976 completed. Loss: 0.7101, Accuracy: 0.5404\n",
            "Training batch 977 started.\n",
            "Training batch 977 completed. Loss: 0.7100, Accuracy: 0.5404\n",
            "Training batch 978 started.\n",
            "Training batch 978 completed. Loss: 0.7100, Accuracy: 0.5402\n",
            "Training batch 979 started.\n",
            "Training batch 979 completed. Loss: 0.7100, Accuracy: 0.5402\n",
            "Training batch 980 started.\n",
            "Training batch 980 completed. Loss: 0.7100, Accuracy: 0.5401\n",
            "Training batch 981 started.\n",
            "Training batch 981 completed. Loss: 0.7099, Accuracy: 0.5400\n",
            "Training batch 982 started.\n",
            "Training batch 982 completed. Loss: 0.7099, Accuracy: 0.5401\n",
            "Training batch 983 started.\n",
            "Training batch 983 completed. Loss: 0.7099, Accuracy: 0.5400\n",
            "Training batch 984 started.\n",
            "Training batch 984 completed. Loss: 0.7099, Accuracy: 0.5401\n",
            "Training batch 985 started.\n",
            "Training batch 985 completed. Loss: 0.7099, Accuracy: 0.5403\n",
            "Training batch 986 started.\n",
            "Training batch 986 completed. Loss: 0.7099, Accuracy: 0.5403\n",
            "Training batch 987 started.\n",
            "Training batch 987 completed. Loss: 0.7098, Accuracy: 0.5403\n",
            "Training batch 988 started.\n",
            "Training batch 988 completed. Loss: 0.7098, Accuracy: 0.5403\n",
            "Training batch 989 started.\n",
            "Training batch 989 completed. Loss: 0.7098, Accuracy: 0.5401\n",
            "Training batch 990 started.\n",
            "Training batch 990 completed. Loss: 0.7098, Accuracy: 0.5401\n",
            "Training batch 991 started.\n",
            "Training batch 991 completed. Loss: 0.7098, Accuracy: 0.5400\n",
            "Training batch 992 started.\n",
            "Training batch 992 completed. Loss: 0.7098, Accuracy: 0.5400\n",
            "Training batch 993 started.\n",
            "Training batch 993 completed. Loss: 0.7097, Accuracy: 0.5400\n",
            "Training batch 994 started.\n",
            "Training batch 994 completed. Loss: 0.7097, Accuracy: 0.5401\n",
            "Training batch 995 started.\n",
            "Training batch 995 completed. Loss: 0.7096, Accuracy: 0.5401\n",
            "Training batch 996 started.\n",
            "Training batch 996 completed. Loss: 0.7096, Accuracy: 0.5402\n",
            "Training batch 997 started.\n",
            "Training batch 997 completed. Loss: 0.7096, Accuracy: 0.5401\n",
            "Training batch 998 started.\n",
            "Training batch 998 completed. Loss: 0.7096, Accuracy: 0.5402\n",
            "Training batch 999 started.\n",
            "Training batch 999 completed. Loss: 0.7096, Accuracy: 0.5402\n",
            "Training batch 1000 started.\n",
            "Training batch 1000 completed. Loss: 0.7095, Accuracy: 0.5401\n",
            "Training batch 1001 started.\n",
            "Training batch 1001 completed. Loss: 0.7095, Accuracy: 0.5401\n",
            "Training batch 1002 started.\n",
            "Training batch 1002 completed. Loss: 0.7095, Accuracy: 0.5402\n",
            "Training batch 1003 started.\n",
            "Training batch 1003 completed. Loss: 0.7095, Accuracy: 0.5402\n",
            "Training batch 1004 started.\n",
            "Training batch 1004 completed. Loss: 0.7095, Accuracy: 0.5401\n",
            "Training batch 1005 started.\n",
            "Training batch 1005 completed. Loss: 0.7094, Accuracy: 0.5403\n",
            "Training batch 1006 started.\n",
            "Training batch 1006 completed. Loss: 0.7094, Accuracy: 0.5406\n",
            "Training batch 1007 started.\n",
            "Training batch 1007 completed. Loss: 0.7094, Accuracy: 0.5406\n",
            "Training batch 1008 started.\n",
            "Training batch 1008 completed. Loss: 0.7093, Accuracy: 0.5408\n",
            "Training batch 1009 started.\n",
            "Training batch 1009 completed. Loss: 0.7093, Accuracy: 0.5408\n",
            "Training batch 1010 started.\n",
            "Training batch 1010 completed. Loss: 0.7092, Accuracy: 0.5408\n",
            "Training batch 1011 started.\n",
            "Training batch 1011 completed. Loss: 0.7092, Accuracy: 0.5409\n",
            "Training batch 1012 started.\n",
            "Training batch 1012 completed. Loss: 0.7092, Accuracy: 0.5409\n",
            "Training batch 1013 started.\n",
            "Training batch 1013 completed. Loss: 0.7092, Accuracy: 0.5409\n",
            "Training batch 1014 started.\n",
            "Training batch 1014 completed. Loss: 0.7092, Accuracy: 0.5408\n",
            "Training batch 1015 started.\n",
            "Training batch 1015 completed. Loss: 0.7091, Accuracy: 0.5408\n",
            "Training batch 1016 started.\n",
            "Training batch 1016 completed. Loss: 0.7091, Accuracy: 0.5409\n",
            "Training batch 1017 started.\n",
            "Training batch 1017 completed. Loss: 0.7091, Accuracy: 0.5408\n",
            "Training batch 1018 started.\n",
            "Training batch 1018 completed. Loss: 0.7090, Accuracy: 0.5408\n",
            "Training batch 1019 started.\n",
            "Training batch 1019 completed. Loss: 0.7090, Accuracy: 0.5411\n",
            "Training batch 1020 started.\n",
            "Training batch 1020 completed. Loss: 0.7089, Accuracy: 0.5412\n",
            "Training batch 1021 started.\n",
            "Training batch 1021 completed. Loss: 0.7089, Accuracy: 0.5412\n",
            "Training batch 1022 started.\n",
            "Training batch 1022 completed. Loss: 0.7089, Accuracy: 0.5412\n",
            "Training batch 1023 started.\n",
            "Training batch 1023 completed. Loss: 0.7088, Accuracy: 0.5414\n",
            "Training batch 1024 started.\n",
            "Training batch 1024 completed. Loss: 0.7088, Accuracy: 0.5415\n",
            "Training batch 1025 started.\n",
            "Training batch 1025 completed. Loss: 0.7088, Accuracy: 0.5415\n",
            "Training batch 1026 started.\n",
            "Training batch 1026 completed. Loss: 0.7088, Accuracy: 0.5415\n",
            "Training batch 1027 started.\n",
            "Training batch 1027 completed. Loss: 0.7087, Accuracy: 0.5416\n",
            "Training batch 1028 started.\n",
            "Training batch 1028 completed. Loss: 0.7087, Accuracy: 0.5416\n",
            "Training batch 1029 started.\n",
            "Training batch 1029 completed. Loss: 0.7087, Accuracy: 0.5416\n",
            "Training batch 1030 started.\n",
            "Training batch 1030 completed. Loss: 0.7087, Accuracy: 0.5416\n",
            "Training batch 1031 started.\n",
            "Training batch 1031 completed. Loss: 0.7087, Accuracy: 0.5417\n",
            "Training batch 1032 started.\n",
            "Training batch 1032 completed. Loss: 0.7087, Accuracy: 0.5416\n",
            "Training batch 1033 started.\n",
            "Training batch 1033 completed. Loss: 0.7087, Accuracy: 0.5417\n",
            "Training batch 1034 started.\n",
            "Training batch 1034 completed. Loss: 0.7086, Accuracy: 0.5417\n",
            "Training batch 1035 started.\n",
            "Training batch 1035 completed. Loss: 0.7086, Accuracy: 0.5416\n",
            "Training batch 1036 started.\n",
            "Training batch 1036 completed. Loss: 0.7086, Accuracy: 0.5416\n",
            "Training batch 1037 started.\n",
            "Training batch 1037 completed. Loss: 0.7086, Accuracy: 0.5416\n",
            "Training batch 1038 started.\n",
            "Training batch 1038 completed. Loss: 0.7086, Accuracy: 0.5416\n",
            "Training batch 1039 started.\n",
            "Training batch 1039 completed. Loss: 0.7086, Accuracy: 0.5415\n",
            "Training batch 1040 started.\n",
            "Training batch 1040 completed. Loss: 0.7085, Accuracy: 0.5417\n",
            "Training batch 1041 started.\n",
            "Training batch 1041 completed. Loss: 0.7085, Accuracy: 0.5417\n",
            "Training batch 1042 started.\n",
            "Training batch 1042 completed. Loss: 0.7085, Accuracy: 0.5417\n",
            "Training batch 1043 started.\n",
            "Training batch 1043 completed. Loss: 0.7085, Accuracy: 0.5417\n",
            "Training batch 1044 started.\n",
            "Training batch 1044 completed. Loss: 0.7084, Accuracy: 0.5417\n",
            "Training batch 1045 started.\n",
            "Training batch 1045 completed. Loss: 0.7085, Accuracy: 0.5415\n",
            "Training batch 1046 started.\n",
            "Training batch 1046 completed. Loss: 0.7085, Accuracy: 0.5415\n",
            "Training batch 1047 started.\n",
            "Training batch 1047 completed. Loss: 0.7084, Accuracy: 0.5414\n",
            "Training batch 1048 started.\n",
            "Training batch 1048 completed. Loss: 0.7084, Accuracy: 0.5414\n",
            "Training batch 1049 started.\n",
            "Training batch 1049 completed. Loss: 0.7084, Accuracy: 0.5415\n",
            "Training batch 1050 started.\n",
            "Training batch 1050 completed. Loss: 0.7083, Accuracy: 0.5415\n",
            "Training batch 1051 started.\n",
            "Training batch 1051 completed. Loss: 0.7083, Accuracy: 0.5415\n",
            "Training batch 1052 started.\n",
            "Training batch 1052 completed. Loss: 0.7083, Accuracy: 0.5416\n",
            "Training batch 1053 started.\n",
            "Training batch 1053 completed. Loss: 0.7082, Accuracy: 0.5415\n",
            "Training batch 1054 started.\n",
            "Training batch 1054 completed. Loss: 0.7082, Accuracy: 0.5416\n",
            "Training batch 1055 started.\n",
            "Training batch 1055 completed. Loss: 0.7082, Accuracy: 0.5416\n",
            "Training batch 1056 started.\n",
            "Training batch 1056 completed. Loss: 0.7082, Accuracy: 0.5416\n",
            "Training batch 1057 started.\n",
            "Training batch 1057 completed. Loss: 0.7081, Accuracy: 0.5417\n",
            "Training batch 1058 started.\n",
            "Training batch 1058 completed. Loss: 0.7081, Accuracy: 0.5417\n",
            "Training batch 1059 started.\n",
            "Training batch 1059 completed. Loss: 0.7081, Accuracy: 0.5419\n",
            "Training batch 1060 started.\n",
            "Training batch 1060 completed. Loss: 0.7081, Accuracy: 0.5418\n",
            "Training batch 1061 started.\n",
            "Training batch 1061 completed. Loss: 0.7081, Accuracy: 0.5418\n",
            "Training batch 1062 started.\n",
            "Training batch 1062 completed. Loss: 0.7080, Accuracy: 0.5417\n",
            "Training batch 1063 started.\n",
            "Training batch 1063 completed. Loss: 0.7080, Accuracy: 0.5416\n",
            "Training batch 1064 started.\n",
            "Training batch 1064 completed. Loss: 0.7080, Accuracy: 0.5416\n",
            "Training batch 1065 started.\n",
            "Training batch 1065 completed. Loss: 0.7080, Accuracy: 0.5416\n",
            "Training batch 1066 started.\n",
            "Training batch 1066 completed. Loss: 0.7080, Accuracy: 0.5417\n",
            "Training batch 1067 started.\n",
            "Training batch 1067 completed. Loss: 0.7079, Accuracy: 0.5418\n",
            "Training batch 1068 started.\n",
            "Training batch 1068 completed. Loss: 0.7079, Accuracy: 0.5418\n",
            "Training batch 1069 started.\n",
            "Training batch 1069 completed. Loss: 0.7079, Accuracy: 0.5418\n",
            "Training batch 1070 started.\n",
            "Training batch 1070 completed. Loss: 0.7078, Accuracy: 0.5418\n",
            "Training batch 1071 started.\n",
            "Training batch 1071 completed. Loss: 0.7078, Accuracy: 0.5419\n",
            "Training batch 1072 started.\n",
            "Training batch 1072 completed. Loss: 0.7079, Accuracy: 0.5420\n",
            "Training batch 1073 started.\n",
            "Training batch 1073 completed. Loss: 0.7078, Accuracy: 0.5422\n",
            "Training batch 1074 started.\n",
            "Training batch 1074 completed. Loss: 0.7078, Accuracy: 0.5422\n",
            "Training batch 1075 started.\n",
            "Training batch 1075 completed. Loss: 0.7078, Accuracy: 0.5422\n",
            "Training batch 1076 started.\n",
            "Training batch 1076 completed. Loss: 0.7078, Accuracy: 0.5421\n",
            "Training batch 1077 started.\n",
            "Training batch 1077 completed. Loss: 0.7077, Accuracy: 0.5421\n",
            "Training batch 1078 started.\n",
            "Training batch 1078 completed. Loss: 0.7077, Accuracy: 0.5422\n",
            "Training batch 1079 started.\n",
            "Training batch 1079 completed. Loss: 0.7077, Accuracy: 0.5422\n",
            "Training batch 1080 started.\n",
            "Training batch 1080 completed. Loss: 0.7077, Accuracy: 0.5423\n",
            "Training batch 1081 started.\n",
            "Training batch 1081 completed. Loss: 0.7077, Accuracy: 0.5422\n",
            "Training batch 1082 started.\n",
            "Training batch 1082 completed. Loss: 0.7077, Accuracy: 0.5422\n",
            "Training batch 1083 started.\n",
            "Training batch 1083 completed. Loss: 0.7077, Accuracy: 0.5423\n",
            "Training batch 1084 started.\n",
            "Training batch 1084 completed. Loss: 0.7077, Accuracy: 0.5422\n",
            "Training batch 1085 started.\n",
            "Training batch 1085 completed. Loss: 0.7077, Accuracy: 0.5422\n",
            "Training batch 1086 started.\n",
            "Training batch 1086 completed. Loss: 0.7077, Accuracy: 0.5423\n",
            "Training batch 1087 started.\n",
            "Training batch 1087 completed. Loss: 0.7077, Accuracy: 0.5422\n",
            "Training batch 1088 started.\n",
            "Training batch 1088 completed. Loss: 0.7076, Accuracy: 0.5424\n",
            "Training batch 1089 started.\n",
            "Training batch 1089 completed. Loss: 0.7076, Accuracy: 0.5424\n",
            "Training batch 1090 started.\n",
            "Training batch 1090 completed. Loss: 0.7075, Accuracy: 0.5424\n",
            "Training batch 1091 started.\n",
            "Training batch 1091 completed. Loss: 0.7075, Accuracy: 0.5424\n",
            "Training batch 1092 started.\n",
            "Training batch 1092 completed. Loss: 0.7075, Accuracy: 0.5426\n",
            "Training batch 1093 started.\n",
            "Training batch 1093 completed. Loss: 0.7074, Accuracy: 0.5426\n",
            "Training batch 1094 started.\n",
            "Training batch 1094 completed. Loss: 0.7074, Accuracy: 0.5426\n",
            "Training batch 1095 started.\n",
            "Training batch 1095 completed. Loss: 0.7074, Accuracy: 0.5426\n",
            "Training batch 1096 started.\n",
            "Training batch 1096 completed. Loss: 0.7074, Accuracy: 0.5426\n",
            "Training batch 1097 started.\n",
            "Training batch 1097 completed. Loss: 0.7074, Accuracy: 0.5425\n",
            "Training batch 1098 started.\n",
            "Training batch 1098 completed. Loss: 0.7073, Accuracy: 0.5427\n",
            "Training batch 1099 started.\n",
            "Training batch 1099 completed. Loss: 0.7073, Accuracy: 0.5427\n",
            "Training batch 1100 started.\n",
            "Training batch 1100 completed. Loss: 0.7073, Accuracy: 0.5426\n",
            "Training batch 1101 started.\n",
            "Training batch 1101 completed. Loss: 0.7073, Accuracy: 0.5426\n",
            "Training batch 1102 started.\n",
            "Training batch 1102 completed. Loss: 0.7073, Accuracy: 0.5426\n",
            "Training batch 1103 started.\n",
            "Training batch 1103 completed. Loss: 0.7072, Accuracy: 0.5428\n",
            "Training batch 1104 started.\n",
            "Training batch 1104 completed. Loss: 0.7072, Accuracy: 0.5428\n",
            "Training batch 1105 started.\n",
            "Training batch 1105 completed. Loss: 0.7071, Accuracy: 0.5427\n",
            "Training batch 1106 started.\n",
            "Training batch 1106 completed. Loss: 0.7071, Accuracy: 0.5428\n",
            "Training batch 1107 started.\n",
            "Training batch 1107 completed. Loss: 0.7071, Accuracy: 0.5429\n",
            "Training batch 1108 started.\n",
            "Training batch 1108 completed. Loss: 0.7071, Accuracy: 0.5429\n",
            "Training batch 1109 started.\n",
            "Training batch 1109 completed. Loss: 0.7070, Accuracy: 0.5430\n",
            "Training batch 1110 started.\n",
            "Training batch 1110 completed. Loss: 0.7070, Accuracy: 0.5430\n",
            "Training batch 1111 started.\n",
            "Training batch 1111 completed. Loss: 0.7069, Accuracy: 0.5431\n",
            "Training batch 1112 started.\n",
            "Training batch 1112 completed. Loss: 0.7069, Accuracy: 0.5430\n",
            "Training batch 1113 started.\n",
            "Training batch 1113 completed. Loss: 0.7069, Accuracy: 0.5432\n",
            "Training batch 1114 started.\n",
            "Training batch 1114 completed. Loss: 0.7068, Accuracy: 0.5432\n",
            "Training batch 1115 started.\n",
            "Training batch 1115 completed. Loss: 0.7068, Accuracy: 0.5432\n",
            "Training batch 1116 started.\n",
            "Training batch 1116 completed. Loss: 0.7068, Accuracy: 0.5431\n",
            "Training batch 1117 started.\n",
            "Training batch 1117 completed. Loss: 0.7068, Accuracy: 0.5431\n",
            "Training batch 1118 started.\n",
            "Training batch 1118 completed. Loss: 0.7068, Accuracy: 0.5431\n",
            "Training batch 1119 started.\n",
            "Training batch 1119 completed. Loss: 0.7068, Accuracy: 0.5431\n",
            "Training batch 1120 started.\n",
            "Training batch 1120 completed. Loss: 0.7067, Accuracy: 0.5433\n",
            "Training batch 1121 started.\n",
            "Training batch 1121 completed. Loss: 0.7067, Accuracy: 0.5433\n",
            "Training batch 1122 started.\n",
            "Training batch 1122 completed. Loss: 0.7067, Accuracy: 0.5433\n",
            "Training batch 1123 started.\n",
            "Training batch 1123 completed. Loss: 0.7066, Accuracy: 0.5434\n",
            "Training batch 1124 started.\n",
            "Training batch 1124 completed. Loss: 0.7066, Accuracy: 0.5433\n",
            "Training batch 1125 started.\n",
            "Training batch 1125 completed. Loss: 0.7065, Accuracy: 0.5433\n",
            "Training batch 1126 started.\n",
            "Training batch 1126 completed. Loss: 0.7065, Accuracy: 0.5433\n",
            "Training batch 1127 started.\n",
            "Training batch 1127 completed. Loss: 0.7065, Accuracy: 0.5432\n",
            "Training batch 1128 started.\n",
            "Training batch 1128 completed. Loss: 0.7065, Accuracy: 0.5434\n",
            "Training batch 1129 started.\n",
            "Training batch 1129 completed. Loss: 0.7064, Accuracy: 0.5435\n",
            "Training batch 1130 started.\n",
            "Training batch 1130 completed. Loss: 0.7064, Accuracy: 0.5435\n",
            "Training batch 1131 started.\n",
            "Training batch 1131 completed. Loss: 0.7064, Accuracy: 0.5435\n",
            "Training batch 1132 started.\n",
            "Training batch 1132 completed. Loss: 0.7063, Accuracy: 0.5436\n",
            "Training batch 1133 started.\n",
            "Training batch 1133 completed. Loss: 0.7063, Accuracy: 0.5435\n",
            "Training batch 1134 started.\n",
            "Training batch 1134 completed. Loss: 0.7063, Accuracy: 0.5436\n",
            "Training batch 1135 started.\n",
            "Training batch 1135 completed. Loss: 0.7063, Accuracy: 0.5436\n",
            "Training batch 1136 started.\n",
            "Training batch 1136 completed. Loss: 0.7063, Accuracy: 0.5437\n",
            "Training batch 1137 started.\n",
            "Training batch 1137 completed. Loss: 0.7062, Accuracy: 0.5438\n",
            "Training batch 1138 started.\n",
            "Training batch 1138 completed. Loss: 0.7062, Accuracy: 0.5437\n",
            "Training batch 1139 started.\n",
            "Training batch 1139 completed. Loss: 0.7063, Accuracy: 0.5437\n",
            "Training batch 1140 started.\n",
            "Training batch 1140 completed. Loss: 0.7062, Accuracy: 0.5437\n",
            "Training batch 1141 started.\n",
            "Training batch 1141 completed. Loss: 0.7062, Accuracy: 0.5438\n",
            "Training batch 1142 started.\n",
            "Training batch 1142 completed. Loss: 0.7062, Accuracy: 0.5439\n",
            "Training batch 1143 started.\n",
            "Training batch 1143 completed. Loss: 0.7062, Accuracy: 0.5438\n",
            "Training batch 1144 started.\n",
            "Training batch 1144 completed. Loss: 0.7062, Accuracy: 0.5438\n",
            "Training batch 1145 started.\n",
            "Training batch 1145 completed. Loss: 0.7062, Accuracy: 0.5439\n",
            "Training batch 1146 started.\n",
            "Training batch 1146 completed. Loss: 0.7061, Accuracy: 0.5441\n",
            "Training batch 1147 started.\n",
            "Training batch 1147 completed. Loss: 0.7061, Accuracy: 0.5440\n",
            "Training batch 1148 started.\n",
            "Training batch 1148 completed. Loss: 0.7061, Accuracy: 0.5439\n",
            "Training batch 1149 started.\n",
            "Training batch 1149 completed. Loss: 0.7061, Accuracy: 0.5440\n",
            "Training batch 1150 started.\n",
            "Training batch 1150 completed. Loss: 0.7061, Accuracy: 0.5440\n",
            "Training batch 1151 started.\n",
            "Training batch 1151 completed. Loss: 0.7061, Accuracy: 0.5440\n",
            "Training batch 1152 started.\n",
            "Training batch 1152 completed. Loss: 0.7060, Accuracy: 0.5442\n",
            "Training batch 1153 started.\n",
            "Training batch 1153 completed. Loss: 0.7060, Accuracy: 0.5440\n",
            "Training batch 1154 started.\n",
            "Training batch 1154 completed. Loss: 0.7060, Accuracy: 0.5440\n",
            "Training batch 1155 started.\n",
            "Training batch 1155 completed. Loss: 0.7060, Accuracy: 0.5439\n",
            "Training batch 1156 started.\n",
            "Training batch 1156 completed. Loss: 0.7060, Accuracy: 0.5439\n",
            "Training batch 1157 started.\n",
            "Training batch 1157 completed. Loss: 0.7060, Accuracy: 0.5439\n",
            "Training batch 1158 started.\n",
            "Training batch 1158 completed. Loss: 0.7060, Accuracy: 0.5439\n",
            "Training batch 1159 started.\n",
            "Training batch 1159 completed. Loss: 0.7060, Accuracy: 0.5438\n",
            "Training batch 1160 started.\n",
            "Training batch 1160 completed. Loss: 0.7060, Accuracy: 0.5438\n",
            "Training batch 1161 started.\n",
            "Training batch 1161 completed. Loss: 0.7060, Accuracy: 0.5437\n",
            "Training batch 1162 started.\n",
            "Training batch 1162 completed. Loss: 0.7059, Accuracy: 0.5437\n",
            "Training batch 1163 started.\n",
            "Training batch 1163 completed. Loss: 0.7059, Accuracy: 0.5438\n",
            "Training batch 1164 started.\n",
            "Training batch 1164 completed. Loss: 0.7059, Accuracy: 0.5438\n",
            "Training batch 1165 started.\n",
            "Training batch 1165 completed. Loss: 0.7059, Accuracy: 0.5438\n",
            "Training batch 1166 started.\n",
            "Training batch 1166 completed. Loss: 0.7059, Accuracy: 0.5438\n",
            "Training batch 1167 started.\n",
            "Training batch 1167 completed. Loss: 0.7059, Accuracy: 0.5437\n",
            "Training batch 1168 started.\n",
            "Training batch 1168 completed. Loss: 0.7058, Accuracy: 0.5437\n",
            "Training batch 1169 started.\n",
            "Training batch 1169 completed. Loss: 0.7058, Accuracy: 0.5437\n",
            "Training batch 1170 started.\n",
            "Training batch 1170 completed. Loss: 0.7058, Accuracy: 0.5438\n",
            "Training batch 1171 started.\n",
            "Training batch 1171 completed. Loss: 0.7058, Accuracy: 0.5438\n",
            "Training batch 1172 started.\n",
            "Training batch 1172 completed. Loss: 0.7058, Accuracy: 0.5438\n",
            "Training batch 1173 started.\n",
            "Training batch 1173 completed. Loss: 0.7058, Accuracy: 0.5438\n",
            "Training batch 1174 started.\n",
            "Training batch 1174 completed. Loss: 0.7057, Accuracy: 0.5438\n",
            "Training batch 1175 started.\n",
            "Training batch 1175 completed. Loss: 0.7057, Accuracy: 0.5438\n",
            "Training batch 1176 started.\n",
            "Training batch 1176 completed. Loss: 0.7057, Accuracy: 0.5439\n",
            "Training batch 1177 started.\n",
            "Training batch 1177 completed. Loss: 0.7057, Accuracy: 0.5439\n",
            "Training batch 1178 started.\n",
            "Training batch 1178 completed. Loss: 0.7056, Accuracy: 0.5440\n",
            "Training batch 1179 started.\n",
            "Training batch 1179 completed. Loss: 0.7056, Accuracy: 0.5439\n",
            "Training batch 1180 started.\n",
            "Training batch 1180 completed. Loss: 0.7056, Accuracy: 0.5439\n",
            "Training batch 1181 started.\n",
            "Training batch 1181 completed. Loss: 0.7056, Accuracy: 0.5439\n",
            "Training batch 1182 started.\n",
            "Training batch 1182 completed. Loss: 0.7056, Accuracy: 0.5439\n",
            "Training batch 1183 started.\n",
            "Training batch 1183 completed. Loss: 0.7056, Accuracy: 0.5439\n",
            "Training batch 1184 started.\n",
            "Training batch 1184 completed. Loss: 0.7055, Accuracy: 0.5439\n",
            "Training batch 1185 started.\n",
            "Training batch 1185 completed. Loss: 0.7055, Accuracy: 0.5440\n",
            "Training batch 1186 started.\n",
            "Training batch 1186 completed. Loss: 0.7055, Accuracy: 0.5440\n",
            "Training batch 1187 started.\n",
            "Training batch 1187 completed. Loss: 0.7055, Accuracy: 0.5441\n",
            "Training batch 1188 started.\n",
            "Training batch 1188 completed. Loss: 0.7054, Accuracy: 0.5440\n",
            "Training batch 1189 started.\n",
            "Training batch 1189 completed. Loss: 0.7054, Accuracy: 0.5440\n",
            "Training batch 1190 started.\n",
            "Training batch 1190 completed. Loss: 0.7054, Accuracy: 0.5439\n",
            "Training batch 1191 started.\n",
            "Training batch 1191 completed. Loss: 0.7054, Accuracy: 0.5439\n",
            "Training batch 1192 started.\n",
            "Training batch 1192 completed. Loss: 0.7054, Accuracy: 0.5441\n",
            "Training batch 1193 started.\n",
            "Training batch 1193 completed. Loss: 0.7053, Accuracy: 0.5442\n",
            "Training batch 1194 started.\n",
            "Training batch 1194 completed. Loss: 0.7053, Accuracy: 0.5442\n",
            "Training batch 1195 started.\n",
            "Training batch 1195 completed. Loss: 0.7053, Accuracy: 0.5443\n",
            "Training batch 1196 started.\n",
            "Training batch 1196 completed. Loss: 0.7053, Accuracy: 0.5442\n",
            "Training batch 1197 started.\n",
            "Training batch 1197 completed. Loss: 0.7053, Accuracy: 0.5441\n",
            "Training batch 1198 started.\n",
            "Training batch 1198 completed. Loss: 0.7053, Accuracy: 0.5439\n",
            "Training batch 1199 started.\n",
            "Training batch 1199 completed. Loss: 0.7053, Accuracy: 0.5440\n",
            "Training batch 1200 started.\n",
            "Training batch 1200 completed. Loss: 0.7053, Accuracy: 0.5440\n",
            "Training batch 1201 started.\n",
            "Training batch 1201 completed. Loss: 0.7052, Accuracy: 0.5441\n",
            "Training batch 1202 started.\n",
            "Training batch 1202 completed. Loss: 0.7053, Accuracy: 0.5440\n",
            "Training batch 1203 started.\n",
            "Training batch 1203 completed. Loss: 0.7052, Accuracy: 0.5441\n",
            "Training batch 1204 started.\n",
            "Training batch 1204 completed. Loss: 0.7052, Accuracy: 0.5441\n",
            "Training batch 1205 started.\n",
            "Training batch 1205 completed. Loss: 0.7052, Accuracy: 0.5441\n",
            "Training batch 1206 started.\n",
            "Training batch 1206 completed. Loss: 0.7052, Accuracy: 0.5441\n",
            "Training batch 1207 started.\n",
            "Training batch 1207 completed. Loss: 0.7051, Accuracy: 0.5441\n",
            "Training batch 1208 started.\n",
            "Training batch 1208 completed. Loss: 0.7051, Accuracy: 0.5440\n",
            "Training batch 1209 started.\n",
            "Training batch 1209 completed. Loss: 0.7051, Accuracy: 0.5440\n",
            "Training batch 1210 started.\n",
            "Training batch 1210 completed. Loss: 0.7051, Accuracy: 0.5440\n",
            "Training batch 1211 started.\n",
            "Training batch 1211 completed. Loss: 0.7051, Accuracy: 0.5441\n",
            "Training batch 1212 started.\n",
            "Training batch 1212 completed. Loss: 0.7051, Accuracy: 0.5440\n",
            "Training batch 1213 started.\n",
            "Training batch 1213 completed. Loss: 0.7051, Accuracy: 0.5440\n",
            "Training batch 1214 started.\n",
            "Training batch 1214 completed. Loss: 0.7051, Accuracy: 0.5440\n",
            "Training batch 1215 started.\n",
            "Training batch 1215 completed. Loss: 0.7050, Accuracy: 0.5441\n",
            "Training batch 1216 started.\n",
            "Training batch 1216 completed. Loss: 0.7050, Accuracy: 0.5441\n",
            "Training batch 1217 started.\n",
            "Training batch 1217 completed. Loss: 0.7049, Accuracy: 0.5442\n",
            "Training batch 1218 started.\n",
            "Training batch 1218 completed. Loss: 0.7049, Accuracy: 0.5443\n",
            "Training batch 1219 started.\n",
            "Training batch 1219 completed. Loss: 0.7049, Accuracy: 0.5444\n",
            "Training batch 1220 started.\n",
            "Training batch 1220 completed. Loss: 0.7048, Accuracy: 0.5444\n",
            "Training batch 1221 started.\n",
            "Training batch 1221 completed. Loss: 0.7048, Accuracy: 0.5445\n",
            "Training batch 1222 started.\n",
            "Training batch 1222 completed. Loss: 0.7048, Accuracy: 0.5446\n",
            "Training batch 1223 started.\n",
            "Training batch 1223 completed. Loss: 0.7048, Accuracy: 0.5446\n",
            "Training batch 1224 started.\n",
            "Training batch 1224 completed. Loss: 0.7048, Accuracy: 0.5447\n",
            "Training batch 1225 started.\n",
            "Training batch 1225 completed. Loss: 0.7048, Accuracy: 0.5447\n",
            "Training batch 1226 started.\n",
            "Training batch 1226 completed. Loss: 0.7048, Accuracy: 0.5446\n",
            "Training batch 1227 started.\n",
            "Training batch 1227 completed. Loss: 0.7047, Accuracy: 0.5446\n",
            "Training batch 1228 started.\n",
            "Training batch 1228 completed. Loss: 0.7047, Accuracy: 0.5445\n",
            "Training batch 1229 started.\n",
            "Training batch 1229 completed. Loss: 0.7047, Accuracy: 0.5446\n",
            "Training batch 1230 started.\n",
            "Training batch 1230 completed. Loss: 0.7047, Accuracy: 0.5446\n",
            "Training batch 1231 started.\n",
            "Training batch 1231 completed. Loss: 0.7047, Accuracy: 0.5447\n",
            "Training batch 1232 started.\n",
            "Training batch 1232 completed. Loss: 0.7047, Accuracy: 0.5447\n",
            "Training batch 1233 started.\n",
            "Training batch 1233 completed. Loss: 0.7046, Accuracy: 0.5448\n",
            "Training batch 1234 started.\n",
            "Training batch 1234 completed. Loss: 0.7046, Accuracy: 0.5449\n",
            "Training batch 1235 started.\n",
            "Training batch 1235 completed. Loss: 0.7046, Accuracy: 0.5449\n",
            "Training batch 1236 started.\n",
            "Training batch 1236 completed. Loss: 0.7046, Accuracy: 0.5448\n",
            "Training batch 1237 started.\n",
            "Training batch 1237 completed. Loss: 0.7045, Accuracy: 0.5449\n",
            "Training batch 1238 started.\n",
            "Training batch 1238 completed. Loss: 0.7045, Accuracy: 0.5449\n",
            "Training batch 1239 started.\n",
            "Training batch 1239 completed. Loss: 0.7045, Accuracy: 0.5449\n",
            "Training batch 1240 started.\n",
            "Training batch 1240 completed. Loss: 0.7045, Accuracy: 0.5448\n",
            "Training batch 1241 started.\n",
            "Training batch 1241 completed. Loss: 0.7044, Accuracy: 0.5449\n",
            "Training batch 1242 started.\n",
            "Training batch 1242 completed. Loss: 0.7044, Accuracy: 0.5449\n",
            "Training batch 1243 started.\n",
            "Training batch 1243 completed. Loss: 0.7044, Accuracy: 0.5448\n",
            "Training batch 1244 started.\n",
            "Training batch 1244 completed. Loss: 0.7044, Accuracy: 0.5448\n",
            "Training batch 1245 started.\n",
            "Training batch 1245 completed. Loss: 0.7044, Accuracy: 0.5449\n",
            "Training batch 1246 started.\n",
            "Training batch 1246 completed. Loss: 0.7044, Accuracy: 0.5449\n",
            "Training batch 1247 started.\n",
            "Training batch 1247 completed. Loss: 0.7043, Accuracy: 0.5450\n",
            "Training batch 1248 started.\n",
            "Training batch 1248 completed. Loss: 0.7043, Accuracy: 0.5450\n",
            "Training batch 1249 started.\n",
            "Training batch 1249 completed. Loss: 0.7043, Accuracy: 0.5450\n",
            "Training batch 1250 started.\n",
            "Training batch 1250 completed. Loss: 0.7043, Accuracy: 0.5450\n",
            "Training batch 1251 started.\n",
            "Training batch 1251 completed. Loss: 0.7043, Accuracy: 0.5449\n",
            "Training batch 1252 started.\n",
            "Training batch 1252 completed. Loss: 0.7042, Accuracy: 0.5449\n",
            "Training batch 1253 started.\n",
            "Training batch 1253 completed. Loss: 0.7042, Accuracy: 0.5450\n",
            "Training batch 1254 started.\n",
            "Training batch 1254 completed. Loss: 0.7042, Accuracy: 0.5451\n",
            "Training batch 1255 started.\n",
            "Training batch 1255 completed. Loss: 0.7041, Accuracy: 0.5452\n",
            "Training batch 1256 started.\n",
            "Training batch 1256 completed. Loss: 0.7041, Accuracy: 0.5453\n",
            "Training batch 1257 started.\n",
            "Training batch 1257 completed. Loss: 0.7041, Accuracy: 0.5453\n",
            "Training batch 1258 started.\n",
            "Training batch 1258 completed. Loss: 0.7041, Accuracy: 0.5453\n",
            "Training batch 1259 started.\n",
            "Training batch 1259 completed. Loss: 0.7040, Accuracy: 0.5453\n",
            "Training batch 1260 started.\n",
            "Training batch 1260 completed. Loss: 0.7040, Accuracy: 0.5454\n",
            "Training batch 1261 started.\n",
            "Training batch 1261 completed. Loss: 0.7040, Accuracy: 0.5454\n",
            "Training batch 1262 started.\n",
            "Training batch 1262 completed. Loss: 0.7040, Accuracy: 0.5455\n",
            "Training batch 1263 started.\n",
            "Training batch 1263 completed. Loss: 0.7040, Accuracy: 0.5454\n",
            "Training batch 1264 started.\n",
            "Training batch 1264 completed. Loss: 0.7040, Accuracy: 0.5454\n",
            "Training batch 1265 started.\n",
            "Training batch 1265 completed. Loss: 0.7039, Accuracy: 0.5455\n",
            "Training batch 1266 started.\n",
            "Training batch 1266 completed. Loss: 0.7039, Accuracy: 0.5456\n",
            "Training batch 1267 started.\n",
            "Training batch 1267 completed. Loss: 0.7038, Accuracy: 0.5455\n",
            "Training batch 1268 started.\n",
            "Training batch 1268 completed. Loss: 0.7039, Accuracy: 0.5456\n",
            "Training batch 1269 started.\n",
            "Training batch 1269 completed. Loss: 0.7039, Accuracy: 0.5455\n",
            "Training batch 1270 started.\n",
            "Training batch 1270 completed. Loss: 0.7038, Accuracy: 0.5456\n",
            "Training batch 1271 started.\n",
            "Training batch 1271 completed. Loss: 0.7039, Accuracy: 0.5456\n",
            "Training batch 1272 started.\n",
            "Training batch 1272 completed. Loss: 0.7039, Accuracy: 0.5456\n",
            "Training batch 1273 started.\n",
            "Training batch 1273 completed. Loss: 0.7039, Accuracy: 0.5456\n",
            "Training batch 1274 started.\n",
            "Training batch 1274 completed. Loss: 0.7038, Accuracy: 0.5458\n",
            "Training batch 1275 started.\n",
            "Training batch 1275 completed. Loss: 0.7037, Accuracy: 0.5458\n",
            "Training batch 1276 started.\n",
            "Training batch 1276 completed. Loss: 0.7037, Accuracy: 0.5460\n",
            "Training batch 1277 started.\n",
            "Training batch 1277 completed. Loss: 0.7037, Accuracy: 0.5460\n",
            "Training batch 1278 started.\n",
            "Training batch 1278 completed. Loss: 0.7037, Accuracy: 0.5461\n",
            "Training batch 1279 started.\n",
            "Training batch 1279 completed. Loss: 0.7036, Accuracy: 0.5461\n",
            "Training batch 1280 started.\n",
            "Training batch 1280 completed. Loss: 0.7036, Accuracy: 0.5460\n",
            "Training batch 1281 started.\n",
            "Training batch 1281 completed. Loss: 0.7036, Accuracy: 0.5460\n",
            "Training batch 1282 started.\n",
            "Training batch 1282 completed. Loss: 0.7036, Accuracy: 0.5461\n",
            "Training batch 1283 started.\n",
            "Training batch 1283 completed. Loss: 0.7036, Accuracy: 0.5461\n",
            "Training batch 1284 started.\n",
            "Training batch 1284 completed. Loss: 0.7035, Accuracy: 0.5461\n",
            "Training batch 1285 started.\n",
            "Training batch 1285 completed. Loss: 0.7035, Accuracy: 0.5462\n",
            "Training batch 1286 started.\n",
            "Training batch 1286 completed. Loss: 0.7035, Accuracy: 0.5462\n",
            "Training batch 1287 started.\n",
            "Training batch 1287 completed. Loss: 0.7035, Accuracy: 0.5463\n",
            "Training batch 1288 started.\n",
            "Training batch 1288 completed. Loss: 0.7034, Accuracy: 0.5463\n",
            "Training batch 1289 started.\n",
            "Training batch 1289 completed. Loss: 0.7034, Accuracy: 0.5463\n",
            "Training batch 1290 started.\n",
            "Training batch 1290 completed. Loss: 0.7035, Accuracy: 0.5463\n",
            "Training batch 1291 started.\n",
            "Training batch 1291 completed. Loss: 0.7035, Accuracy: 0.5464\n",
            "Training batch 1292 started.\n",
            "Training batch 1292 completed. Loss: 0.7034, Accuracy: 0.5464\n",
            "Training batch 1293 started.\n",
            "Training batch 1293 completed. Loss: 0.7034, Accuracy: 0.5464\n",
            "Training batch 1294 started.\n",
            "Training batch 1294 completed. Loss: 0.7034, Accuracy: 0.5464\n",
            "Training batch 1295 started.\n",
            "Training batch 1295 completed. Loss: 0.7034, Accuracy: 0.5465\n",
            "Training batch 1296 started.\n",
            "Training batch 1296 completed. Loss: 0.7034, Accuracy: 0.5465\n",
            "Training batch 1297 started.\n",
            "Training batch 1297 completed. Loss: 0.7033, Accuracy: 0.5466\n",
            "Training batch 1298 started.\n",
            "Training batch 1298 completed. Loss: 0.7033, Accuracy: 0.5467\n",
            "Training batch 1299 started.\n",
            "Training batch 1299 completed. Loss: 0.7033, Accuracy: 0.5467\n",
            "Training batch 1300 started.\n",
            "Training batch 1300 completed. Loss: 0.7033, Accuracy: 0.5468\n",
            "Training batch 1301 started.\n",
            "Training batch 1301 completed. Loss: 0.7032, Accuracy: 0.5468\n",
            "Training batch 1302 started.\n",
            "Training batch 1302 completed. Loss: 0.7032, Accuracy: 0.5468\n",
            "Training batch 1303 started.\n",
            "Training batch 1303 completed. Loss: 0.7032, Accuracy: 0.5470\n",
            "Training batch 1304 started.\n",
            "Training batch 1304 completed. Loss: 0.7032, Accuracy: 0.5470\n",
            "Training batch 1305 started.\n",
            "Training batch 1305 completed. Loss: 0.7031, Accuracy: 0.5470\n",
            "Training batch 1306 started.\n",
            "Training batch 1306 completed. Loss: 0.7031, Accuracy: 0.5471\n",
            "Training batch 1307 started.\n",
            "Training batch 1307 completed. Loss: 0.7032, Accuracy: 0.5470\n",
            "Training batch 1308 started.\n",
            "Training batch 1308 completed. Loss: 0.7031, Accuracy: 0.5471\n",
            "Training batch 1309 started.\n",
            "Training batch 1309 completed. Loss: 0.7031, Accuracy: 0.5471\n",
            "Training batch 1310 started.\n",
            "Training batch 1310 completed. Loss: 0.7031, Accuracy: 0.5471\n",
            "Training batch 1311 started.\n",
            "Training batch 1311 completed. Loss: 0.7031, Accuracy: 0.5470\n",
            "Training batch 1312 started.\n",
            "Training batch 1312 completed. Loss: 0.7031, Accuracy: 0.5471\n",
            "Training batch 1313 started.\n",
            "Training batch 1313 completed. Loss: 0.7031, Accuracy: 0.5471\n",
            "Training batch 1314 started.\n",
            "Training batch 1314 completed. Loss: 0.7031, Accuracy: 0.5470\n",
            "Training batch 1315 started.\n",
            "Training batch 1315 completed. Loss: 0.7030, Accuracy: 0.5471\n",
            "Training batch 1316 started.\n",
            "Training batch 1316 completed. Loss: 0.7030, Accuracy: 0.5470\n",
            "Training batch 1317 started.\n",
            "Training batch 1317 completed. Loss: 0.7030, Accuracy: 0.5470\n",
            "Training batch 1318 started.\n",
            "Training batch 1318 completed. Loss: 0.7030, Accuracy: 0.5470\n",
            "Training batch 1319 started.\n",
            "Training batch 1319 completed. Loss: 0.7030, Accuracy: 0.5470\n",
            "Training batch 1320 started.\n",
            "Training batch 1320 completed. Loss: 0.7030, Accuracy: 0.5470\n",
            "Training batch 1321 started.\n",
            "Training batch 1321 completed. Loss: 0.7029, Accuracy: 0.5471\n",
            "Training batch 1322 started.\n",
            "Training batch 1322 completed. Loss: 0.7029, Accuracy: 0.5470\n",
            "Training batch 1323 started.\n",
            "Training batch 1323 completed. Loss: 0.7029, Accuracy: 0.5470\n",
            "Training batch 1324 started.\n",
            "Training batch 1324 completed. Loss: 0.7029, Accuracy: 0.5471\n",
            "Training batch 1325 started.\n",
            "Training batch 1325 completed. Loss: 0.7029, Accuracy: 0.5471\n",
            "Training batch 1326 started.\n",
            "Training batch 1326 completed. Loss: 0.7029, Accuracy: 0.5471\n",
            "Training batch 1327 started.\n",
            "Training batch 1327 completed. Loss: 0.7029, Accuracy: 0.5471\n",
            "Training batch 1328 started.\n",
            "Training batch 1328 completed. Loss: 0.7029, Accuracy: 0.5471\n",
            "Training batch 1329 started.\n",
            "Training batch 1329 completed. Loss: 0.7029, Accuracy: 0.5470\n",
            "Training batch 1330 started.\n",
            "Training batch 1330 completed. Loss: 0.7028, Accuracy: 0.5471\n",
            "Training batch 1331 started.\n",
            "Training batch 1331 completed. Loss: 0.7028, Accuracy: 0.5472\n",
            "Training batch 1332 started.\n",
            "Training batch 1332 completed. Loss: 0.7028, Accuracy: 0.5473\n",
            "Training batch 1333 started.\n",
            "Training batch 1333 completed. Loss: 0.7028, Accuracy: 0.5473\n",
            "Training batch 1334 started.\n",
            "Training batch 1334 completed. Loss: 0.7028, Accuracy: 0.5473\n",
            "Training batch 1335 started.\n",
            "Training batch 1335 completed. Loss: 0.7027, Accuracy: 0.5474\n",
            "Training batch 1336 started.\n",
            "Training batch 1336 completed. Loss: 0.7027, Accuracy: 0.5475\n",
            "Training batch 1337 started.\n",
            "Training batch 1337 completed. Loss: 0.7027, Accuracy: 0.5474\n",
            "Training batch 1338 started.\n",
            "Training batch 1338 completed. Loss: 0.7027, Accuracy: 0.5475\n",
            "Training batch 1339 started.\n",
            "Training batch 1339 completed. Loss: 0.7027, Accuracy: 0.5475\n",
            "Training batch 1340 started.\n",
            "Training batch 1340 completed. Loss: 0.7026, Accuracy: 0.5475\n",
            "Training batch 1341 started.\n",
            "Training batch 1341 completed. Loss: 0.7026, Accuracy: 0.5475\n",
            "Training batch 1342 started.\n",
            "Training batch 1342 completed. Loss: 0.7026, Accuracy: 0.5475\n",
            "Training batch 1343 started.\n",
            "Training batch 1343 completed. Loss: 0.7026, Accuracy: 0.5476\n",
            "Training batch 1344 started.\n",
            "Training batch 1344 completed. Loss: 0.7026, Accuracy: 0.5476\n",
            "Training batch 1345 started.\n",
            "Training batch 1345 completed. Loss: 0.7026, Accuracy: 0.5476\n",
            "Training batch 1346 started.\n",
            "Training batch 1346 completed. Loss: 0.7026, Accuracy: 0.5476\n",
            "Training batch 1347 started.\n",
            "Training batch 1347 completed. Loss: 0.7026, Accuracy: 0.5476\n",
            "Training batch 1348 started.\n",
            "Training batch 1348 completed. Loss: 0.7025, Accuracy: 0.5476\n",
            "Training batch 1349 started.\n",
            "Training batch 1349 completed. Loss: 0.7025, Accuracy: 0.5477\n",
            "Training batch 1350 started.\n",
            "Training batch 1350 completed. Loss: 0.7025, Accuracy: 0.5477\n",
            "Training batch 1351 started.\n",
            "Training batch 1351 completed. Loss: 0.7025, Accuracy: 0.5476\n",
            "Training batch 1352 started.\n",
            "Training batch 1352 completed. Loss: 0.7025, Accuracy: 0.5477\n",
            "Training batch 1353 started.\n",
            "Training batch 1353 completed. Loss: 0.7025, Accuracy: 0.5477\n",
            "Training batch 1354 started.\n",
            "Training batch 1354 completed. Loss: 0.7025, Accuracy: 0.5476\n",
            "Training batch 1355 started.\n",
            "Training batch 1355 completed. Loss: 0.7025, Accuracy: 0.5476\n",
            "Training batch 1356 started.\n",
            "Training batch 1356 completed. Loss: 0.7025, Accuracy: 0.5476\n",
            "Training batch 1357 started.\n",
            "Training batch 1357 completed. Loss: 0.7025, Accuracy: 0.5475\n",
            "Training batch 1358 started.\n",
            "Training batch 1358 completed. Loss: 0.7025, Accuracy: 0.5475\n",
            "Training batch 1359 started.\n",
            "Training batch 1359 completed. Loss: 0.7024, Accuracy: 0.5475\n",
            "Training batch 1360 started.\n",
            "Training batch 1360 completed. Loss: 0.7025, Accuracy: 0.5475\n",
            "Training batch 1361 started.\n",
            "Training batch 1361 completed. Loss: 0.7024, Accuracy: 0.5475\n",
            "Training batch 1362 started.\n",
            "Training batch 1362 completed. Loss: 0.7024, Accuracy: 0.5474\n",
            "Training batch 1363 started.\n",
            "Training batch 1363 completed. Loss: 0.7024, Accuracy: 0.5474\n",
            "Training batch 1364 started.\n",
            "Training batch 1364 completed. Loss: 0.7024, Accuracy: 0.5474\n",
            "Training batch 1365 started.\n",
            "Training batch 1365 completed. Loss: 0.7024, Accuracy: 0.5473\n",
            "Training batch 1366 started.\n",
            "Training batch 1366 completed. Loss: 0.7024, Accuracy: 0.5474\n",
            "Training batch 1367 started.\n",
            "Training batch 1367 completed. Loss: 0.7023, Accuracy: 0.5476\n",
            "Training batch 1368 started.\n",
            "Training batch 1368 completed. Loss: 0.7023, Accuracy: 0.5476\n",
            "Training batch 1369 started.\n",
            "Training batch 1369 completed. Loss: 0.7023, Accuracy: 0.5477\n",
            "Training batch 1370 started.\n",
            "Training batch 1370 completed. Loss: 0.7022, Accuracy: 0.5478\n",
            "Training batch 1371 started.\n",
            "Training batch 1371 completed. Loss: 0.7022, Accuracy: 0.5477\n",
            "Training batch 1372 started.\n",
            "Training batch 1372 completed. Loss: 0.7022, Accuracy: 0.5477\n",
            "Training batch 1373 started.\n",
            "Training batch 1373 completed. Loss: 0.7022, Accuracy: 0.5478\n",
            "Training batch 1374 started.\n",
            "Training batch 1374 completed. Loss: 0.7021, Accuracy: 0.5479\n",
            "Training batch 1375 started.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnknownError",
          "evalue": "Graph execution error:\n\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\nFileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/Image/real_vs_fake/real-vs-fake/train/real/34435.jpg'\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/data_adapter.py\", line 917, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/data_adapter.py\", line 1064, in generator_fn\n    yield x[i]\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/preprocessing/image.py\", line 116, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/preprocessing/image.py\", line 370, in _get_batches_of_transformed_samples\n    img = image_utils.load_img(\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/image_utils.py\", line 422, in load_img\n    with open(path, \"rb\") as f:\n\nFileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/Image/real_vs_fake/real-vs-fake/train/real/34435.jpg'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_1469]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-934549e8e283>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Ideally, use a separate validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\nFileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/Image/real_vs_fake/real-vs-fake/train/real/34435.jpg'\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/data_adapter.py\", line 917, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/data_adapter.py\", line 1064, in generator_fn\n    yield x[i]\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/preprocessing/image.py\", line 116, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/preprocessing/image.py\", line 370, in _get_batches_of_transformed_samples\n    img = image_utils.load_img(\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/image_utils.py\", line 422, in load_img\n    with open(path, \"rb\") as f:\n\nFileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/Image/real_vs_fake/real-vs-fake/train/real/34435.jpg'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_1469]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('model_weights_interrupted.h5')"
      ],
      "metadata": {
        "id": "BJ0J79N21W3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint = ModelCheckpoint('model_checkpoint.h5', save_best_only=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "5cH1Bv_Ia4qN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('/content/drive/MyDrive/Image/model_checkpoint.h5')"
      ],
      "metadata": {
        "id": "lgEdWHj2ctk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('/content/drive/MyDrive/Image/model_weights_interrupted.h5')"
      ],
      "metadata": {
        "id": "MqzkWy2fcVcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Define resuming_training based on user input\n",
        "resume = input(\"Resume training from saved weights? (y/n): \")\n",
        "resuming_training = resume.lower() == 'y'\n",
        "\n",
        "# Load saved weights (if resuming)\n",
        "if resuming_training:\n",
        "    model.load_weights('/content/drive/MyDrive/Image/model_weights_interrupted.h5')\n",
        "\n",
        "# Model checkpoint callback\n",
        "#checkpoint = ModelCheckpoint('/content/drive/MyDrive/Image/model_checkpoint.h5', save_best_only=True)\n",
        "\n",
        "# Early stopping for validation loss improvement\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,  # Stop training after 5 epochs with no improvement\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "# TensorBoard for visualization\n",
        "tensorboard = tf.keras.callbacks.TensorBoard(\n",
        "    log_dir='logs',  # Directory for visualization data\n",
        "    histogram_freq=1,  # Track weight histograms during training\n",
        ")\n",
        "\n",
        "# Custom accuracy logging callback\n",
        "class AccuracyLogger(tf.keras.callbacks.Callback):\n",
        "    def on_train_batch_end(self, batch, logs):\n",
        "        print(f\"Train batch {batch+1}: Accuracy = {logs['accuracy']:.4f}\")\n",
        "\n",
        "    def on_test_batch_end(self, batch, logs):\n",
        "        print(f\"Validation batch {batch+1}: Accuracy = {logs['accuracy']:.4f}\")\n",
        "\n",
        "# Start or resume training\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=test_generator,\n",
        "    epochs=10,  # Adjust as needed\n",
        "    verbose=2,\n",
        "    initial_epoch=2 ,#(Start from epoch 2 if resuming),\n",
        "    steps_per_epoch=100,  # Optional for remaining batches\n",
        "    callbacks=[\n",
        "        #checkpoint,\n",
        "        early_stopping,\n",
        "        tensorboard,\n",
        "        AccuracyLogger(),\n",
        "        # ... other callbacks ...\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Save final weights\n",
        "model.save_weights('/content/drive/MyDrive/Image/model_final_weights.h5')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7rcB8uplcZ-T",
        "outputId": "6c8d6ec4-89f5-49ff-919f-c3be2d1f9c95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resume training from saved weights? (y/n): y\n",
            "Epoch 3/10\n",
            "Train batch 1: Accuracy = 0.0312\n",
            "Train batch 2: Accuracy = 0.5156\n",
            "Train batch 3: Accuracy = 0.6771\n",
            "Train batch 4: Accuracy = 0.7578\n",
            "Train batch 5: Accuracy = 0.8062\n",
            "Train batch 6: Accuracy = 0.8385\n",
            "Train batch 7: Accuracy = 0.8616\n",
            "Train batch 8: Accuracy = 0.8789\n",
            "Train batch 9: Accuracy = 0.8924\n",
            "Train batch 10: Accuracy = 0.9031\n",
            "Train batch 11: Accuracy = 0.9119\n",
            "Train batch 12: Accuracy = 0.9193\n",
            "Train batch 13: Accuracy = 0.9255\n",
            "Train batch 14: Accuracy = 0.9308\n",
            "Train batch 15: Accuracy = 0.9354\n",
            "Train batch 16: Accuracy = 0.9395\n",
            "Train batch 17: Accuracy = 0.9430\n",
            "Train batch 18: Accuracy = 0.9462\n",
            "Train batch 19: Accuracy = 0.9490\n",
            "Train batch 20: Accuracy = 0.9516\n",
            "Train batch 21: Accuracy = 0.9539\n",
            "Train batch 22: Accuracy = 0.9560\n",
            "Train batch 23: Accuracy = 0.9579\n",
            "Train batch 24: Accuracy = 0.9596\n",
            "Train batch 25: Accuracy = 0.9613\n",
            "Train batch 26: Accuracy = 0.9627\n",
            "Train batch 27: Accuracy = 0.9641\n",
            "Train batch 28: Accuracy = 0.9654\n",
            "Train batch 29: Accuracy = 0.9666\n",
            "Train batch 30: Accuracy = 0.9677\n",
            "Train batch 31: Accuracy = 0.9688\n",
            "Train batch 32: Accuracy = 0.9697\n",
            "Train batch 33: Accuracy = 0.9706\n",
            "Train batch 34: Accuracy = 0.9715\n",
            "Train batch 35: Accuracy = 0.9723\n",
            "Train batch 36: Accuracy = 0.9731\n",
            "Train batch 37: Accuracy = 0.9738\n",
            "Train batch 38: Accuracy = 0.9745\n",
            "Train batch 39: Accuracy = 0.9752\n",
            "Train batch 40: Accuracy = 0.9758\n",
            "Train batch 41: Accuracy = 0.9764\n",
            "Train batch 42: Accuracy = 0.9769\n",
            "Train batch 43: Accuracy = 0.9775\n",
            "Train batch 44: Accuracy = 0.9780\n",
            "Train batch 45: Accuracy = 0.9785\n",
            "Train batch 46: Accuracy = 0.9789\n",
            "Train batch 47: Accuracy = 0.9794\n",
            "Train batch 48: Accuracy = 0.9798\n",
            "Train batch 49: Accuracy = 0.9802\n",
            "Train batch 50: Accuracy = 0.9806\n",
            "Train batch 51: Accuracy = 0.9810\n",
            "Train batch 52: Accuracy = 0.9814\n",
            "Train batch 53: Accuracy = 0.9817\n",
            "Train batch 54: Accuracy = 0.9821\n",
            "Train batch 55: Accuracy = 0.9824\n",
            "Train batch 56: Accuracy = 0.9827\n",
            "Train batch 57: Accuracy = 0.9830\n",
            "Train batch 58: Accuracy = 0.9833\n",
            "Train batch 59: Accuracy = 0.9836\n",
            "Train batch 60: Accuracy = 0.9839\n",
            "Train batch 61: Accuracy = 0.9841\n",
            "Train batch 62: Accuracy = 0.9844\n",
            "Train batch 63: Accuracy = 0.9846\n",
            "Train batch 64: Accuracy = 0.9849\n",
            "Train batch 65: Accuracy = 0.9851\n",
            "Train batch 66: Accuracy = 0.9853\n",
            "Train batch 67: Accuracy = 0.9855\n",
            "Train batch 68: Accuracy = 0.9858\n",
            "Train batch 69: Accuracy = 0.9860\n",
            "Train batch 70: Accuracy = 0.9862\n",
            "Train batch 71: Accuracy = 0.9864\n",
            "Train batch 72: Accuracy = 0.9865\n",
            "Train batch 73: Accuracy = 0.9867\n",
            "Train batch 74: Accuracy = 0.9869\n",
            "Train batch 75: Accuracy = 0.9871\n",
            "Train batch 76: Accuracy = 0.9873\n",
            "Train batch 77: Accuracy = 0.9874\n",
            "Train batch 78: Accuracy = 0.9876\n",
            "Train batch 79: Accuracy = 0.9877\n",
            "Train batch 80: Accuracy = 0.9879\n",
            "Train batch 81: Accuracy = 0.9880\n",
            "Train batch 82: Accuracy = 0.9882\n",
            "Train batch 83: Accuracy = 0.9883\n",
            "Train batch 84: Accuracy = 0.9885\n",
            "Train batch 85: Accuracy = 0.9886\n",
            "Train batch 86: Accuracy = 0.9887\n",
            "Train batch 87: Accuracy = 0.9889\n",
            "Train batch 88: Accuracy = 0.9890\n",
            "Train batch 89: Accuracy = 0.9891\n",
            "Train batch 90: Accuracy = 0.9892\n",
            "Train batch 91: Accuracy = 0.9894\n",
            "Train batch 92: Accuracy = 0.9895\n",
            "Train batch 93: Accuracy = 0.9896\n",
            "Train batch 94: Accuracy = 0.9897\n",
            "Train batch 95: Accuracy = 0.9898\n",
            "Train batch 96: Accuracy = 0.9899\n",
            "Train batch 97: Accuracy = 0.9900\n",
            "Train batch 98: Accuracy = 0.9901\n",
            "Train batch 99: Accuracy = 0.9902\n",
            "Train batch 100: Accuracy = 0.9903\n",
            "Validation batch 1: Accuracy = 0.5312\n",
            "Validation batch 2: Accuracy = 0.5625\n",
            "Validation batch 3: Accuracy = 0.5521\n",
            "Validation batch 4: Accuracy = 0.5391\n",
            "Validation batch 5: Accuracy = 0.5375\n",
            "Validation batch 6: Accuracy = 0.5521\n",
            "Validation batch 7: Accuracy = 0.5491\n",
            "Validation batch 8: Accuracy = 0.5586\n",
            "Validation batch 9: Accuracy = 0.5451\n",
            "Validation batch 10: Accuracy = 0.5437\n",
            "Validation batch 11: Accuracy = 0.5341\n",
            "Validation batch 12: Accuracy = 0.5312\n",
            "Validation batch 13: Accuracy = 0.5168\n",
            "Validation batch 14: Accuracy = 0.5112\n",
            "Validation batch 15: Accuracy = 0.5188\n",
            "Validation batch 16: Accuracy = 0.5215\n",
            "Validation batch 17: Accuracy = 0.5184\n",
            "Validation batch 18: Accuracy = 0.5139\n",
            "Validation batch 19: Accuracy = 0.5082\n",
            "Validation batch 20: Accuracy = 0.5047\n",
            "Validation batch 21: Accuracy = 0.5104\n",
            "Validation batch 22: Accuracy = 0.5128\n",
            "Validation batch 23: Accuracy = 0.5136\n",
            "Validation batch 24: Accuracy = 0.5104\n",
            "Validation batch 25: Accuracy = 0.5038\n",
            "Validation batch 26: Accuracy = 0.5036\n",
            "Validation batch 27: Accuracy = 0.5012\n",
            "Validation batch 28: Accuracy = 0.5022\n",
            "Validation batch 29: Accuracy = 0.5011\n",
            "Validation batch 30: Accuracy = 0.5000\n",
            "Validation batch 31: Accuracy = 0.4960\n",
            "Validation batch 32: Accuracy = 0.4922\n",
            "Validation batch 33: Accuracy = 0.4924\n",
            "Validation batch 34: Accuracy = 0.4945\n",
            "Validation batch 35: Accuracy = 0.5009\n",
            "Validation batch 36: Accuracy = 0.5017\n",
            "Validation batch 37: Accuracy = 0.5034\n",
            "Validation batch 38: Accuracy = 0.5025\n",
            "Validation batch 39: Accuracy = 0.5000\n",
            "Validation batch 40: Accuracy = 0.5047\n",
            "Validation batch 41: Accuracy = 0.5061\n",
            "Validation batch 42: Accuracy = 0.5045\n",
            "Validation batch 43: Accuracy = 0.5036\n",
            "Validation batch 44: Accuracy = 0.5050\n",
            "Validation batch 45: Accuracy = 0.5035\n",
            "Validation batch 46: Accuracy = 0.5034\n",
            "Validation batch 47: Accuracy = 0.5040\n",
            "Validation batch 48: Accuracy = 0.5033\n",
            "Validation batch 49: Accuracy = 0.5013\n",
            "Validation batch 50: Accuracy = 0.5025\n",
            "Validation batch 51: Accuracy = 0.4969\n",
            "Validation batch 52: Accuracy = 0.4946\n",
            "Validation batch 53: Accuracy = 0.4941\n",
            "Validation batch 54: Accuracy = 0.4954\n",
            "Validation batch 55: Accuracy = 0.4943\n",
            "Validation batch 56: Accuracy = 0.4944\n",
            "Validation batch 57: Accuracy = 0.4945\n",
            "Validation batch 58: Accuracy = 0.4935\n",
            "Validation batch 59: Accuracy = 0.4926\n",
            "Validation batch 60: Accuracy = 0.4927\n",
            "Validation batch 61: Accuracy = 0.4928\n",
            "Validation batch 62: Accuracy = 0.4940\n",
            "Validation batch 63: Accuracy = 0.4936\n",
            "Validation batch 64: Accuracy = 0.4927\n",
            "Validation batch 65: Accuracy = 0.4913\n",
            "Validation batch 66: Accuracy = 0.4929\n",
            "Validation batch 67: Accuracy = 0.4930\n",
            "Validation batch 68: Accuracy = 0.4936\n",
            "Validation batch 69: Accuracy = 0.4941\n",
            "Validation batch 70: Accuracy = 0.4938\n",
            "Validation batch 71: Accuracy = 0.4930\n",
            "Validation batch 72: Accuracy = 0.4926\n",
            "Validation batch 73: Accuracy = 0.4936\n",
            "Validation batch 74: Accuracy = 0.4932\n",
            "Validation batch 75: Accuracy = 0.4921\n",
            "Validation batch 76: Accuracy = 0.4918\n",
            "Validation batch 77: Accuracy = 0.4927\n",
            "Validation batch 78: Accuracy = 0.4928\n",
            "Validation batch 79: Accuracy = 0.4933\n",
            "Validation batch 80: Accuracy = 0.4922\n",
            "Validation batch 81: Accuracy = 0.4919\n",
            "Validation batch 82: Accuracy = 0.4920\n",
            "Validation batch 83: Accuracy = 0.4895\n",
            "Validation batch 84: Accuracy = 0.4896\n",
            "Validation batch 85: Accuracy = 0.4908\n",
            "Validation batch 86: Accuracy = 0.4913\n",
            "Validation batch 87: Accuracy = 0.4903\n",
            "Validation batch 88: Accuracy = 0.4893\n",
            "Validation batch 89: Accuracy = 0.4881\n",
            "Validation batch 90: Accuracy = 0.4899\n",
            "Validation batch 91: Accuracy = 0.4880\n",
            "Validation batch 92: Accuracy = 0.4881\n",
            "Validation batch 93: Accuracy = 0.4889\n",
            "Validation batch 94: Accuracy = 0.4910\n",
            "Validation batch 95: Accuracy = 0.4905\n",
            "Validation batch 96: Accuracy = 0.4928\n",
            "Validation batch 97: Accuracy = 0.4939\n",
            "Validation batch 98: Accuracy = 0.4933\n",
            "Validation batch 99: Accuracy = 0.4949\n",
            "Validation batch 100: Accuracy = 0.4947\n",
            "Validation batch 101: Accuracy = 0.4950\n",
            "Validation batch 102: Accuracy = 0.4945\n",
            "Validation batch 103: Accuracy = 0.4942\n",
            "Validation batch 104: Accuracy = 0.4931\n",
            "Validation batch 105: Accuracy = 0.4952\n",
            "Validation batch 106: Accuracy = 0.4956\n",
            "Validation batch 107: Accuracy = 0.4953\n",
            "Validation batch 108: Accuracy = 0.4942\n",
            "Validation batch 109: Accuracy = 0.4960\n",
            "Validation batch 110: Accuracy = 0.4963\n",
            "Validation batch 111: Accuracy = 0.4977\n",
            "Validation batch 112: Accuracy = 0.4980\n",
            "Validation batch 113: Accuracy = 0.4975\n",
            "Validation batch 114: Accuracy = 0.4973\n",
            "Validation batch 115: Accuracy = 0.4965\n",
            "Validation batch 116: Accuracy = 0.4965\n",
            "Validation batch 117: Accuracy = 0.4981\n",
            "Validation batch 118: Accuracy = 0.4984\n",
            "Validation batch 119: Accuracy = 0.4976\n",
            "Validation batch 120: Accuracy = 0.4956\n",
            "Validation batch 121: Accuracy = 0.4954\n",
            "Validation batch 122: Accuracy = 0.4954\n",
            "Validation batch 123: Accuracy = 0.4957\n",
            "Validation batch 124: Accuracy = 0.4957\n",
            "Validation batch 125: Accuracy = 0.4955\n",
            "Validation batch 126: Accuracy = 0.4963\n",
            "Validation batch 127: Accuracy = 0.4968\n",
            "Validation batch 128: Accuracy = 0.4961\n",
            "Validation batch 129: Accuracy = 0.4949\n",
            "Validation batch 130: Accuracy = 0.4959\n",
            "Validation batch 131: Accuracy = 0.4957\n",
            "Validation batch 132: Accuracy = 0.4960\n",
            "Validation batch 133: Accuracy = 0.4955\n",
            "Validation batch 134: Accuracy = 0.4956\n",
            "Validation batch 135: Accuracy = 0.4956\n",
            "Validation batch 136: Accuracy = 0.4956\n",
            "Validation batch 137: Accuracy = 0.4948\n",
            "Validation batch 138: Accuracy = 0.4946\n",
            "Validation batch 139: Accuracy = 0.4948\n",
            "Validation batch 140: Accuracy = 0.4955\n",
            "Validation batch 141: Accuracy = 0.4960\n",
            "Validation batch 142: Accuracy = 0.4963\n",
            "Validation batch 143: Accuracy = 0.4967\n",
            "Validation batch 144: Accuracy = 0.4961\n",
            "Validation batch 145: Accuracy = 0.4950\n",
            "Validation batch 146: Accuracy = 0.4959\n",
            "Validation batch 147: Accuracy = 0.4962\n",
            "Validation batch 148: Accuracy = 0.4960\n",
            "Validation batch 149: Accuracy = 0.4964\n",
            "Validation batch 150: Accuracy = 0.4954\n",
            "Validation batch 151: Accuracy = 0.4957\n",
            "Validation batch 152: Accuracy = 0.4961\n",
            "Validation batch 153: Accuracy = 0.4953\n",
            "Validation batch 154: Accuracy = 0.4951\n",
            "Validation batch 155: Accuracy = 0.4950\n",
            "Validation batch 156: Accuracy = 0.4956\n",
            "Validation batch 157: Accuracy = 0.4958\n",
            "Validation batch 158: Accuracy = 0.4951\n",
            "Validation batch 159: Accuracy = 0.4951\n",
            "Validation batch 160: Accuracy = 0.4953\n",
            "Validation batch 161: Accuracy = 0.4959\n",
            "Validation batch 162: Accuracy = 0.4950\n",
            "Validation batch 163: Accuracy = 0.4946\n",
            "Validation batch 164: Accuracy = 0.4939\n",
            "Validation batch 165: Accuracy = 0.4939\n",
            "Validation batch 166: Accuracy = 0.4934\n",
            "Validation batch 167: Accuracy = 0.4938\n",
            "Validation batch 168: Accuracy = 0.4939\n",
            "Validation batch 169: Accuracy = 0.4948\n",
            "Validation batch 170: Accuracy = 0.4950\n",
            "Validation batch 171: Accuracy = 0.4951\n",
            "Validation batch 172: Accuracy = 0.4951\n",
            "Validation batch 173: Accuracy = 0.4951\n",
            "Validation batch 174: Accuracy = 0.4950\n",
            "Validation batch 175: Accuracy = 0.4959\n",
            "Validation batch 176: Accuracy = 0.4964\n",
            "Validation batch 177: Accuracy = 0.4963\n",
            "Validation batch 178: Accuracy = 0.4970\n",
            "Validation batch 179: Accuracy = 0.4972\n",
            "Validation batch 180: Accuracy = 0.4967\n",
            "Validation batch 181: Accuracy = 0.4967\n",
            "Validation batch 182: Accuracy = 0.4966\n",
            "Validation batch 183: Accuracy = 0.4961\n",
            "Validation batch 184: Accuracy = 0.4956\n",
            "Validation batch 185: Accuracy = 0.4961\n",
            "Validation batch 186: Accuracy = 0.4961\n",
            "Validation batch 187: Accuracy = 0.4963\n",
            "Validation batch 188: Accuracy = 0.4957\n",
            "Validation batch 189: Accuracy = 0.4957\n",
            "Validation batch 190: Accuracy = 0.4959\n",
            "Validation batch 191: Accuracy = 0.4966\n",
            "Validation batch 192: Accuracy = 0.4969\n",
            "Validation batch 193: Accuracy = 0.4964\n",
            "Validation batch 194: Accuracy = 0.4965\n",
            "Validation batch 195: Accuracy = 0.4962\n",
            "Validation batch 196: Accuracy = 0.4963\n",
            "Validation batch 197: Accuracy = 0.4964\n",
            "Validation batch 198: Accuracy = 0.4961\n",
            "Validation batch 199: Accuracy = 0.4964\n",
            "Validation batch 200: Accuracy = 0.4970\n",
            "Validation batch 201: Accuracy = 0.4966\n",
            "Validation batch 202: Accuracy = 0.4966\n",
            "Validation batch 203: Accuracy = 0.4963\n",
            "Validation batch 204: Accuracy = 0.4962\n",
            "Validation batch 205: Accuracy = 0.4956\n",
            "Validation batch 206: Accuracy = 0.4956\n",
            "Validation batch 207: Accuracy = 0.4958\n",
            "Validation batch 208: Accuracy = 0.4965\n",
            "Validation batch 209: Accuracy = 0.4964\n",
            "Validation batch 210: Accuracy = 0.4960\n",
            "Validation batch 211: Accuracy = 0.4966\n",
            "Validation batch 212: Accuracy = 0.4971\n",
            "Validation batch 213: Accuracy = 0.4972\n",
            "Validation batch 214: Accuracy = 0.4971\n",
            "Validation batch 215: Accuracy = 0.4972\n",
            "Validation batch 216: Accuracy = 0.4980\n",
            "Validation batch 217: Accuracy = 0.4983\n",
            "Validation batch 218: Accuracy = 0.4983\n",
            "Validation batch 219: Accuracy = 0.4987\n",
            "Validation batch 220: Accuracy = 0.4989\n",
            "Validation batch 221: Accuracy = 0.4986\n",
            "Validation batch 222: Accuracy = 0.4993\n",
            "Validation batch 223: Accuracy = 0.4992\n",
            "Validation batch 224: Accuracy = 0.4994\n",
            "Validation batch 225: Accuracy = 0.4997\n",
            "Validation batch 226: Accuracy = 0.5001\n",
            "Validation batch 227: Accuracy = 0.4999\n",
            "Validation batch 228: Accuracy = 0.4997\n",
            "Validation batch 229: Accuracy = 0.4999\n",
            "Validation batch 230: Accuracy = 0.4999\n",
            "Validation batch 231: Accuracy = 0.4999\n",
            "Validation batch 232: Accuracy = 0.4992\n",
            "Validation batch 233: Accuracy = 0.4993\n",
            "Validation batch 234: Accuracy = 0.4993\n",
            "Validation batch 235: Accuracy = 0.4991\n",
            "Validation batch 236: Accuracy = 0.4993\n",
            "Validation batch 237: Accuracy = 0.4995\n",
            "Validation batch 238: Accuracy = 0.4997\n",
            "Validation batch 239: Accuracy = 0.5004\n",
            "Validation batch 240: Accuracy = 0.5003\n",
            "Validation batch 241: Accuracy = 0.5005\n",
            "Validation batch 242: Accuracy = 0.5009\n",
            "Validation batch 243: Accuracy = 0.5014\n",
            "Validation batch 244: Accuracy = 0.5013\n",
            "Validation batch 245: Accuracy = 0.5013\n",
            "Validation batch 246: Accuracy = 0.5022\n",
            "Validation batch 247: Accuracy = 0.5027\n",
            "Validation batch 248: Accuracy = 0.5019\n",
            "Validation batch 249: Accuracy = 0.5013\n",
            "Validation batch 250: Accuracy = 0.5019\n",
            "Validation batch 251: Accuracy = 0.5025\n",
            "Validation batch 252: Accuracy = 0.5022\n",
            "Validation batch 253: Accuracy = 0.5025\n",
            "Validation batch 254: Accuracy = 0.5022\n",
            "Validation batch 255: Accuracy = 0.5025\n",
            "Validation batch 256: Accuracy = 0.5027\n",
            "Validation batch 257: Accuracy = 0.5024\n",
            "Validation batch 258: Accuracy = 0.5022\n",
            "Validation batch 259: Accuracy = 0.5027\n",
            "Validation batch 260: Accuracy = 0.5031\n",
            "Validation batch 261: Accuracy = 0.5028\n",
            "Validation batch 262: Accuracy = 0.5026\n",
            "Validation batch 263: Accuracy = 0.5026\n",
            "Validation batch 264: Accuracy = 0.5024\n",
            "Validation batch 265: Accuracy = 0.5021\n",
            "Validation batch 266: Accuracy = 0.5019\n",
            "Validation batch 267: Accuracy = 0.5018\n",
            "Validation batch 268: Accuracy = 0.5016\n",
            "Validation batch 269: Accuracy = 0.5021\n",
            "Validation batch 270: Accuracy = 0.5016\n",
            "Validation batch 271: Accuracy = 0.5016\n",
            "Validation batch 272: Accuracy = 0.5015\n",
            "Validation batch 273: Accuracy = 0.5015\n",
            "Validation batch 274: Accuracy = 0.5018\n",
            "Validation batch 275: Accuracy = 0.5019\n",
            "Validation batch 276: Accuracy = 0.5018\n",
            "Validation batch 277: Accuracy = 0.5021\n",
            "Validation batch 278: Accuracy = 0.5021\n",
            "Validation batch 279: Accuracy = 0.5021\n",
            "Validation batch 280: Accuracy = 0.5025\n",
            "Validation batch 281: Accuracy = 0.5023\n",
            "Validation batch 282: Accuracy = 0.5027\n",
            "Validation batch 283: Accuracy = 0.5030\n",
            "Validation batch 284: Accuracy = 0.5031\n",
            "Validation batch 285: Accuracy = 0.5036\n",
            "Validation batch 286: Accuracy = 0.5032\n",
            "Validation batch 287: Accuracy = 0.5037\n",
            "Validation batch 288: Accuracy = 0.5041\n",
            "Validation batch 289: Accuracy = 0.5042\n",
            "Validation batch 290: Accuracy = 0.5042\n",
            "Validation batch 291: Accuracy = 0.5043\n",
            "Validation batch 292: Accuracy = 0.5044\n",
            "Validation batch 293: Accuracy = 0.5045\n",
            "Validation batch 294: Accuracy = 0.5045\n",
            "Validation batch 295: Accuracy = 0.5049\n",
            "Validation batch 296: Accuracy = 0.5048\n",
            "Validation batch 297: Accuracy = 0.5047\n",
            "Validation batch 298: Accuracy = 0.5042\n",
            "Validation batch 299: Accuracy = 0.5046\n",
            "Validation batch 300: Accuracy = 0.5045\n",
            "Validation batch 301: Accuracy = 0.5046\n",
            "Validation batch 302: Accuracy = 0.5039\n",
            "Validation batch 303: Accuracy = 0.5037\n",
            "Validation batch 304: Accuracy = 0.5036\n",
            "Validation batch 305: Accuracy = 0.5036\n",
            "Validation batch 306: Accuracy = 0.5036\n",
            "Validation batch 307: Accuracy = 0.5032\n",
            "Validation batch 308: Accuracy = 0.5028\n",
            "Validation batch 309: Accuracy = 0.5024\n",
            "Validation batch 310: Accuracy = 0.5021\n",
            "Validation batch 311: Accuracy = 0.5019\n",
            "Validation batch 312: Accuracy = 0.5022\n",
            "Validation batch 313: Accuracy = 0.5024\n",
            "Validation batch 314: Accuracy = 0.5018\n",
            "Validation batch 315: Accuracy = 0.5018\n",
            "Validation batch 316: Accuracy = 0.5018\n",
            "Validation batch 317: Accuracy = 0.5016\n",
            "Validation batch 318: Accuracy = 0.5017\n",
            "Validation batch 319: Accuracy = 0.5016\n",
            "Validation batch 320: Accuracy = 0.5018\n",
            "Validation batch 321: Accuracy = 0.5022\n",
            "Validation batch 322: Accuracy = 0.5019\n",
            "Validation batch 323: Accuracy = 0.5020\n",
            "Validation batch 324: Accuracy = 0.5026\n",
            "Validation batch 325: Accuracy = 0.5025\n",
            "Validation batch 326: Accuracy = 0.5029\n",
            "Validation batch 327: Accuracy = 0.5024\n",
            "Validation batch 328: Accuracy = 0.5030\n",
            "Validation batch 329: Accuracy = 0.5029\n",
            "Validation batch 330: Accuracy = 0.5029\n",
            "Validation batch 331: Accuracy = 0.5027\n",
            "Validation batch 332: Accuracy = 0.5026\n",
            "Validation batch 333: Accuracy = 0.5029\n",
            "Validation batch 334: Accuracy = 0.5027\n",
            "Validation batch 335: Accuracy = 0.5029\n",
            "Validation batch 336: Accuracy = 0.5030\n",
            "Validation batch 337: Accuracy = 0.5030\n",
            "Validation batch 338: Accuracy = 0.5028\n",
            "Validation batch 339: Accuracy = 0.5028\n",
            "Validation batch 340: Accuracy = 0.5023\n",
            "Validation batch 341: Accuracy = 0.5023\n",
            "Validation batch 342: Accuracy = 0.5025\n",
            "Validation batch 343: Accuracy = 0.5021\n",
            "Validation batch 344: Accuracy = 0.5016\n",
            "Validation batch 345: Accuracy = 0.5014\n",
            "Validation batch 346: Accuracy = 0.5011\n",
            "Validation batch 347: Accuracy = 0.5013\n",
            "Validation batch 348: Accuracy = 0.5012\n",
            "Validation batch 349: Accuracy = 0.5012\n",
            "Validation batch 350: Accuracy = 0.5017\n",
            "Validation batch 351: Accuracy = 0.5015\n",
            "Validation batch 352: Accuracy = 0.5014\n",
            "Validation batch 353: Accuracy = 0.5013\n",
            "Validation batch 354: Accuracy = 0.5015\n",
            "Validation batch 355: Accuracy = 0.5018\n",
            "Validation batch 356: Accuracy = 0.5016\n",
            "Validation batch 357: Accuracy = 0.5016\n",
            "Validation batch 358: Accuracy = 0.5014\n",
            "Validation batch 359: Accuracy = 0.5014\n",
            "Validation batch 360: Accuracy = 0.5013\n",
            "Validation batch 361: Accuracy = 0.5010\n",
            "Validation batch 362: Accuracy = 0.5012\n",
            "Validation batch 363: Accuracy = 0.5015\n",
            "Validation batch 364: Accuracy = 0.5014\n",
            "Validation batch 365: Accuracy = 0.5015\n",
            "Validation batch 366: Accuracy = 0.5017\n",
            "Validation batch 367: Accuracy = 0.5014\n",
            "Validation batch 368: Accuracy = 0.5014\n",
            "Validation batch 369: Accuracy = 0.5017\n",
            "Validation batch 370: Accuracy = 0.5018\n",
            "Validation batch 371: Accuracy = 0.5023\n",
            "Validation batch 372: Accuracy = 0.5023\n",
            "Validation batch 373: Accuracy = 0.5023\n",
            "Validation batch 374: Accuracy = 0.5024\n",
            "Validation batch 375: Accuracy = 0.5024\n",
            "Validation batch 376: Accuracy = 0.5025\n",
            "Validation batch 377: Accuracy = 0.5025\n",
            "Validation batch 378: Accuracy = 0.5023\n",
            "Validation batch 379: Accuracy = 0.5024\n",
            "Validation batch 380: Accuracy = 0.5025\n",
            "Validation batch 381: Accuracy = 0.5023\n",
            "Validation batch 382: Accuracy = 0.5021\n",
            "Validation batch 383: Accuracy = 0.5022\n",
            "Validation batch 384: Accuracy = 0.5020\n",
            "Validation batch 385: Accuracy = 0.5024\n",
            "Validation batch 386: Accuracy = 0.5023\n",
            "Validation batch 387: Accuracy = 0.5020\n",
            "Validation batch 388: Accuracy = 0.5017\n",
            "Validation batch 389: Accuracy = 0.5018\n",
            "Validation batch 390: Accuracy = 0.5018\n",
            "Validation batch 391: Accuracy = 0.5017\n",
            "Validation batch 392: Accuracy = 0.5018\n",
            "Validation batch 393: Accuracy = 0.5018\n",
            "Validation batch 394: Accuracy = 0.5024\n",
            "Validation batch 395: Accuracy = 0.5022\n",
            "Validation batch 396: Accuracy = 0.5024\n",
            "Validation batch 397: Accuracy = 0.5021\n",
            "Validation batch 398: Accuracy = 0.5017\n",
            "Validation batch 399: Accuracy = 0.5019\n",
            "Validation batch 400: Accuracy = 0.5017\n",
            "Validation batch 401: Accuracy = 0.5016\n",
            "Validation batch 402: Accuracy = 0.5012\n",
            "Validation batch 403: Accuracy = 0.5012\n",
            "Validation batch 404: Accuracy = 0.5012\n",
            "Validation batch 405: Accuracy = 0.5014\n",
            "Validation batch 406: Accuracy = 0.5010\n",
            "Validation batch 407: Accuracy = 0.5012\n",
            "Validation batch 408: Accuracy = 0.5009\n",
            "Validation batch 409: Accuracy = 0.5008\n",
            "Validation batch 410: Accuracy = 0.5007\n",
            "Validation batch 411: Accuracy = 0.5005\n",
            "Validation batch 412: Accuracy = 0.5006\n",
            "Validation batch 413: Accuracy = 0.5002\n",
            "Validation batch 414: Accuracy = 0.5002\n",
            "Validation batch 415: Accuracy = 0.5001\n",
            "Validation batch 416: Accuracy = 0.5005\n",
            "Validation batch 417: Accuracy = 0.5006\n",
            "Validation batch 418: Accuracy = 0.5004\n",
            "Validation batch 419: Accuracy = 0.5004\n",
            "Validation batch 420: Accuracy = 0.5000\n",
            "Validation batch 421: Accuracy = 0.5000\n",
            "Validation batch 422: Accuracy = 0.4998\n",
            "Validation batch 423: Accuracy = 0.5001\n",
            "Validation batch 424: Accuracy = 0.5004\n",
            "Validation batch 425: Accuracy = 0.5004\n",
            "Validation batch 426: Accuracy = 0.5007\n",
            "Validation batch 427: Accuracy = 0.5004\n",
            "Validation batch 428: Accuracy = 0.5006\n",
            "Validation batch 429: Accuracy = 0.5007\n",
            "Validation batch 430: Accuracy = 0.5007\n",
            "Validation batch 431: Accuracy = 0.5005\n",
            "Validation batch 432: Accuracy = 0.5005\n",
            "Validation batch 433: Accuracy = 0.5003\n",
            "Validation batch 434: Accuracy = 0.5006\n",
            "Validation batch 435: Accuracy = 0.5009\n",
            "Validation batch 436: Accuracy = 0.5009\n",
            "Validation batch 437: Accuracy = 0.5011\n",
            "Validation batch 438: Accuracy = 0.5013\n",
            "Validation batch 439: Accuracy = 0.5010\n",
            "Validation batch 440: Accuracy = 0.5009\n",
            "Validation batch 441: Accuracy = 0.5010\n",
            "Validation batch 442: Accuracy = 0.5010\n",
            "Validation batch 443: Accuracy = 0.5009\n",
            "Validation batch 444: Accuracy = 0.5008\n",
            "Validation batch 445: Accuracy = 0.5010\n",
            "Validation batch 446: Accuracy = 0.5011\n",
            "Validation batch 447: Accuracy = 0.5012\n",
            "Validation batch 448: Accuracy = 0.5014\n",
            "Validation batch 449: Accuracy = 0.5010\n",
            "Validation batch 450: Accuracy = 0.5008\n",
            "Validation batch 451: Accuracy = 0.5010\n",
            "Validation batch 452: Accuracy = 0.5009\n",
            "Validation batch 453: Accuracy = 0.5009\n",
            "Validation batch 454: Accuracy = 0.5008\n",
            "Validation batch 455: Accuracy = 0.5005\n",
            "Validation batch 456: Accuracy = 0.5005\n",
            "Validation batch 457: Accuracy = 0.5006\n",
            "Validation batch 458: Accuracy = 0.5005\n",
            "Validation batch 459: Accuracy = 0.5006\n",
            "Validation batch 460: Accuracy = 0.5005\n",
            "Validation batch 461: Accuracy = 0.5007\n",
            "Validation batch 462: Accuracy = 0.5007\n",
            "Validation batch 463: Accuracy = 0.5009\n",
            "Validation batch 464: Accuracy = 0.5007\n",
            "Validation batch 465: Accuracy = 0.5007\n",
            "Validation batch 466: Accuracy = 0.5007\n",
            "Validation batch 467: Accuracy = 0.5007\n",
            "Validation batch 468: Accuracy = 0.5010\n",
            "Validation batch 469: Accuracy = 0.5009\n",
            "Validation batch 470: Accuracy = 0.5009\n",
            "Validation batch 471: Accuracy = 0.5008\n",
            "Validation batch 472: Accuracy = 0.5007\n",
            "Validation batch 473: Accuracy = 0.5007\n",
            "Validation batch 474: Accuracy = 0.5009\n",
            "Validation batch 475: Accuracy = 0.5006\n",
            "Validation batch 476: Accuracy = 0.5007\n",
            "Validation batch 477: Accuracy = 0.5008\n",
            "Validation batch 478: Accuracy = 0.5008\n",
            "Validation batch 479: Accuracy = 0.5008\n",
            "Validation batch 480: Accuracy = 0.5007\n",
            "Validation batch 481: Accuracy = 0.5008\n",
            "Validation batch 482: Accuracy = 0.5005\n",
            "Validation batch 483: Accuracy = 0.5006\n",
            "Validation batch 484: Accuracy = 0.5008\n",
            "Validation batch 485: Accuracy = 0.5011\n",
            "Validation batch 486: Accuracy = 0.5011\n",
            "Validation batch 487: Accuracy = 0.5010\n",
            "Validation batch 488: Accuracy = 0.5010\n",
            "Validation batch 489: Accuracy = 0.5010\n",
            "Validation batch 490: Accuracy = 0.5007\n",
            "Validation batch 491: Accuracy = 0.5004\n",
            "Validation batch 492: Accuracy = 0.5001\n",
            "Validation batch 493: Accuracy = 0.5001\n",
            "Validation batch 494: Accuracy = 0.5002\n",
            "Validation batch 495: Accuracy = 0.5003\n",
            "Validation batch 496: Accuracy = 0.5004\n",
            "Validation batch 497: Accuracy = 0.5008\n",
            "Validation batch 498: Accuracy = 0.5007\n",
            "Validation batch 499: Accuracy = 0.5010\n",
            "Validation batch 500: Accuracy = 0.5010\n",
            "Validation batch 501: Accuracy = 0.5009\n",
            "Validation batch 502: Accuracy = 0.5010\n",
            "Validation batch 503: Accuracy = 0.5010\n",
            "Validation batch 504: Accuracy = 0.5009\n",
            "Validation batch 505: Accuracy = 0.5007\n",
            "Validation batch 506: Accuracy = 0.5007\n",
            "Validation batch 507: Accuracy = 0.5006\n",
            "Validation batch 508: Accuracy = 0.5005\n",
            "Validation batch 509: Accuracy = 0.5007\n",
            "Validation batch 510: Accuracy = 0.5003\n",
            "Validation batch 511: Accuracy = 0.5004\n",
            "Validation batch 512: Accuracy = 0.5004\n",
            "Validation batch 513: Accuracy = 0.5002\n",
            "Validation batch 514: Accuracy = 0.5004\n",
            "Validation batch 515: Accuracy = 0.5002\n",
            "Validation batch 516: Accuracy = 0.5004\n",
            "Validation batch 517: Accuracy = 0.5001\n",
            "Validation batch 518: Accuracy = 0.5004\n",
            "Validation batch 519: Accuracy = 0.5001\n",
            "Validation batch 520: Accuracy = 0.4999\n",
            "Validation batch 521: Accuracy = 0.5002\n",
            "Validation batch 522: Accuracy = 0.5002\n",
            "Validation batch 523: Accuracy = 0.5002\n",
            "Validation batch 524: Accuracy = 0.5004\n",
            "Validation batch 525: Accuracy = 0.5007\n",
            "Validation batch 526: Accuracy = 0.5005\n",
            "Validation batch 527: Accuracy = 0.5008\n",
            "Validation batch 528: Accuracy = 0.5007\n",
            "Validation batch 529: Accuracy = 0.5004\n",
            "Validation batch 530: Accuracy = 0.5004\n",
            "Validation batch 531: Accuracy = 0.5005\n",
            "Validation batch 532: Accuracy = 0.5006\n",
            "Validation batch 533: Accuracy = 0.5005\n",
            "Validation batch 534: Accuracy = 0.5004\n",
            "Validation batch 535: Accuracy = 0.5004\n",
            "Validation batch 536: Accuracy = 0.5008\n",
            "Validation batch 537: Accuracy = 0.5006\n",
            "Validation batch 538: Accuracy = 0.5006\n",
            "Validation batch 539: Accuracy = 0.5006\n",
            "Validation batch 540: Accuracy = 0.5002\n",
            "Validation batch 541: Accuracy = 0.4999\n",
            "Validation batch 542: Accuracy = 0.4998\n",
            "Validation batch 543: Accuracy = 0.4999\n",
            "Validation batch 544: Accuracy = 0.4998\n",
            "Validation batch 545: Accuracy = 0.4998\n",
            "Validation batch 546: Accuracy = 0.5000\n",
            "Validation batch 547: Accuracy = 0.5001\n",
            "Validation batch 548: Accuracy = 0.5001\n",
            "Validation batch 549: Accuracy = 0.5002\n",
            "Validation batch 550: Accuracy = 0.5003\n",
            "Validation batch 551: Accuracy = 0.5001\n",
            "Validation batch 552: Accuracy = 0.4998\n",
            "Validation batch 553: Accuracy = 0.5000\n",
            "Validation batch 554: Accuracy = 0.4997\n",
            "Validation batch 555: Accuracy = 0.4996\n",
            "Validation batch 556: Accuracy = 0.4997\n",
            "Validation batch 557: Accuracy = 0.4994\n",
            "Validation batch 558: Accuracy = 0.4994\n",
            "Validation batch 559: Accuracy = 0.4994\n",
            "Validation batch 560: Accuracy = 0.4994\n",
            "Validation batch 561: Accuracy = 0.4993\n",
            "Validation batch 562: Accuracy = 0.4992\n",
            "Validation batch 563: Accuracy = 0.4995\n",
            "Validation batch 564: Accuracy = 0.4996\n",
            "Validation batch 565: Accuracy = 0.4994\n",
            "Validation batch 566: Accuracy = 0.4993\n",
            "Validation batch 567: Accuracy = 0.4994\n",
            "Validation batch 568: Accuracy = 0.4994\n",
            "Validation batch 569: Accuracy = 0.4997\n",
            "Validation batch 570: Accuracy = 0.4997\n",
            "Validation batch 571: Accuracy = 0.4995\n",
            "Validation batch 572: Accuracy = 0.4995\n",
            "Validation batch 573: Accuracy = 0.4994\n",
            "Validation batch 574: Accuracy = 0.4997\n",
            "Validation batch 575: Accuracy = 0.4997\n",
            "Validation batch 576: Accuracy = 0.4999\n",
            "Validation batch 577: Accuracy = 0.4999\n",
            "Validation batch 578: Accuracy = 0.5000\n",
            "Validation batch 579: Accuracy = 0.5003\n",
            "Validation batch 580: Accuracy = 0.5001\n",
            "Validation batch 581: Accuracy = 0.5002\n",
            "Validation batch 582: Accuracy = 0.5004\n",
            "Validation batch 583: Accuracy = 0.5003\n",
            "Validation batch 584: Accuracy = 0.5002\n",
            "Validation batch 585: Accuracy = 0.5001\n",
            "Validation batch 586: Accuracy = 0.5001\n",
            "Validation batch 587: Accuracy = 0.5001\n",
            "Validation batch 588: Accuracy = 0.5000\n",
            "Validation batch 589: Accuracy = 0.5001\n",
            "Validation batch 590: Accuracy = 0.5001\n",
            "Validation batch 591: Accuracy = 0.5001\n",
            "Validation batch 592: Accuracy = 0.5001\n",
            "Validation batch 593: Accuracy = 0.4999\n",
            "Validation batch 594: Accuracy = 0.5000\n",
            "Validation batch 595: Accuracy = 0.5001\n",
            "Validation batch 596: Accuracy = 0.5002\n",
            "Validation batch 597: Accuracy = 0.5002\n",
            "Validation batch 598: Accuracy = 0.5002\n",
            "Validation batch 599: Accuracy = 0.5004\n",
            "Validation batch 600: Accuracy = 0.5003\n",
            "Validation batch 601: Accuracy = 0.5005\n",
            "Validation batch 602: Accuracy = 0.5006\n",
            "Validation batch 603: Accuracy = 0.5005\n",
            "Validation batch 604: Accuracy = 0.5003\n",
            "Validation batch 605: Accuracy = 0.5001\n",
            "Validation batch 606: Accuracy = 0.5001\n",
            "Validation batch 607: Accuracy = 0.5003\n",
            "Validation batch 608: Accuracy = 0.5002\n",
            "Validation batch 609: Accuracy = 0.5002\n",
            "Validation batch 610: Accuracy = 0.5002\n",
            "Validation batch 611: Accuracy = 0.5003\n",
            "Validation batch 612: Accuracy = 0.5001\n",
            "Validation batch 613: Accuracy = 0.5003\n",
            "Validation batch 614: Accuracy = 0.5002\n",
            "Validation batch 615: Accuracy = 0.5002\n",
            "Validation batch 616: Accuracy = 0.5002\n",
            "Validation batch 617: Accuracy = 0.5003\n",
            "Validation batch 618: Accuracy = 0.5003\n",
            "Validation batch 619: Accuracy = 0.5002\n",
            "Validation batch 620: Accuracy = 0.5001\n",
            "Validation batch 621: Accuracy = 0.5002\n",
            "Validation batch 622: Accuracy = 0.5000\n",
            "Validation batch 623: Accuracy = 0.5000\n",
            "Validation batch 624: Accuracy = 0.5002\n",
            "Validation batch 625: Accuracy = 0.5000\n",
            "100/100 - 6480s - loss: 0.0074 - accuracy: 0.9903 - val_loss: 130.7299 - val_accuracy: 0.5000 - 6480s/epoch - 65s/step\n",
            "Epoch 4/10\n",
            "Train batch 1: Accuracy = 1.0000\n",
            "Train batch 2: Accuracy = 1.0000\n",
            "Train batch 3: Accuracy = 1.0000\n",
            "Train batch 4: Accuracy = 1.0000\n",
            "Train batch 5: Accuracy = 1.0000\n",
            "Train batch 6: Accuracy = 1.0000\n",
            "Train batch 7: Accuracy = 1.0000\n",
            "Train batch 8: Accuracy = 1.0000\n",
            "Train batch 9: Accuracy = 1.0000\n",
            "Train batch 10: Accuracy = 1.0000\n",
            "Train batch 11: Accuracy = 1.0000\n",
            "Train batch 12: Accuracy = 1.0000\n",
            "Train batch 13: Accuracy = 1.0000\n",
            "Train batch 14: Accuracy = 1.0000\n",
            "Train batch 15: Accuracy = 1.0000\n",
            "Train batch 16: Accuracy = 1.0000\n",
            "Train batch 17: Accuracy = 1.0000\n",
            "Train batch 18: Accuracy = 1.0000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-07d0e6be681c>\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# Start or resume training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1781\u001b[0m                         ):\n\u001b[1;32m   1782\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1783\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1784\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    868\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1262\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1263\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1264\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1265\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mflat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mflat_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;34m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    253\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1480\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     ]\n\u001b[0;32m---> 60\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     61\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('/content/drive/MyDrive/Image/model_weights_interrupted1.h5')"
      ],
      "metadata": {
        "id": "Q9vi07-Teluc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Define resuming_training based on user input\n",
        "resume = input(\"Resume training from saved weights? (y/n): \")\n",
        "resuming_training = resume.lower() == 'y'\n",
        "\n",
        "# Load saved weights (if resuming)\n",
        "if resuming_training:\n",
        "    model.load_weights('/content/drive/MyDrive/Image/model_weights_interrupted1.h5')\n",
        "\n",
        "# Model checkpoint callback\n",
        "#checkpoint = ModelCheckpoint('/content/drive/MyDrive/Image/model_checkpoint.h5', save_best_only=True)\n",
        "\n",
        "# Early stopping for validation loss improvement\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,  # Stop training after 5 epochs with no improvement\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "# TensorBoard for visualization\n",
        "tensorboard = tf.keras.callbacks.TensorBoard(\n",
        "    log_dir='logs',  # Directory for visualization data\n",
        "    histogram_freq=1,  # Track weight histograms during training\n",
        ")\n",
        "\n",
        "# Custom accuracy logging callback\n",
        "class AccuracyLogger(tf.keras.callbacks.Callback):\n",
        "    def on_train_batch_end(self, batch, logs):\n",
        "        print(f\"Train batch {batch+1}: Accuracy = {logs['accuracy']:.4f}\")\n",
        "\n",
        "    def on_test_batch_end(self, batch, logs):\n",
        "        print(f\"Validation batch {batch+1}: Accuracy = {logs['accuracy']:.4f}\")\n",
        "\n",
        "# Start or resume training\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=test_generator,\n",
        "    epochs=4,  # Adjust as needed\n",
        "    verbose=2,\n",
        "    initial_epoch=2 ,#(Start from epoch 2 if resuming),\n",
        "    steps_per_epoch=100,  # Optional for remaining batches\n",
        "    callbacks=[\n",
        "        #checkpoint,\n",
        "        early_stopping,\n",
        "        tensorboard,\n",
        "        AccuracyLogger(),\n",
        "        # ... other callbacks ...\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Save final weights\n",
        "model.save_weights('/content/drive/MyDrive/Image/model_final_weights.h5')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8iM7izCju0U",
        "outputId": "230e3216-697a-432c-e8dd-8d8cc2d4ec0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resume training from saved weights? (y/n): y\n",
            "Epoch 3/4\n",
            "Train batch 1: Accuracy = 1.0000\n",
            "Train batch 2: Accuracy = 1.0000\n",
            "Train batch 3: Accuracy = 1.0000\n",
            "Train batch 4: Accuracy = 1.0000\n",
            "Train batch 5: Accuracy = 1.0000\n",
            "Train batch 6: Accuracy = 1.0000\n",
            "Train batch 7: Accuracy = 1.0000\n",
            "Train batch 8: Accuracy = 1.0000\n",
            "Train batch 9: Accuracy = 1.0000\n",
            "Train batch 10: Accuracy = 1.0000\n",
            "Train batch 11: Accuracy = 1.0000\n",
            "Train batch 12: Accuracy = 1.0000\n",
            "Train batch 13: Accuracy = 1.0000\n",
            "Train batch 14: Accuracy = 1.0000\n",
            "Train batch 15: Accuracy = 1.0000\n",
            "Train batch 16: Accuracy = 1.0000\n",
            "Train batch 17: Accuracy = 1.0000\n",
            "Train batch 18: Accuracy = 1.0000\n",
            "Train batch 19: Accuracy = 1.0000\n",
            "Train batch 20: Accuracy = 1.0000\n",
            "Train batch 21: Accuracy = 1.0000\n",
            "Train batch 22: Accuracy = 1.0000\n",
            "Train batch 23: Accuracy = 1.0000\n",
            "Train batch 24: Accuracy = 1.0000\n",
            "Train batch 25: Accuracy = 1.0000\n",
            "Train batch 26: Accuracy = 1.0000\n",
            "Train batch 27: Accuracy = 1.0000\n",
            "Train batch 28: Accuracy = 1.0000\n",
            "Train batch 29: Accuracy = 1.0000\n",
            "Train batch 30: Accuracy = 1.0000\n",
            "Train batch 31: Accuracy = 1.0000\n",
            "Train batch 32: Accuracy = 1.0000\n",
            "Train batch 33: Accuracy = 1.0000\n",
            "Train batch 34: Accuracy = 1.0000\n",
            "Train batch 35: Accuracy = 1.0000\n",
            "Train batch 36: Accuracy = 1.0000\n",
            "Train batch 37: Accuracy = 1.0000\n",
            "Train batch 38: Accuracy = 1.0000\n",
            "Train batch 39: Accuracy = 1.0000\n",
            "Train batch 40: Accuracy = 1.0000\n",
            "Train batch 41: Accuracy = 1.0000\n",
            "Train batch 42: Accuracy = 1.0000\n",
            "Train batch 43: Accuracy = 1.0000\n",
            "Train batch 44: Accuracy = 1.0000\n",
            "Train batch 45: Accuracy = 1.0000\n",
            "Train batch 46: Accuracy = 1.0000\n",
            "Train batch 47: Accuracy = 1.0000\n",
            "Train batch 48: Accuracy = 1.0000\n",
            "Train batch 49: Accuracy = 1.0000\n",
            "Train batch 50: Accuracy = 1.0000\n",
            "Train batch 51: Accuracy = 1.0000\n",
            "Train batch 52: Accuracy = 1.0000\n",
            "Train batch 53: Accuracy = 1.0000\n",
            "Train batch 54: Accuracy = 1.0000\n",
            "Train batch 55: Accuracy = 1.0000\n",
            "Train batch 56: Accuracy = 1.0000\n",
            "Train batch 57: Accuracy = 1.0000\n",
            "Train batch 58: Accuracy = 1.0000\n",
            "Train batch 59: Accuracy = 1.0000\n",
            "Train batch 60: Accuracy = 1.0000\n",
            "Train batch 61: Accuracy = 1.0000\n",
            "Train batch 62: Accuracy = 1.0000\n",
            "Train batch 63: Accuracy = 1.0000\n",
            "Train batch 64: Accuracy = 1.0000\n",
            "Train batch 65: Accuracy = 1.0000\n",
            "Train batch 66: Accuracy = 1.0000\n",
            "Train batch 67: Accuracy = 1.0000\n",
            "Train batch 68: Accuracy = 1.0000\n",
            "Train batch 69: Accuracy = 1.0000\n",
            "Train batch 70: Accuracy = 1.0000\n",
            "Train batch 71: Accuracy = 1.0000\n",
            "Train batch 72: Accuracy = 1.0000\n",
            "Train batch 73: Accuracy = 1.0000\n",
            "Train batch 74: Accuracy = 1.0000\n",
            "Train batch 75: Accuracy = 1.0000\n",
            "Train batch 76: Accuracy = 1.0000\n",
            "Train batch 77: Accuracy = 1.0000\n",
            "Train batch 78: Accuracy = 1.0000\n",
            "Train batch 79: Accuracy = 1.0000\n",
            "Train batch 80: Accuracy = 1.0000\n",
            "Train batch 81: Accuracy = 1.0000\n",
            "Train batch 82: Accuracy = 1.0000\n",
            "Train batch 83: Accuracy = 1.0000\n",
            "Train batch 84: Accuracy = 1.0000\n",
            "Train batch 85: Accuracy = 1.0000\n",
            "Train batch 86: Accuracy = 1.0000\n",
            "Train batch 87: Accuracy = 1.0000\n",
            "Train batch 88: Accuracy = 1.0000\n",
            "Train batch 89: Accuracy = 1.0000\n",
            "Train batch 90: Accuracy = 1.0000\n",
            "Train batch 91: Accuracy = 1.0000\n",
            "Train batch 92: Accuracy = 1.0000\n",
            "Train batch 93: Accuracy = 1.0000\n",
            "Train batch 94: Accuracy = 1.0000\n",
            "Train batch 95: Accuracy = 1.0000\n",
            "Train batch 96: Accuracy = 1.0000\n",
            "Train batch 97: Accuracy = 1.0000\n",
            "Train batch 98: Accuracy = 1.0000\n",
            "Train batch 99: Accuracy = 1.0000\n",
            "Train batch 100: Accuracy = 1.0000\n",
            "Validation batch 1: Accuracy = 0.3125\n",
            "Validation batch 2: Accuracy = 0.4531\n",
            "Validation batch 3: Accuracy = 0.4479\n",
            "Validation batch 4: Accuracy = 0.4922\n",
            "Validation batch 5: Accuracy = 0.5063\n",
            "Validation batch 6: Accuracy = 0.4948\n",
            "Validation batch 7: Accuracy = 0.4955\n",
            "Validation batch 8: Accuracy = 0.4922\n",
            "Validation batch 9: Accuracy = 0.4965\n",
            "Validation batch 10: Accuracy = 0.4938\n",
            "Validation batch 11: Accuracy = 0.5000\n",
            "Validation batch 12: Accuracy = 0.4896\n",
            "Validation batch 13: Accuracy = 0.4976\n",
            "Validation batch 14: Accuracy = 0.4911\n",
            "Validation batch 15: Accuracy = 0.4938\n",
            "Validation batch 16: Accuracy = 0.4980\n",
            "Validation batch 17: Accuracy = 0.5018\n",
            "Validation batch 18: Accuracy = 0.5052\n",
            "Validation batch 19: Accuracy = 0.4984\n",
            "Validation batch 20: Accuracy = 0.5016\n",
            "Validation batch 21: Accuracy = 0.5030\n",
            "Validation batch 22: Accuracy = 0.5057\n",
            "Validation batch 23: Accuracy = 0.5068\n",
            "Validation batch 24: Accuracy = 0.5039\n",
            "Validation batch 25: Accuracy = 0.5063\n",
            "Validation batch 26: Accuracy = 0.5048\n",
            "Validation batch 27: Accuracy = 0.5116\n",
            "Validation batch 28: Accuracy = 0.5123\n",
            "Validation batch 29: Accuracy = 0.5108\n",
            "Validation batch 30: Accuracy = 0.5083\n",
            "Validation batch 31: Accuracy = 0.5030\n",
            "Validation batch 32: Accuracy = 0.5039\n",
            "Validation batch 33: Accuracy = 0.5057\n",
            "Validation batch 34: Accuracy = 0.5083\n",
            "Validation batch 35: Accuracy = 0.5063\n",
            "Validation batch 36: Accuracy = 0.5095\n",
            "Validation batch 37: Accuracy = 0.5084\n",
            "Validation batch 38: Accuracy = 0.5132\n",
            "Validation batch 39: Accuracy = 0.5152\n",
            "Validation batch 40: Accuracy = 0.5156\n",
            "Validation batch 41: Accuracy = 0.5175\n",
            "Validation batch 42: Accuracy = 0.5149\n",
            "Validation batch 43: Accuracy = 0.5153\n",
            "Validation batch 44: Accuracy = 0.5170\n",
            "Validation batch 45: Accuracy = 0.5167\n",
            "Validation batch 46: Accuracy = 0.5177\n",
            "Validation batch 47: Accuracy = 0.5180\n",
            "Validation batch 48: Accuracy = 0.5202\n",
            "Validation batch 49: Accuracy = 0.5166\n",
            "Validation batch 50: Accuracy = 0.5156\n",
            "Validation batch 51: Accuracy = 0.5178\n",
            "Validation batch 52: Accuracy = 0.5216\n",
            "Validation batch 53: Accuracy = 0.5212\n",
            "Validation batch 54: Accuracy = 0.5208\n",
            "Validation batch 55: Accuracy = 0.5193\n",
            "Validation batch 56: Accuracy = 0.5184\n",
            "Validation batch 57: Accuracy = 0.5181\n",
            "Validation batch 58: Accuracy = 0.5172\n",
            "Validation batch 59: Accuracy = 0.5180\n",
            "Validation batch 60: Accuracy = 0.5198\n",
            "Validation batch 61: Accuracy = 0.5210\n",
            "Validation batch 62: Accuracy = 0.5202\n",
            "Validation batch 63: Accuracy = 0.5179\n",
            "Validation batch 64: Accuracy = 0.5190\n",
            "Validation batch 65: Accuracy = 0.5188\n",
            "Validation batch 66: Accuracy = 0.5204\n",
            "Validation batch 67: Accuracy = 0.5191\n",
            "Validation batch 68: Accuracy = 0.5179\n",
            "Validation batch 69: Accuracy = 0.5186\n",
            "Validation batch 70: Accuracy = 0.5179\n",
            "Validation batch 71: Accuracy = 0.5185\n",
            "Validation batch 72: Accuracy = 0.5200\n",
            "Validation batch 73: Accuracy = 0.5180\n",
            "Validation batch 74: Accuracy = 0.5177\n",
            "Validation batch 75: Accuracy = 0.5167\n",
            "Validation batch 76: Accuracy = 0.5156\n",
            "Validation batch 77: Accuracy = 0.5146\n",
            "Validation batch 78: Accuracy = 0.5140\n",
            "Validation batch 79: Accuracy = 0.5146\n",
            "Validation batch 80: Accuracy = 0.5133\n",
            "Validation batch 81: Accuracy = 0.5131\n",
            "Validation batch 82: Accuracy = 0.5137\n",
            "Validation batch 83: Accuracy = 0.5139\n",
            "Validation batch 84: Accuracy = 0.5145\n",
            "Validation batch 85: Accuracy = 0.5147\n",
            "Validation batch 86: Accuracy = 0.5149\n",
            "Validation batch 87: Accuracy = 0.5158\n",
            "Validation batch 88: Accuracy = 0.5178\n",
            "Validation batch 89: Accuracy = 0.5193\n",
            "Validation batch 90: Accuracy = 0.5194\n",
            "Validation batch 91: Accuracy = 0.5179\n",
            "Validation batch 92: Accuracy = 0.5183\n",
            "Validation batch 93: Accuracy = 0.5181\n",
            "Validation batch 94: Accuracy = 0.5193\n",
            "Validation batch 95: Accuracy = 0.5204\n",
            "Validation batch 96: Accuracy = 0.5215\n",
            "Validation batch 97: Accuracy = 0.5219\n",
            "Validation batch 98: Accuracy = 0.5230\n",
            "Validation batch 99: Accuracy = 0.5224\n",
            "Validation batch 100: Accuracy = 0.5219\n",
            "Validation batch 101: Accuracy = 0.5192\n",
            "Validation batch 102: Accuracy = 0.5187\n",
            "Validation batch 103: Accuracy = 0.5182\n",
            "Validation batch 104: Accuracy = 0.5171\n",
            "Validation batch 105: Accuracy = 0.5161\n",
            "Validation batch 106: Accuracy = 0.5153\n",
            "Validation batch 107: Accuracy = 0.5166\n",
            "Validation batch 108: Accuracy = 0.5182\n",
            "Validation batch 109: Accuracy = 0.5186\n",
            "Validation batch 110: Accuracy = 0.5188\n",
            "Validation batch 111: Accuracy = 0.5183\n",
            "Validation batch 112: Accuracy = 0.5165\n",
            "Validation batch 113: Accuracy = 0.5171\n",
            "Validation batch 114: Accuracy = 0.5164\n",
            "Validation batch 115: Accuracy = 0.5177\n",
            "Validation batch 116: Accuracy = 0.5178\n",
            "Validation batch 117: Accuracy = 0.5179\n",
            "Validation batch 118: Accuracy = 0.5177\n",
            "Validation batch 119: Accuracy = 0.5168\n",
            "Validation batch 120: Accuracy = 0.5159\n",
            "Validation batch 121: Accuracy = 0.5147\n",
            "Validation batch 122: Accuracy = 0.5138\n",
            "Validation batch 123: Accuracy = 0.5127\n",
            "Validation batch 124: Accuracy = 0.5121\n",
            "Validation batch 125: Accuracy = 0.5132\n",
            "Validation batch 126: Accuracy = 0.5129\n",
            "Validation batch 127: Accuracy = 0.5128\n",
            "Validation batch 128: Accuracy = 0.5127\n",
            "Validation batch 129: Accuracy = 0.5128\n",
            "Validation batch 130: Accuracy = 0.5125\n",
            "Validation batch 131: Accuracy = 0.5143\n",
            "Validation batch 132: Accuracy = 0.5156\n",
            "Validation batch 133: Accuracy = 0.5146\n",
            "Validation batch 134: Accuracy = 0.5149\n",
            "Validation batch 135: Accuracy = 0.5141\n",
            "Validation batch 136: Accuracy = 0.5147\n",
            "Validation batch 137: Accuracy = 0.5141\n",
            "Validation batch 138: Accuracy = 0.5138\n",
            "Validation batch 139: Accuracy = 0.5151\n",
            "Validation batch 140: Accuracy = 0.5163\n",
            "Validation batch 141: Accuracy = 0.5168\n",
            "Validation batch 142: Accuracy = 0.5172\n",
            "Validation batch 143: Accuracy = 0.5177\n",
            "Validation batch 144: Accuracy = 0.5182\n",
            "Validation batch 145: Accuracy = 0.5183\n",
            "Validation batch 146: Accuracy = 0.5190\n",
            "Validation batch 147: Accuracy = 0.5179\n",
            "Validation batch 148: Accuracy = 0.5175\n",
            "Validation batch 149: Accuracy = 0.5159\n",
            "Validation batch 150: Accuracy = 0.5167\n",
            "Validation batch 151: Accuracy = 0.5174\n",
            "Validation batch 152: Accuracy = 0.5167\n",
            "Validation batch 153: Accuracy = 0.5167\n",
            "Validation batch 154: Accuracy = 0.5170\n",
            "Validation batch 155: Accuracy = 0.5169\n",
            "Validation batch 156: Accuracy = 0.5168\n",
            "Validation batch 157: Accuracy = 0.5173\n",
            "Validation batch 158: Accuracy = 0.5176\n",
            "Validation batch 159: Accuracy = 0.5179\n",
            "Validation batch 160: Accuracy = 0.5170\n",
            "Validation batch 161: Accuracy = 0.5171\n",
            "Validation batch 162: Accuracy = 0.5176\n",
            "Validation batch 163: Accuracy = 0.5167\n",
            "Validation batch 164: Accuracy = 0.5171\n",
            "Validation batch 165: Accuracy = 0.5161\n",
            "Validation batch 166: Accuracy = 0.5160\n",
            "Validation batch 167: Accuracy = 0.5155\n",
            "Validation batch 168: Accuracy = 0.5153\n",
            "Validation batch 169: Accuracy = 0.5146\n",
            "Validation batch 170: Accuracy = 0.5138\n",
            "Validation batch 171: Accuracy = 0.5141\n",
            "Validation batch 172: Accuracy = 0.5145\n",
            "Validation batch 173: Accuracy = 0.5146\n",
            "Validation batch 174: Accuracy = 0.5154\n",
            "Validation batch 175: Accuracy = 0.5152\n",
            "Validation batch 176: Accuracy = 0.5147\n",
            "Validation batch 177: Accuracy = 0.5147\n",
            "Validation batch 178: Accuracy = 0.5142\n",
            "Validation batch 179: Accuracy = 0.5134\n",
            "Validation batch 180: Accuracy = 0.5137\n",
            "Validation batch 181: Accuracy = 0.5128\n",
            "Validation batch 182: Accuracy = 0.5122\n",
            "Validation batch 183: Accuracy = 0.5125\n",
            "Validation batch 184: Accuracy = 0.5129\n",
            "Validation batch 185: Accuracy = 0.5127\n",
            "Validation batch 186: Accuracy = 0.5124\n",
            "Validation batch 187: Accuracy = 0.5122\n",
            "Validation batch 188: Accuracy = 0.5128\n",
            "Validation batch 189: Accuracy = 0.5131\n",
            "Validation batch 190: Accuracy = 0.5130\n",
            "Validation batch 191: Accuracy = 0.5124\n",
            "Validation batch 192: Accuracy = 0.5127\n",
            "Validation batch 193: Accuracy = 0.5121\n",
            "Validation batch 194: Accuracy = 0.5118\n",
            "Validation batch 195: Accuracy = 0.5130\n",
            "Validation batch 196: Accuracy = 0.5131\n",
            "Validation batch 197: Accuracy = 0.5127\n",
            "Validation batch 198: Accuracy = 0.5126\n",
            "Validation batch 199: Accuracy = 0.5127\n",
            "Validation batch 200: Accuracy = 0.5131\n",
            "Validation batch 201: Accuracy = 0.5120\n",
            "Validation batch 202: Accuracy = 0.5119\n",
            "Validation batch 203: Accuracy = 0.5126\n",
            "Validation batch 204: Accuracy = 0.5124\n",
            "Validation batch 205: Accuracy = 0.5127\n",
            "Validation batch 206: Accuracy = 0.5127\n",
            "Validation batch 207: Accuracy = 0.5130\n",
            "Validation batch 208: Accuracy = 0.5141\n",
            "Validation batch 209: Accuracy = 0.5139\n",
            "Validation batch 210: Accuracy = 0.5138\n",
            "Validation batch 211: Accuracy = 0.5135\n",
            "Validation batch 212: Accuracy = 0.5133\n",
            "Validation batch 213: Accuracy = 0.5129\n",
            "Validation batch 214: Accuracy = 0.5126\n",
            "Validation batch 215: Accuracy = 0.5121\n",
            "Validation batch 216: Accuracy = 0.5123\n",
            "Validation batch 217: Accuracy = 0.5124\n",
            "Validation batch 218: Accuracy = 0.5128\n",
            "Validation batch 219: Accuracy = 0.5121\n",
            "Validation batch 220: Accuracy = 0.5118\n",
            "Validation batch 221: Accuracy = 0.5117\n",
            "Validation batch 222: Accuracy = 0.5117\n",
            "Validation batch 223: Accuracy = 0.5116\n",
            "Validation batch 224: Accuracy = 0.5112\n",
            "Validation batch 225: Accuracy = 0.5115\n",
            "Validation batch 226: Accuracy = 0.5112\n",
            "Validation batch 227: Accuracy = 0.5105\n",
            "Validation batch 228: Accuracy = 0.5101\n",
            "Validation batch 229: Accuracy = 0.5096\n",
            "Validation batch 230: Accuracy = 0.5096\n",
            "Validation batch 231: Accuracy = 0.5100\n",
            "Validation batch 232: Accuracy = 0.5101\n",
            "Validation batch 233: Accuracy = 0.5098\n",
            "Validation batch 234: Accuracy = 0.5099\n",
            "Validation batch 235: Accuracy = 0.5104\n",
            "Validation batch 236: Accuracy = 0.5107\n",
            "Validation batch 237: Accuracy = 0.5109\n",
            "Validation batch 238: Accuracy = 0.5104\n",
            "Validation batch 239: Accuracy = 0.5092\n",
            "Validation batch 240: Accuracy = 0.5087\n",
            "Validation batch 241: Accuracy = 0.5082\n",
            "Validation batch 242: Accuracy = 0.5081\n",
            "Validation batch 243: Accuracy = 0.5082\n",
            "Validation batch 244: Accuracy = 0.5081\n",
            "Validation batch 245: Accuracy = 0.5079\n",
            "Validation batch 246: Accuracy = 0.5084\n",
            "Validation batch 247: Accuracy = 0.5078\n",
            "Validation batch 248: Accuracy = 0.5076\n",
            "Validation batch 249: Accuracy = 0.5072\n",
            "Validation batch 250: Accuracy = 0.5069\n",
            "Validation batch 251: Accuracy = 0.5061\n",
            "Validation batch 252: Accuracy = 0.5057\n",
            "Validation batch 253: Accuracy = 0.5049\n",
            "Validation batch 254: Accuracy = 0.5050\n",
            "Validation batch 255: Accuracy = 0.5050\n",
            "Validation batch 256: Accuracy = 0.5050\n",
            "Validation batch 257: Accuracy = 0.5054\n",
            "Validation batch 258: Accuracy = 0.5048\n",
            "Validation batch 259: Accuracy = 0.5045\n",
            "Validation batch 260: Accuracy = 0.5043\n",
            "Validation batch 261: Accuracy = 0.5043\n",
            "Validation batch 262: Accuracy = 0.5050\n",
            "Validation batch 263: Accuracy = 0.5048\n",
            "Validation batch 264: Accuracy = 0.5043\n",
            "Validation batch 265: Accuracy = 0.5042\n",
            "Validation batch 266: Accuracy = 0.5046\n",
            "Validation batch 267: Accuracy = 0.5044\n",
            "Validation batch 268: Accuracy = 0.5038\n",
            "Validation batch 269: Accuracy = 0.5033\n",
            "Validation batch 270: Accuracy = 0.5032\n",
            "Validation batch 271: Accuracy = 0.5029\n",
            "Validation batch 272: Accuracy = 0.5030\n",
            "Validation batch 273: Accuracy = 0.5032\n",
            "Validation batch 274: Accuracy = 0.5032\n",
            "Validation batch 275: Accuracy = 0.5033\n",
            "Validation batch 276: Accuracy = 0.5033\n",
            "Validation batch 277: Accuracy = 0.5033\n",
            "Validation batch 278: Accuracy = 0.5028\n",
            "Validation batch 279: Accuracy = 0.5030\n",
            "Validation batch 280: Accuracy = 0.5030\n",
            "Validation batch 281: Accuracy = 0.5029\n",
            "Validation batch 282: Accuracy = 0.5028\n",
            "Validation batch 283: Accuracy = 0.5028\n",
            "Validation batch 284: Accuracy = 0.5029\n",
            "Validation batch 285: Accuracy = 0.5030\n",
            "Validation batch 286: Accuracy = 0.5025\n",
            "Validation batch 287: Accuracy = 0.5026\n",
            "Validation batch 288: Accuracy = 0.5031\n",
            "Validation batch 289: Accuracy = 0.5037\n",
            "Validation batch 290: Accuracy = 0.5034\n",
            "Validation batch 291: Accuracy = 0.5031\n",
            "Validation batch 292: Accuracy = 0.5027\n",
            "Validation batch 293: Accuracy = 0.5026\n",
            "Validation batch 294: Accuracy = 0.5027\n",
            "Validation batch 295: Accuracy = 0.5030\n",
            "Validation batch 296: Accuracy = 0.5031\n",
            "Validation batch 297: Accuracy = 0.5029\n",
            "Validation batch 298: Accuracy = 0.5027\n",
            "Validation batch 299: Accuracy = 0.5032\n",
            "Validation batch 300: Accuracy = 0.5033\n",
            "Validation batch 301: Accuracy = 0.5032\n",
            "Validation batch 302: Accuracy = 0.5035\n",
            "Validation batch 303: Accuracy = 0.5036\n",
            "Validation batch 304: Accuracy = 0.5035\n",
            "Validation batch 305: Accuracy = 0.5039\n",
            "Validation batch 306: Accuracy = 0.5040\n",
            "Validation batch 307: Accuracy = 0.5038\n",
            "Validation batch 308: Accuracy = 0.5040\n",
            "Validation batch 309: Accuracy = 0.5046\n",
            "Validation batch 310: Accuracy = 0.5052\n",
            "Validation batch 311: Accuracy = 0.5053\n",
            "Validation batch 312: Accuracy = 0.5051\n",
            "Validation batch 313: Accuracy = 0.5049\n",
            "Validation batch 314: Accuracy = 0.5045\n",
            "Validation batch 315: Accuracy = 0.5041\n",
            "Validation batch 316: Accuracy = 0.5037\n",
            "Validation batch 317: Accuracy = 0.5042\n",
            "Validation batch 318: Accuracy = 0.5046\n",
            "Validation batch 319: Accuracy = 0.5044\n",
            "Validation batch 320: Accuracy = 0.5045\n",
            "Validation batch 321: Accuracy = 0.5046\n",
            "Validation batch 322: Accuracy = 0.5044\n",
            "Validation batch 323: Accuracy = 0.5040\n",
            "Validation batch 324: Accuracy = 0.5034\n",
            "Validation batch 325: Accuracy = 0.5028\n",
            "Validation batch 326: Accuracy = 0.5027\n",
            "Validation batch 327: Accuracy = 0.5030\n",
            "Validation batch 328: Accuracy = 0.5030\n",
            "Validation batch 329: Accuracy = 0.5029\n",
            "Validation batch 330: Accuracy = 0.5027\n",
            "Validation batch 331: Accuracy = 0.5025\n",
            "Validation batch 332: Accuracy = 0.5026\n",
            "Validation batch 333: Accuracy = 0.5027\n",
            "Validation batch 334: Accuracy = 0.5025\n",
            "Validation batch 335: Accuracy = 0.5019\n",
            "Validation batch 336: Accuracy = 0.5020\n",
            "Validation batch 337: Accuracy = 0.5016\n",
            "Validation batch 338: Accuracy = 0.5022\n",
            "Validation batch 339: Accuracy = 0.5023\n",
            "Validation batch 340: Accuracy = 0.5027\n",
            "Validation batch 341: Accuracy = 0.5027\n",
            "Validation batch 342: Accuracy = 0.5030\n",
            "Validation batch 343: Accuracy = 0.5029\n",
            "Validation batch 344: Accuracy = 0.5028\n",
            "Validation batch 345: Accuracy = 0.5030\n",
            "Validation batch 346: Accuracy = 0.5029\n",
            "Validation batch 347: Accuracy = 0.5026\n",
            "Validation batch 348: Accuracy = 0.5031\n",
            "Validation batch 349: Accuracy = 0.5030\n",
            "Validation batch 350: Accuracy = 0.5030\n",
            "Validation batch 351: Accuracy = 0.5027\n",
            "Validation batch 352: Accuracy = 0.5025\n",
            "Validation batch 353: Accuracy = 0.5023\n",
            "Validation batch 354: Accuracy = 0.5021\n",
            "Validation batch 355: Accuracy = 0.5018\n",
            "Validation batch 356: Accuracy = 0.5018\n",
            "Validation batch 357: Accuracy = 0.5018\n",
            "Validation batch 358: Accuracy = 0.5017\n",
            "Validation batch 359: Accuracy = 0.5019\n",
            "Validation batch 360: Accuracy = 0.5018\n",
            "Validation batch 361: Accuracy = 0.5021\n",
            "Validation batch 362: Accuracy = 0.5020\n",
            "Validation batch 363: Accuracy = 0.5016\n",
            "Validation batch 364: Accuracy = 0.5015\n",
            "Validation batch 365: Accuracy = 0.5015\n",
            "Validation batch 366: Accuracy = 0.5012\n",
            "Validation batch 367: Accuracy = 0.5014\n",
            "Validation batch 368: Accuracy = 0.5016\n",
            "Validation batch 369: Accuracy = 0.5019\n",
            "Validation batch 370: Accuracy = 0.5024\n",
            "Validation batch 371: Accuracy = 0.5025\n",
            "Validation batch 372: Accuracy = 0.5026\n",
            "Validation batch 373: Accuracy = 0.5030\n",
            "Validation batch 374: Accuracy = 0.5032\n",
            "Validation batch 375: Accuracy = 0.5028\n",
            "Validation batch 376: Accuracy = 0.5027\n",
            "Validation batch 377: Accuracy = 0.5023\n",
            "Validation batch 378: Accuracy = 0.5023\n",
            "Validation batch 379: Accuracy = 0.5024\n",
            "Validation batch 380: Accuracy = 0.5025\n",
            "Validation batch 381: Accuracy = 0.5025\n",
            "Validation batch 382: Accuracy = 0.5024\n",
            "Validation batch 383: Accuracy = 0.5023\n",
            "Validation batch 384: Accuracy = 0.5022\n",
            "Validation batch 385: Accuracy = 0.5024\n",
            "Validation batch 386: Accuracy = 0.5024\n",
            "Validation batch 387: Accuracy = 0.5023\n",
            "Validation batch 388: Accuracy = 0.5023\n",
            "Validation batch 389: Accuracy = 0.5023\n",
            "Validation batch 390: Accuracy = 0.5025\n",
            "Validation batch 391: Accuracy = 0.5023\n",
            "Validation batch 392: Accuracy = 0.5022\n",
            "Validation batch 393: Accuracy = 0.5020\n",
            "Validation batch 394: Accuracy = 0.5022\n",
            "Validation batch 395: Accuracy = 0.5024\n",
            "Validation batch 396: Accuracy = 0.5023\n",
            "Validation batch 397: Accuracy = 0.5023\n",
            "Validation batch 398: Accuracy = 0.5022\n",
            "Validation batch 399: Accuracy = 0.5020\n",
            "Validation batch 400: Accuracy = 0.5018\n",
            "Validation batch 401: Accuracy = 0.5013\n",
            "Validation batch 402: Accuracy = 0.5011\n",
            "Validation batch 403: Accuracy = 0.5005\n",
            "Validation batch 404: Accuracy = 0.5004\n",
            "Validation batch 405: Accuracy = 0.5002\n",
            "Validation batch 406: Accuracy = 0.5002\n",
            "Validation batch 407: Accuracy = 0.5003\n",
            "Validation batch 408: Accuracy = 0.5003\n",
            "Validation batch 409: Accuracy = 0.5005\n",
            "Validation batch 410: Accuracy = 0.5003\n",
            "Validation batch 411: Accuracy = 0.5005\n",
            "Validation batch 412: Accuracy = 0.5004\n",
            "Validation batch 413: Accuracy = 0.5003\n",
            "Validation batch 414: Accuracy = 0.5005\n",
            "Validation batch 415: Accuracy = 0.5003\n",
            "Validation batch 416: Accuracy = 0.5001\n",
            "Validation batch 417: Accuracy = 0.5001\n",
            "Validation batch 418: Accuracy = 0.4999\n",
            "Validation batch 419: Accuracy = 0.4996\n",
            "Validation batch 420: Accuracy = 0.4996\n",
            "Validation batch 421: Accuracy = 0.4994\n",
            "Validation batch 422: Accuracy = 0.4996\n",
            "Validation batch 423: Accuracy = 0.4996\n",
            "Validation batch 424: Accuracy = 0.4996\n",
            "Validation batch 425: Accuracy = 0.4996\n",
            "Validation batch 426: Accuracy = 0.4997\n",
            "Validation batch 427: Accuracy = 0.5000\n",
            "Validation batch 428: Accuracy = 0.4998\n",
            "Validation batch 429: Accuracy = 0.4996\n",
            "Validation batch 430: Accuracy = 0.4999\n",
            "Validation batch 431: Accuracy = 0.4999\n",
            "Validation batch 432: Accuracy = 0.4999\n",
            "Validation batch 433: Accuracy = 0.4998\n",
            "Validation batch 434: Accuracy = 0.4996\n",
            "Validation batch 435: Accuracy = 0.4997\n",
            "Validation batch 436: Accuracy = 0.4997\n",
            "Validation batch 437: Accuracy = 0.4996\n",
            "Validation batch 438: Accuracy = 0.4997\n",
            "Validation batch 439: Accuracy = 0.5000\n",
            "Validation batch 440: Accuracy = 0.5001\n",
            "Validation batch 441: Accuracy = 0.5004\n",
            "Validation batch 442: Accuracy = 0.5006\n",
            "Validation batch 443: Accuracy = 0.5007\n",
            "Validation batch 444: Accuracy = 0.5008\n",
            "Validation batch 445: Accuracy = 0.5008\n",
            "Validation batch 446: Accuracy = 0.5011\n",
            "Validation batch 447: Accuracy = 0.5004\n",
            "Validation batch 448: Accuracy = 0.5008\n",
            "Validation batch 449: Accuracy = 0.5008\n",
            "Validation batch 450: Accuracy = 0.5009\n",
            "Validation batch 451: Accuracy = 0.5009\n",
            "Validation batch 452: Accuracy = 0.5007\n",
            "Validation batch 453: Accuracy = 0.5006\n",
            "Validation batch 454: Accuracy = 0.5003\n",
            "Validation batch 455: Accuracy = 0.5006\n",
            "Validation batch 456: Accuracy = 0.5007\n",
            "Validation batch 457: Accuracy = 0.5003\n",
            "Validation batch 458: Accuracy = 0.5001\n",
            "Validation batch 459: Accuracy = 0.5001\n",
            "Validation batch 460: Accuracy = 0.4999\n",
            "Validation batch 461: Accuracy = 0.4997\n",
            "Validation batch 462: Accuracy = 0.4996\n",
            "Validation batch 463: Accuracy = 0.4995\n",
            "Validation batch 464: Accuracy = 0.4993\n",
            "Validation batch 465: Accuracy = 0.4994\n",
            "Validation batch 466: Accuracy = 0.4993\n",
            "Validation batch 467: Accuracy = 0.4993\n",
            "Validation batch 468: Accuracy = 0.4996\n",
            "Validation batch 469: Accuracy = 0.4996\n",
            "Validation batch 470: Accuracy = 0.4997\n",
            "Validation batch 471: Accuracy = 0.4996\n",
            "Validation batch 472: Accuracy = 0.4996\n",
            "Validation batch 473: Accuracy = 0.4995\n",
            "Validation batch 474: Accuracy = 0.4997\n",
            "Validation batch 475: Accuracy = 0.4997\n",
            "Validation batch 476: Accuracy = 0.4995\n",
            "Validation batch 477: Accuracy = 0.4995\n",
            "Validation batch 478: Accuracy = 0.4995\n",
            "Validation batch 479: Accuracy = 0.4995\n",
            "Validation batch 480: Accuracy = 0.4997\n",
            "Validation batch 481: Accuracy = 0.4998\n",
            "Validation batch 482: Accuracy = 0.4997\n",
            "Validation batch 483: Accuracy = 0.4997\n",
            "Validation batch 484: Accuracy = 0.4995\n",
            "Validation batch 485: Accuracy = 0.4994\n",
            "Validation batch 486: Accuracy = 0.4994\n",
            "Validation batch 487: Accuracy = 0.4990\n",
            "Validation batch 488: Accuracy = 0.4988\n",
            "Validation batch 489: Accuracy = 0.4987\n",
            "Validation batch 490: Accuracy = 0.4987\n",
            "Validation batch 491: Accuracy = 0.4985\n",
            "Validation batch 492: Accuracy = 0.4985\n",
            "Validation batch 493: Accuracy = 0.4985\n",
            "Validation batch 494: Accuracy = 0.4984\n",
            "Validation batch 495: Accuracy = 0.4984\n",
            "Validation batch 496: Accuracy = 0.4982\n",
            "Validation batch 497: Accuracy = 0.4979\n",
            "Validation batch 498: Accuracy = 0.4979\n",
            "Validation batch 499: Accuracy = 0.4976\n",
            "Validation batch 500: Accuracy = 0.4976\n",
            "Validation batch 501: Accuracy = 0.4976\n",
            "Validation batch 502: Accuracy = 0.4976\n",
            "Validation batch 503: Accuracy = 0.4976\n",
            "Validation batch 504: Accuracy = 0.4976\n",
            "Validation batch 505: Accuracy = 0.4977\n",
            "Validation batch 506: Accuracy = 0.4976\n",
            "Validation batch 507: Accuracy = 0.4978\n",
            "Validation batch 508: Accuracy = 0.4976\n",
            "Validation batch 509: Accuracy = 0.4975\n",
            "Validation batch 510: Accuracy = 0.4975\n",
            "Validation batch 511: Accuracy = 0.4975\n",
            "Validation batch 512: Accuracy = 0.4974\n",
            "Validation batch 513: Accuracy = 0.4974\n",
            "Validation batch 514: Accuracy = 0.4974\n",
            "Validation batch 515: Accuracy = 0.4979\n",
            "Validation batch 516: Accuracy = 0.4978\n",
            "Validation batch 517: Accuracy = 0.4981\n",
            "Validation batch 518: Accuracy = 0.4983\n",
            "Validation batch 519: Accuracy = 0.4982\n",
            "Validation batch 520: Accuracy = 0.4982\n",
            "Validation batch 521: Accuracy = 0.4981\n",
            "Validation batch 522: Accuracy = 0.4984\n",
            "Validation batch 523: Accuracy = 0.4986\n",
            "Validation batch 524: Accuracy = 0.4986\n",
            "Validation batch 525: Accuracy = 0.4985\n",
            "Validation batch 526: Accuracy = 0.4988\n",
            "Validation batch 527: Accuracy = 0.4985\n",
            "Validation batch 528: Accuracy = 0.4985\n",
            "Validation batch 529: Accuracy = 0.4985\n",
            "Validation batch 530: Accuracy = 0.4986\n",
            "Validation batch 531: Accuracy = 0.4984\n",
            "Validation batch 532: Accuracy = 0.4985\n",
            "Validation batch 533: Accuracy = 0.4987\n",
            "Validation batch 534: Accuracy = 0.4987\n",
            "Validation batch 535: Accuracy = 0.4985\n",
            "Validation batch 536: Accuracy = 0.4985\n",
            "Validation batch 537: Accuracy = 0.4984\n",
            "Validation batch 538: Accuracy = 0.4982\n",
            "Validation batch 539: Accuracy = 0.4982\n",
            "Validation batch 540: Accuracy = 0.4981\n",
            "Validation batch 541: Accuracy = 0.4981\n",
            "Validation batch 542: Accuracy = 0.4980\n",
            "Validation batch 543: Accuracy = 0.4979\n",
            "Validation batch 544: Accuracy = 0.4980\n",
            "Validation batch 545: Accuracy = 0.4982\n",
            "Validation batch 546: Accuracy = 0.4984\n",
            "Validation batch 547: Accuracy = 0.4985\n",
            "Validation batch 548: Accuracy = 0.4986\n",
            "Validation batch 549: Accuracy = 0.4985\n",
            "Validation batch 550: Accuracy = 0.4985\n",
            "Validation batch 551: Accuracy = 0.4985\n",
            "Validation batch 552: Accuracy = 0.4985\n",
            "Validation batch 553: Accuracy = 0.4986\n",
            "Validation batch 554: Accuracy = 0.4988\n",
            "Validation batch 555: Accuracy = 0.4986\n",
            "Validation batch 556: Accuracy = 0.4986\n",
            "Validation batch 557: Accuracy = 0.4985\n",
            "Validation batch 558: Accuracy = 0.4985\n",
            "Validation batch 559: Accuracy = 0.4987\n",
            "Validation batch 560: Accuracy = 0.4988\n",
            "Validation batch 561: Accuracy = 0.4990\n",
            "Validation batch 562: Accuracy = 0.4991\n",
            "Validation batch 563: Accuracy = 0.4995\n",
            "Validation batch 564: Accuracy = 0.4996\n",
            "Validation batch 565: Accuracy = 0.4996\n",
            "Validation batch 566: Accuracy = 0.4997\n",
            "Validation batch 567: Accuracy = 0.4997\n",
            "Validation batch 568: Accuracy = 0.4998\n",
            "Validation batch 569: Accuracy = 0.4997\n",
            "Validation batch 570: Accuracy = 0.4998\n",
            "Validation batch 571: Accuracy = 0.4998\n",
            "Validation batch 572: Accuracy = 0.4999\n",
            "Validation batch 573: Accuracy = 0.4997\n",
            "Validation batch 574: Accuracy = 0.4996\n",
            "Validation batch 575: Accuracy = 0.4995\n",
            "Validation batch 576: Accuracy = 0.4994\n",
            "Validation batch 577: Accuracy = 0.4995\n",
            "Validation batch 578: Accuracy = 0.4995\n",
            "Validation batch 579: Accuracy = 0.4997\n",
            "Validation batch 580: Accuracy = 0.4996\n",
            "Validation batch 581: Accuracy = 0.4996\n",
            "Validation batch 582: Accuracy = 0.4996\n",
            "Validation batch 583: Accuracy = 0.4996\n",
            "Validation batch 584: Accuracy = 0.4998\n",
            "Validation batch 585: Accuracy = 0.4999\n",
            "Validation batch 586: Accuracy = 0.4999\n",
            "Validation batch 587: Accuracy = 0.5001\n",
            "Validation batch 588: Accuracy = 0.4998\n",
            "Validation batch 589: Accuracy = 0.4999\n",
            "Validation batch 590: Accuracy = 0.5001\n",
            "Validation batch 591: Accuracy = 0.5002\n",
            "Validation batch 592: Accuracy = 0.5003\n",
            "Validation batch 593: Accuracy = 0.5000\n",
            "Validation batch 594: Accuracy = 0.5002\n",
            "Validation batch 595: Accuracy = 0.5001\n",
            "Validation batch 596: Accuracy = 0.5000\n",
            "Validation batch 597: Accuracy = 0.4997\n",
            "Validation batch 598: Accuracy = 0.4999\n",
            "Validation batch 599: Accuracy = 0.4997\n",
            "Validation batch 600: Accuracy = 0.4995\n",
            "Validation batch 601: Accuracy = 0.4994\n",
            "Validation batch 602: Accuracy = 0.4995\n",
            "Validation batch 603: Accuracy = 0.4996\n",
            "Validation batch 604: Accuracy = 0.4996\n",
            "Validation batch 605: Accuracy = 0.4996\n",
            "Validation batch 606: Accuracy = 0.4998\n",
            "Validation batch 607: Accuracy = 0.4997\n",
            "Validation batch 608: Accuracy = 0.4998\n",
            "Validation batch 609: Accuracy = 0.4996\n",
            "Validation batch 610: Accuracy = 0.4997\n",
            "Validation batch 611: Accuracy = 0.4994\n",
            "Validation batch 612: Accuracy = 0.4995\n",
            "Validation batch 613: Accuracy = 0.4994\n",
            "Validation batch 614: Accuracy = 0.4994\n",
            "Validation batch 615: Accuracy = 0.4996\n",
            "Validation batch 616: Accuracy = 0.5001\n",
            "Validation batch 617: Accuracy = 0.4999\n",
            "Validation batch 618: Accuracy = 0.4999\n",
            "Validation batch 619: Accuracy = 0.4998\n",
            "Validation batch 620: Accuracy = 0.4999\n",
            "Validation batch 621: Accuracy = 0.5000\n",
            "Validation batch 622: Accuracy = 0.4998\n",
            "Validation batch 623: Accuracy = 0.4998\n",
            "Validation batch 624: Accuracy = 0.4998\n",
            "Validation batch 625: Accuracy = 0.5000\n",
            "100/100 - 1257s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 130.7415 - val_accuracy: 0.5000 - 1257s/epoch - 13s/step\n",
            "Epoch 4/4\n",
            "Train batch 1: Accuracy = 1.0000\n",
            "Train batch 2: Accuracy = 1.0000\n",
            "Train batch 3: Accuracy = 1.0000\n",
            "Train batch 4: Accuracy = 1.0000\n",
            "Train batch 5: Accuracy = 1.0000\n",
            "Train batch 6: Accuracy = 1.0000\n",
            "Train batch 7: Accuracy = 1.0000\n",
            "Train batch 8: Accuracy = 1.0000\n",
            "Train batch 9: Accuracy = 1.0000\n",
            "Train batch 10: Accuracy = 1.0000\n",
            "Train batch 11: Accuracy = 1.0000\n",
            "Train batch 12: Accuracy = 1.0000\n",
            "Train batch 13: Accuracy = 1.0000\n",
            "Train batch 14: Accuracy = 1.0000\n",
            "Train batch 15: Accuracy = 1.0000\n",
            "Train batch 16: Accuracy = 1.0000\n",
            "Train batch 17: Accuracy = 1.0000\n",
            "Train batch 18: Accuracy = 1.0000\n",
            "Train batch 19: Accuracy = 1.0000\n",
            "Train batch 20: Accuracy = 1.0000\n",
            "Train batch 21: Accuracy = 1.0000\n",
            "Train batch 22: Accuracy = 1.0000\n",
            "Train batch 23: Accuracy = 1.0000\n",
            "Train batch 24: Accuracy = 1.0000\n",
            "Train batch 25: Accuracy = 1.0000\n",
            "Train batch 26: Accuracy = 1.0000\n",
            "Train batch 27: Accuracy = 1.0000\n",
            "Train batch 28: Accuracy = 1.0000\n",
            "Train batch 29: Accuracy = 1.0000\n",
            "Train batch 30: Accuracy = 1.0000\n",
            "Train batch 31: Accuracy = 1.0000\n",
            "Train batch 32: Accuracy = 1.0000\n",
            "Train batch 33: Accuracy = 1.0000\n",
            "Train batch 34: Accuracy = 1.0000\n",
            "Train batch 35: Accuracy = 1.0000\n",
            "Train batch 36: Accuracy = 1.0000\n",
            "Train batch 37: Accuracy = 1.0000\n",
            "Train batch 38: Accuracy = 1.0000\n",
            "Train batch 39: Accuracy = 1.0000\n",
            "Train batch 40: Accuracy = 1.0000\n",
            "Train batch 41: Accuracy = 1.0000\n",
            "Train batch 42: Accuracy = 1.0000\n",
            "Train batch 43: Accuracy = 1.0000\n",
            "Train batch 44: Accuracy = 1.0000\n",
            "Train batch 45: Accuracy = 1.0000\n",
            "Train batch 46: Accuracy = 1.0000\n",
            "Train batch 47: Accuracy = 1.0000\n",
            "Train batch 48: Accuracy = 1.0000\n",
            "Train batch 49: Accuracy = 1.0000\n",
            "Train batch 50: Accuracy = 1.0000\n",
            "Train batch 51: Accuracy = 1.0000\n",
            "Train batch 52: Accuracy = 1.0000\n",
            "Train batch 53: Accuracy = 1.0000\n",
            "Train batch 54: Accuracy = 1.0000\n",
            "Train batch 55: Accuracy = 1.0000\n",
            "Train batch 56: Accuracy = 1.0000\n",
            "Train batch 57: Accuracy = 1.0000\n",
            "Train batch 58: Accuracy = 1.0000\n",
            "Train batch 59: Accuracy = 1.0000\n",
            "Train batch 60: Accuracy = 1.0000\n",
            "Train batch 61: Accuracy = 1.0000\n",
            "Train batch 62: Accuracy = 1.0000\n",
            "Train batch 63: Accuracy = 1.0000\n",
            "Train batch 64: Accuracy = 1.0000\n",
            "Train batch 65: Accuracy = 1.0000\n",
            "Train batch 66: Accuracy = 1.0000\n",
            "Train batch 67: Accuracy = 1.0000\n",
            "Train batch 68: Accuracy = 1.0000\n",
            "Train batch 69: Accuracy = 1.0000\n",
            "Train batch 70: Accuracy = 1.0000\n",
            "Train batch 71: Accuracy = 1.0000\n",
            "Train batch 72: Accuracy = 1.0000\n",
            "Train batch 73: Accuracy = 1.0000\n",
            "Train batch 74: Accuracy = 1.0000\n",
            "Train batch 75: Accuracy = 1.0000\n",
            "Train batch 76: Accuracy = 1.0000\n",
            "Train batch 77: Accuracy = 1.0000\n",
            "Train batch 78: Accuracy = 1.0000\n",
            "Train batch 79: Accuracy = 1.0000\n",
            "Train batch 80: Accuracy = 1.0000\n",
            "Train batch 81: Accuracy = 1.0000\n",
            "Train batch 82: Accuracy = 1.0000\n",
            "Train batch 83: Accuracy = 1.0000\n",
            "Train batch 84: Accuracy = 1.0000\n",
            "Train batch 85: Accuracy = 1.0000\n",
            "Train batch 86: Accuracy = 1.0000\n",
            "Train batch 87: Accuracy = 1.0000\n",
            "Train batch 88: Accuracy = 1.0000\n",
            "Train batch 89: Accuracy = 1.0000\n",
            "Train batch 90: Accuracy = 1.0000\n",
            "Train batch 91: Accuracy = 1.0000\n",
            "Train batch 92: Accuracy = 1.0000\n",
            "Train batch 93: Accuracy = 1.0000\n",
            "Train batch 94: Accuracy = 1.0000\n",
            "Train batch 95: Accuracy = 1.0000\n",
            "Train batch 96: Accuracy = 1.0000\n",
            "Train batch 97: Accuracy = 1.0000\n",
            "Train batch 98: Accuracy = 1.0000\n",
            "Train batch 99: Accuracy = 1.0000\n",
            "Train batch 100: Accuracy = 1.0000\n",
            "Validation batch 1: Accuracy = 0.3438\n",
            "Validation batch 2: Accuracy = 0.4062\n",
            "Validation batch 3: Accuracy = 0.4688\n",
            "Validation batch 4: Accuracy = 0.4609\n",
            "Validation batch 5: Accuracy = 0.4750\n",
            "Validation batch 6: Accuracy = 0.4583\n",
            "Validation batch 7: Accuracy = 0.4643\n",
            "Validation batch 8: Accuracy = 0.4727\n",
            "Validation batch 9: Accuracy = 0.4826\n",
            "Validation batch 10: Accuracy = 0.4969\n",
            "Validation batch 11: Accuracy = 0.4915\n",
            "Validation batch 12: Accuracy = 0.4792\n",
            "Validation batch 13: Accuracy = 0.4880\n",
            "Validation batch 14: Accuracy = 0.4844\n",
            "Validation batch 15: Accuracy = 0.4896\n",
            "Validation batch 16: Accuracy = 0.4824\n",
            "Validation batch 17: Accuracy = 0.4816\n",
            "Validation batch 18: Accuracy = 0.4826\n",
            "Validation batch 19: Accuracy = 0.4786\n",
            "Validation batch 20: Accuracy = 0.4781\n",
            "Validation batch 21: Accuracy = 0.4747\n",
            "Validation batch 22: Accuracy = 0.4844\n",
            "Validation batch 23: Accuracy = 0.4837\n",
            "Validation batch 24: Accuracy = 0.4844\n",
            "Validation batch 25: Accuracy = 0.4863\n",
            "Validation batch 26: Accuracy = 0.4808\n",
            "Validation batch 27: Accuracy = 0.4850\n",
            "Validation batch 28: Accuracy = 0.4888\n",
            "Validation batch 29: Accuracy = 0.4892\n",
            "Validation batch 30: Accuracy = 0.4896\n",
            "Validation batch 31: Accuracy = 0.4899\n",
            "Validation batch 32: Accuracy = 0.4912\n",
            "Validation batch 33: Accuracy = 0.4943\n",
            "Validation batch 34: Accuracy = 0.4926\n",
            "Validation batch 35: Accuracy = 0.4955\n",
            "Validation batch 36: Accuracy = 0.4974\n",
            "Validation batch 37: Accuracy = 0.4949\n",
            "Validation batch 38: Accuracy = 0.4926\n",
            "Validation batch 39: Accuracy = 0.4904\n",
            "Validation batch 40: Accuracy = 0.4883\n",
            "Validation batch 41: Accuracy = 0.4863\n",
            "Validation batch 42: Accuracy = 0.4874\n",
            "Validation batch 43: Accuracy = 0.4876\n",
            "Validation batch 44: Accuracy = 0.4886\n",
            "Validation batch 45: Accuracy = 0.4903\n",
            "Validation batch 46: Accuracy = 0.4891\n",
            "Validation batch 47: Accuracy = 0.4867\n",
            "Validation batch 48: Accuracy = 0.4870\n",
            "Validation batch 49: Accuracy = 0.4898\n",
            "Validation batch 50: Accuracy = 0.4888\n",
            "Validation batch 51: Accuracy = 0.4877\n",
            "Validation batch 52: Accuracy = 0.4862\n",
            "Validation batch 53: Accuracy = 0.4876\n",
            "Validation batch 54: Accuracy = 0.4855\n",
            "Validation batch 55: Accuracy = 0.4858\n",
            "Validation batch 56: Accuracy = 0.4877\n",
            "Validation batch 57: Accuracy = 0.4868\n",
            "Validation batch 58: Accuracy = 0.4860\n",
            "Validation batch 59: Accuracy = 0.4846\n",
            "Validation batch 60: Accuracy = 0.4833\n",
            "Validation batch 61: Accuracy = 0.4836\n",
            "Validation batch 62: Accuracy = 0.4844\n",
            "Validation batch 63: Accuracy = 0.4836\n",
            "Validation batch 64: Accuracy = 0.4849\n",
            "Validation batch 65: Accuracy = 0.4832\n",
            "Validation batch 66: Accuracy = 0.4825\n",
            "Validation batch 67: Accuracy = 0.4837\n",
            "Validation batch 68: Accuracy = 0.4844\n",
            "Validation batch 69: Accuracy = 0.4855\n",
            "Validation batch 70: Accuracy = 0.4839\n",
            "Validation batch 71: Accuracy = 0.4850\n",
            "Validation batch 72: Accuracy = 0.4857\n",
            "Validation batch 73: Accuracy = 0.4846\n",
            "Validation batch 74: Accuracy = 0.4835\n",
            "Validation batch 75: Accuracy = 0.4833\n",
            "Validation batch 76: Accuracy = 0.4831\n",
            "Validation batch 77: Accuracy = 0.4830\n",
            "Validation batch 78: Accuracy = 0.4828\n",
            "Validation batch 79: Accuracy = 0.4842\n",
            "Validation batch 80: Accuracy = 0.4836\n",
            "Validation batch 81: Accuracy = 0.4853\n",
            "Validation batch 82: Accuracy = 0.4859\n",
            "Validation batch 83: Accuracy = 0.4872\n",
            "Validation batch 84: Accuracy = 0.4862\n",
            "Validation batch 85: Accuracy = 0.4879\n",
            "Validation batch 86: Accuracy = 0.4880\n",
            "Validation batch 87: Accuracy = 0.4889\n",
            "Validation batch 88: Accuracy = 0.4897\n",
            "Validation batch 89: Accuracy = 0.4902\n",
            "Validation batch 90: Accuracy = 0.4899\n",
            "Validation batch 91: Accuracy = 0.4900\n",
            "Validation batch 92: Accuracy = 0.4898\n",
            "Validation batch 93: Accuracy = 0.4896\n",
            "Validation batch 94: Accuracy = 0.4894\n",
            "Validation batch 95: Accuracy = 0.4885\n",
            "Validation batch 96: Accuracy = 0.4886\n",
            "Validation batch 97: Accuracy = 0.4878\n",
            "Validation batch 98: Accuracy = 0.4898\n",
            "Validation batch 99: Accuracy = 0.4915\n",
            "Validation batch 100: Accuracy = 0.4903\n",
            "Validation batch 101: Accuracy = 0.4904\n",
            "Validation batch 102: Accuracy = 0.4917\n",
            "Validation batch 103: Accuracy = 0.4900\n",
            "Validation batch 104: Accuracy = 0.4907\n",
            "Validation batch 105: Accuracy = 0.4911\n",
            "Validation batch 106: Accuracy = 0.4909\n",
            "Validation batch 107: Accuracy = 0.4918\n",
            "Validation batch 108: Accuracy = 0.4919\n",
            "Validation batch 109: Accuracy = 0.4925\n",
            "Validation batch 110: Accuracy = 0.4940\n",
            "Validation batch 111: Accuracy = 0.4938\n",
            "Validation batch 112: Accuracy = 0.4939\n",
            "Validation batch 113: Accuracy = 0.4925\n",
            "Validation batch 114: Accuracy = 0.4926\n",
            "Validation batch 115: Accuracy = 0.4935\n",
            "Validation batch 116: Accuracy = 0.4935\n",
            "Validation batch 117: Accuracy = 0.4939\n",
            "Validation batch 118: Accuracy = 0.4939\n",
            "Validation batch 119: Accuracy = 0.4940\n",
            "Validation batch 120: Accuracy = 0.4945\n",
            "Validation batch 121: Accuracy = 0.4956\n",
            "Validation batch 122: Accuracy = 0.4964\n",
            "Validation batch 123: Accuracy = 0.4970\n",
            "Validation batch 124: Accuracy = 0.4970\n",
            "Validation batch 125: Accuracy = 0.4967\n",
            "Validation batch 126: Accuracy = 0.4963\n",
            "Validation batch 127: Accuracy = 0.4973\n",
            "Validation batch 128: Accuracy = 0.4983\n",
            "Validation batch 129: Accuracy = 0.4983\n",
            "Validation batch 130: Accuracy = 0.4976\n",
            "Validation batch 131: Accuracy = 0.4969\n",
            "Validation batch 132: Accuracy = 0.4983\n",
            "Validation batch 133: Accuracy = 0.4995\n",
            "Validation batch 134: Accuracy = 0.4993\n",
            "Validation batch 135: Accuracy = 0.5002\n",
            "Validation batch 136: Accuracy = 0.5011\n",
            "Validation batch 137: Accuracy = 0.5016\n",
            "Validation batch 138: Accuracy = 0.5011\n",
            "Validation batch 139: Accuracy = 0.5004\n",
            "Validation batch 140: Accuracy = 0.4998\n",
            "Validation batch 141: Accuracy = 0.4993\n",
            "Validation batch 142: Accuracy = 0.4993\n",
            "Validation batch 143: Accuracy = 0.4989\n",
            "Validation batch 144: Accuracy = 0.4996\n",
            "Validation batch 145: Accuracy = 0.4994\n",
            "Validation batch 146: Accuracy = 0.5004\n",
            "Validation batch 147: Accuracy = 0.5006\n",
            "Validation batch 148: Accuracy = 0.5004\n",
            "Validation batch 149: Accuracy = 0.5002\n",
            "Validation batch 150: Accuracy = 0.5004\n",
            "Validation batch 151: Accuracy = 0.5000\n",
            "Validation batch 152: Accuracy = 0.4990\n",
            "Validation batch 153: Accuracy = 0.4990\n",
            "Validation batch 154: Accuracy = 0.4990\n",
            "Validation batch 155: Accuracy = 0.4988\n",
            "Validation batch 156: Accuracy = 0.4986\n",
            "Validation batch 157: Accuracy = 0.4988\n",
            "Validation batch 158: Accuracy = 0.4984\n",
            "Validation batch 159: Accuracy = 0.4982\n",
            "Validation batch 160: Accuracy = 0.4979\n",
            "Validation batch 161: Accuracy = 0.4969\n",
            "Validation batch 162: Accuracy = 0.4967\n",
            "Validation batch 163: Accuracy = 0.4971\n",
            "Validation batch 164: Accuracy = 0.4983\n",
            "Validation batch 165: Accuracy = 0.4981\n",
            "Validation batch 166: Accuracy = 0.4976\n",
            "Validation batch 167: Accuracy = 0.4974\n",
            "Validation batch 168: Accuracy = 0.4970\n",
            "Validation batch 169: Accuracy = 0.4963\n",
            "Validation batch 170: Accuracy = 0.4965\n",
            "Validation batch 171: Accuracy = 0.4965\n",
            "Validation batch 172: Accuracy = 0.4955\n",
            "Validation batch 173: Accuracy = 0.4951\n",
            "Validation batch 174: Accuracy = 0.4946\n",
            "Validation batch 175: Accuracy = 0.4952\n",
            "Validation batch 176: Accuracy = 0.4950\n",
            "Validation batch 177: Accuracy = 0.4949\n",
            "Validation batch 178: Accuracy = 0.4951\n",
            "Validation batch 179: Accuracy = 0.4949\n",
            "Validation batch 180: Accuracy = 0.4941\n",
            "Validation batch 181: Accuracy = 0.4945\n",
            "Validation batch 182: Accuracy = 0.4942\n",
            "Validation batch 183: Accuracy = 0.4939\n",
            "Validation batch 184: Accuracy = 0.4939\n",
            "Validation batch 185: Accuracy = 0.4943\n",
            "Validation batch 186: Accuracy = 0.4950\n",
            "Validation batch 187: Accuracy = 0.4955\n",
            "Validation batch 188: Accuracy = 0.4945\n",
            "Validation batch 189: Accuracy = 0.4954\n",
            "Validation batch 190: Accuracy = 0.4961\n",
            "Validation batch 191: Accuracy = 0.4954\n",
            "Validation batch 192: Accuracy = 0.4959\n",
            "Validation batch 193: Accuracy = 0.4955\n",
            "Validation batch 194: Accuracy = 0.4952\n",
            "Validation batch 195: Accuracy = 0.4946\n",
            "Validation batch 196: Accuracy = 0.4943\n",
            "Validation batch 197: Accuracy = 0.4937\n",
            "Validation batch 198: Accuracy = 0.4937\n",
            "Validation batch 199: Accuracy = 0.4947\n",
            "Validation batch 200: Accuracy = 0.4942\n",
            "Validation batch 201: Accuracy = 0.4939\n",
            "Validation batch 202: Accuracy = 0.4941\n",
            "Validation batch 203: Accuracy = 0.4942\n",
            "Validation batch 204: Accuracy = 0.4943\n",
            "Validation batch 205: Accuracy = 0.4947\n",
            "Validation batch 206: Accuracy = 0.4958\n",
            "Validation batch 207: Accuracy = 0.4959\n",
            "Validation batch 208: Accuracy = 0.4962\n",
            "Validation batch 209: Accuracy = 0.4967\n",
            "Validation batch 210: Accuracy = 0.4970\n",
            "Validation batch 211: Accuracy = 0.4972\n",
            "Validation batch 212: Accuracy = 0.4969\n",
            "Validation batch 213: Accuracy = 0.4969\n",
            "Validation batch 214: Accuracy = 0.4966\n",
            "Validation batch 215: Accuracy = 0.4969\n",
            "Validation batch 216: Accuracy = 0.4973\n",
            "Validation batch 217: Accuracy = 0.4976\n",
            "Validation batch 218: Accuracy = 0.4971\n",
            "Validation batch 219: Accuracy = 0.4966\n",
            "Validation batch 220: Accuracy = 0.4960\n",
            "Validation batch 221: Accuracy = 0.4956\n",
            "Validation batch 222: Accuracy = 0.4952\n",
            "Validation batch 223: Accuracy = 0.4947\n",
            "Validation batch 224: Accuracy = 0.4951\n",
            "Validation batch 225: Accuracy = 0.4954\n",
            "Validation batch 226: Accuracy = 0.4952\n",
            "Validation batch 227: Accuracy = 0.4952\n",
            "Validation batch 228: Accuracy = 0.4948\n",
            "Validation batch 229: Accuracy = 0.4947\n",
            "Validation batch 230: Accuracy = 0.4938\n",
            "Validation batch 231: Accuracy = 0.4943\n",
            "Validation batch 232: Accuracy = 0.4946\n",
            "Validation batch 233: Accuracy = 0.4942\n",
            "Validation batch 234: Accuracy = 0.4940\n",
            "Validation batch 235: Accuracy = 0.4941\n",
            "Validation batch 236: Accuracy = 0.4944\n",
            "Validation batch 237: Accuracy = 0.4938\n",
            "Validation batch 238: Accuracy = 0.4937\n",
            "Validation batch 239: Accuracy = 0.4936\n",
            "Validation batch 240: Accuracy = 0.4940\n",
            "Validation batch 241: Accuracy = 0.4943\n",
            "Validation batch 242: Accuracy = 0.4946\n",
            "Validation batch 243: Accuracy = 0.4949\n",
            "Validation batch 244: Accuracy = 0.4949\n",
            "Validation batch 245: Accuracy = 0.4953\n",
            "Validation batch 246: Accuracy = 0.4952\n",
            "Validation batch 247: Accuracy = 0.4951\n",
            "Validation batch 248: Accuracy = 0.4955\n",
            "Validation batch 249: Accuracy = 0.4952\n",
            "Validation batch 250: Accuracy = 0.4952\n",
            "Validation batch 251: Accuracy = 0.4955\n",
            "Validation batch 252: Accuracy = 0.4959\n",
            "Validation batch 253: Accuracy = 0.4964\n",
            "Validation batch 254: Accuracy = 0.4956\n",
            "Validation batch 255: Accuracy = 0.4950\n",
            "Validation batch 256: Accuracy = 0.4954\n",
            "Validation batch 257: Accuracy = 0.4955\n",
            "Validation batch 258: Accuracy = 0.4958\n",
            "Validation batch 259: Accuracy = 0.4961\n",
            "Validation batch 260: Accuracy = 0.4969\n",
            "Validation batch 261: Accuracy = 0.4971\n",
            "Validation batch 262: Accuracy = 0.4973\n",
            "Validation batch 263: Accuracy = 0.4969\n",
            "Validation batch 264: Accuracy = 0.4964\n",
            "Validation batch 265: Accuracy = 0.4960\n",
            "Validation batch 266: Accuracy = 0.4966\n",
            "Validation batch 267: Accuracy = 0.4967\n",
            "Validation batch 268: Accuracy = 0.4965\n",
            "Validation batch 269: Accuracy = 0.4970\n",
            "Validation batch 270: Accuracy = 0.4966\n",
            "Validation batch 271: Accuracy = 0.4962\n",
            "Validation batch 272: Accuracy = 0.4960\n",
            "Validation batch 273: Accuracy = 0.4958\n",
            "Validation batch 274: Accuracy = 0.4961\n",
            "Validation batch 275: Accuracy = 0.4959\n",
            "Validation batch 276: Accuracy = 0.4959\n",
            "Validation batch 277: Accuracy = 0.4957\n",
            "Validation batch 278: Accuracy = 0.4957\n",
            "Validation batch 279: Accuracy = 0.4953\n",
            "Validation batch 280: Accuracy = 0.4959\n",
            "Validation batch 281: Accuracy = 0.4959\n",
            "Validation batch 282: Accuracy = 0.4960\n",
            "Validation batch 283: Accuracy = 0.4965\n",
            "Validation batch 284: Accuracy = 0.4966\n",
            "Validation batch 285: Accuracy = 0.4964\n",
            "Validation batch 286: Accuracy = 0.4964\n",
            "Validation batch 287: Accuracy = 0.4960\n",
            "Validation batch 288: Accuracy = 0.4962\n",
            "Validation batch 289: Accuracy = 0.4962\n",
            "Validation batch 290: Accuracy = 0.4961\n",
            "Validation batch 291: Accuracy = 0.4962\n",
            "Validation batch 292: Accuracy = 0.4966\n",
            "Validation batch 293: Accuracy = 0.4967\n",
            "Validation batch 294: Accuracy = 0.4965\n",
            "Validation batch 295: Accuracy = 0.4963\n",
            "Validation batch 296: Accuracy = 0.4965\n",
            "Validation batch 297: Accuracy = 0.4962\n",
            "Validation batch 298: Accuracy = 0.4962\n",
            "Validation batch 299: Accuracy = 0.4969\n",
            "Validation batch 300: Accuracy = 0.4973\n",
            "Validation batch 301: Accuracy = 0.4970\n",
            "Validation batch 302: Accuracy = 0.4971\n",
            "Validation batch 303: Accuracy = 0.4972\n",
            "Validation batch 304: Accuracy = 0.4972\n",
            "Validation batch 305: Accuracy = 0.4977\n",
            "Validation batch 306: Accuracy = 0.4980\n",
            "Validation batch 307: Accuracy = 0.4978\n",
            "Validation batch 308: Accuracy = 0.4978\n",
            "Validation batch 309: Accuracy = 0.4976\n",
            "Validation batch 310: Accuracy = 0.4975\n",
            "Validation batch 311: Accuracy = 0.4975\n",
            "Validation batch 312: Accuracy = 0.4976\n",
            "Validation batch 313: Accuracy = 0.4981\n",
            "Validation batch 314: Accuracy = 0.4982\n",
            "Validation batch 315: Accuracy = 0.4986\n",
            "Validation batch 316: Accuracy = 0.4987\n",
            "Validation batch 317: Accuracy = 0.4991\n",
            "Validation batch 318: Accuracy = 0.4988\n",
            "Validation batch 319: Accuracy = 0.4987\n",
            "Validation batch 320: Accuracy = 0.4984\n",
            "Validation batch 321: Accuracy = 0.4984\n",
            "Validation batch 322: Accuracy = 0.4986\n",
            "Validation batch 323: Accuracy = 0.4983\n",
            "Validation batch 324: Accuracy = 0.4982\n",
            "Validation batch 325: Accuracy = 0.4987\n",
            "Validation batch 326: Accuracy = 0.4988\n",
            "Validation batch 327: Accuracy = 0.4992\n",
            "Validation batch 328: Accuracy = 0.4993\n",
            "Validation batch 329: Accuracy = 0.4994\n",
            "Validation batch 330: Accuracy = 0.4997\n",
            "Validation batch 331: Accuracy = 0.4991\n",
            "Validation batch 332: Accuracy = 0.4990\n",
            "Validation batch 333: Accuracy = 0.4992\n",
            "Validation batch 334: Accuracy = 0.4995\n",
            "Validation batch 335: Accuracy = 0.4995\n",
            "Validation batch 336: Accuracy = 0.4994\n",
            "Validation batch 337: Accuracy = 0.4995\n",
            "Validation batch 338: Accuracy = 0.4997\n",
            "Validation batch 339: Accuracy = 0.4994\n",
            "Validation batch 340: Accuracy = 0.4991\n",
            "Validation batch 341: Accuracy = 0.4991\n",
            "Validation batch 342: Accuracy = 0.4987\n",
            "Validation batch 343: Accuracy = 0.4981\n",
            "Validation batch 344: Accuracy = 0.4983\n",
            "Validation batch 345: Accuracy = 0.4984\n",
            "Validation batch 346: Accuracy = 0.4984\n",
            "Validation batch 347: Accuracy = 0.4985\n",
            "Validation batch 348: Accuracy = 0.4989\n",
            "Validation batch 349: Accuracy = 0.4993\n",
            "Validation batch 350: Accuracy = 0.4991\n",
            "Validation batch 351: Accuracy = 0.4991\n",
            "Validation batch 352: Accuracy = 0.4993\n",
            "Validation batch 353: Accuracy = 0.4994\n",
            "Validation batch 354: Accuracy = 0.4997\n",
            "Validation batch 355: Accuracy = 0.4994\n",
            "Validation batch 356: Accuracy = 0.4991\n",
            "Validation batch 357: Accuracy = 0.4987\n",
            "Validation batch 358: Accuracy = 0.4986\n",
            "Validation batch 359: Accuracy = 0.4991\n",
            "Validation batch 360: Accuracy = 0.4994\n",
            "Validation batch 361: Accuracy = 0.4994\n",
            "Validation batch 362: Accuracy = 0.4997\n",
            "Validation batch 363: Accuracy = 0.4999\n",
            "Validation batch 364: Accuracy = 0.4999\n",
            "Validation batch 365: Accuracy = 0.5000\n",
            "Validation batch 366: Accuracy = 0.4997\n",
            "Validation batch 367: Accuracy = 0.4997\n",
            "Validation batch 368: Accuracy = 0.5000\n",
            "Validation batch 369: Accuracy = 0.4997\n",
            "Validation batch 370: Accuracy = 0.4996\n",
            "Validation batch 371: Accuracy = 0.4997\n",
            "Validation batch 372: Accuracy = 0.4999\n",
            "Validation batch 373: Accuracy = 0.5002\n",
            "Validation batch 374: Accuracy = 0.5001\n",
            "Validation batch 375: Accuracy = 0.5002\n",
            "Validation batch 376: Accuracy = 0.5003\n",
            "Validation batch 377: Accuracy = 0.5006\n",
            "Validation batch 378: Accuracy = 0.5001\n",
            "Validation batch 379: Accuracy = 0.4998\n",
            "Validation batch 380: Accuracy = 0.4998\n",
            "Validation batch 381: Accuracy = 0.5003\n",
            "Validation batch 382: Accuracy = 0.5001\n",
            "Validation batch 383: Accuracy = 0.5004\n",
            "Validation batch 384: Accuracy = 0.5006\n",
            "Validation batch 385: Accuracy = 0.5010\n",
            "Validation batch 386: Accuracy = 0.5013\n",
            "Validation batch 387: Accuracy = 0.5015\n",
            "Validation batch 388: Accuracy = 0.5016\n",
            "Validation batch 389: Accuracy = 0.5018\n",
            "Validation batch 390: Accuracy = 0.5022\n",
            "Validation batch 391: Accuracy = 0.5023\n",
            "Validation batch 392: Accuracy = 0.5025\n",
            "Validation batch 393: Accuracy = 0.5026\n",
            "Validation batch 394: Accuracy = 0.5025\n",
            "Validation batch 395: Accuracy = 0.5022\n",
            "Validation batch 396: Accuracy = 0.5023\n",
            "Validation batch 397: Accuracy = 0.5022\n",
            "Validation batch 398: Accuracy = 0.5021\n",
            "Validation batch 399: Accuracy = 0.5024\n",
            "Validation batch 400: Accuracy = 0.5023\n",
            "Validation batch 401: Accuracy = 0.5023\n",
            "Validation batch 402: Accuracy = 0.5025\n",
            "Validation batch 403: Accuracy = 0.5027\n",
            "Validation batch 404: Accuracy = 0.5029\n",
            "Validation batch 405: Accuracy = 0.5025\n",
            "Validation batch 406: Accuracy = 0.5024\n",
            "Validation batch 407: Accuracy = 0.5023\n",
            "Validation batch 408: Accuracy = 0.5025\n",
            "Validation batch 409: Accuracy = 0.5026\n",
            "Validation batch 410: Accuracy = 0.5030\n",
            "Validation batch 411: Accuracy = 0.5033\n",
            "Validation batch 412: Accuracy = 0.5031\n",
            "Validation batch 413: Accuracy = 0.5026\n",
            "Validation batch 414: Accuracy = 0.5028\n",
            "Validation batch 415: Accuracy = 0.5032\n",
            "Validation batch 416: Accuracy = 0.5032\n",
            "Validation batch 417: Accuracy = 0.5031\n",
            "Validation batch 418: Accuracy = 0.5028\n",
            "Validation batch 419: Accuracy = 0.5029\n",
            "Validation batch 420: Accuracy = 0.5029\n",
            "Validation batch 421: Accuracy = 0.5027\n",
            "Validation batch 422: Accuracy = 0.5030\n",
            "Validation batch 423: Accuracy = 0.5035\n",
            "Validation batch 424: Accuracy = 0.5036\n",
            "Validation batch 425: Accuracy = 0.5035\n",
            "Validation batch 426: Accuracy = 0.5035\n",
            "Validation batch 427: Accuracy = 0.5037\n",
            "Validation batch 428: Accuracy = 0.5039\n",
            "Validation batch 429: Accuracy = 0.5039\n",
            "Validation batch 430: Accuracy = 0.5039\n",
            "Validation batch 431: Accuracy = 0.5036\n",
            "Validation batch 432: Accuracy = 0.5036\n",
            "Validation batch 433: Accuracy = 0.5032\n",
            "Validation batch 434: Accuracy = 0.5033\n",
            "Validation batch 435: Accuracy = 0.5034\n",
            "Validation batch 436: Accuracy = 0.5034\n",
            "Validation batch 437: Accuracy = 0.5034\n",
            "Validation batch 438: Accuracy = 0.5036\n",
            "Validation batch 439: Accuracy = 0.5039\n",
            "Validation batch 440: Accuracy = 0.5038\n",
            "Validation batch 441: Accuracy = 0.5042\n",
            "Validation batch 442: Accuracy = 0.5041\n",
            "Validation batch 443: Accuracy = 0.5039\n",
            "Validation batch 444: Accuracy = 0.5041\n",
            "Validation batch 445: Accuracy = 0.5038\n",
            "Validation batch 446: Accuracy = 0.5039\n",
            "Validation batch 447: Accuracy = 0.5041\n",
            "Validation batch 448: Accuracy = 0.5040\n",
            "Validation batch 449: Accuracy = 0.5039\n",
            "Validation batch 450: Accuracy = 0.5037\n",
            "Validation batch 451: Accuracy = 0.5040\n",
            "Validation batch 452: Accuracy = 0.5038\n",
            "Validation batch 453: Accuracy = 0.5036\n",
            "Validation batch 454: Accuracy = 0.5036\n",
            "Validation batch 455: Accuracy = 0.5037\n",
            "Validation batch 456: Accuracy = 0.5036\n",
            "Validation batch 457: Accuracy = 0.5034\n",
            "Validation batch 458: Accuracy = 0.5035\n",
            "Validation batch 459: Accuracy = 0.5035\n",
            "Validation batch 460: Accuracy = 0.5033\n",
            "Validation batch 461: Accuracy = 0.5033\n",
            "Validation batch 462: Accuracy = 0.5029\n",
            "Validation batch 463: Accuracy = 0.5031\n",
            "Validation batch 464: Accuracy = 0.5031\n",
            "Validation batch 465: Accuracy = 0.5031\n",
            "Validation batch 466: Accuracy = 0.5030\n",
            "Validation batch 467: Accuracy = 0.5034\n",
            "Validation batch 468: Accuracy = 0.5035\n",
            "Validation batch 469: Accuracy = 0.5037\n",
            "Validation batch 470: Accuracy = 0.5035\n",
            "Validation batch 471: Accuracy = 0.5034\n",
            "Validation batch 472: Accuracy = 0.5034\n",
            "Validation batch 473: Accuracy = 0.5032\n",
            "Validation batch 474: Accuracy = 0.5031\n",
            "Validation batch 475: Accuracy = 0.5029\n",
            "Validation batch 476: Accuracy = 0.5027\n",
            "Validation batch 477: Accuracy = 0.5025\n",
            "Validation batch 478: Accuracy = 0.5024\n",
            "Validation batch 479: Accuracy = 0.5023\n",
            "Validation batch 480: Accuracy = 0.5024\n",
            "Validation batch 481: Accuracy = 0.5025\n",
            "Validation batch 482: Accuracy = 0.5029\n",
            "Validation batch 483: Accuracy = 0.5028\n",
            "Validation batch 484: Accuracy = 0.5029\n",
            "Validation batch 485: Accuracy = 0.5028\n",
            "Validation batch 486: Accuracy = 0.5026\n",
            "Validation batch 487: Accuracy = 0.5027\n",
            "Validation batch 488: Accuracy = 0.5024\n",
            "Validation batch 489: Accuracy = 0.5024\n",
            "Validation batch 490: Accuracy = 0.5023\n",
            "Validation batch 491: Accuracy = 0.5020\n",
            "Validation batch 492: Accuracy = 0.5020\n",
            "Validation batch 493: Accuracy = 0.5021\n",
            "Validation batch 494: Accuracy = 0.5020\n",
            "Validation batch 495: Accuracy = 0.5020\n",
            "Validation batch 496: Accuracy = 0.5020\n",
            "Validation batch 497: Accuracy = 0.5019\n",
            "Validation batch 498: Accuracy = 0.5023\n",
            "Validation batch 499: Accuracy = 0.5021\n",
            "Validation batch 500: Accuracy = 0.5024\n",
            "Validation batch 501: Accuracy = 0.5025\n",
            "Validation batch 502: Accuracy = 0.5026\n",
            "Validation batch 503: Accuracy = 0.5027\n",
            "Validation batch 504: Accuracy = 0.5026\n",
            "Validation batch 505: Accuracy = 0.5024\n",
            "Validation batch 506: Accuracy = 0.5023\n",
            "Validation batch 507: Accuracy = 0.5022\n",
            "Validation batch 508: Accuracy = 0.5023\n",
            "Validation batch 509: Accuracy = 0.5023\n",
            "Validation batch 510: Accuracy = 0.5021\n",
            "Validation batch 511: Accuracy = 0.5022\n",
            "Validation batch 512: Accuracy = 0.5022\n",
            "Validation batch 513: Accuracy = 0.5022\n",
            "Validation batch 514: Accuracy = 0.5019\n",
            "Validation batch 515: Accuracy = 0.5019\n",
            "Validation batch 516: Accuracy = 0.5019\n",
            "Validation batch 517: Accuracy = 0.5019\n",
            "Validation batch 518: Accuracy = 0.5019\n",
            "Validation batch 519: Accuracy = 0.5019\n",
            "Validation batch 520: Accuracy = 0.5020\n",
            "Validation batch 521: Accuracy = 0.5017\n",
            "Validation batch 522: Accuracy = 0.5019\n",
            "Validation batch 523: Accuracy = 0.5017\n",
            "Validation batch 524: Accuracy = 0.5018\n",
            "Validation batch 525: Accuracy = 0.5015\n",
            "Validation batch 526: Accuracy = 0.5014\n",
            "Validation batch 527: Accuracy = 0.5012\n",
            "Validation batch 528: Accuracy = 0.5014\n",
            "Validation batch 529: Accuracy = 0.5012\n",
            "Validation batch 530: Accuracy = 0.5009\n",
            "Validation batch 531: Accuracy = 0.5008\n",
            "Validation batch 532: Accuracy = 0.5009\n",
            "Validation batch 533: Accuracy = 0.5010\n",
            "Validation batch 534: Accuracy = 0.5010\n",
            "Validation batch 535: Accuracy = 0.5011\n",
            "Validation batch 536: Accuracy = 0.5009\n",
            "Validation batch 537: Accuracy = 0.5012\n",
            "Validation batch 538: Accuracy = 0.5012\n",
            "Validation batch 539: Accuracy = 0.5011\n",
            "Validation batch 540: Accuracy = 0.5009\n",
            "Validation batch 541: Accuracy = 0.5010\n",
            "Validation batch 542: Accuracy = 0.5012\n",
            "Validation batch 543: Accuracy = 0.5012\n",
            "Validation batch 544: Accuracy = 0.5009\n",
            "Validation batch 545: Accuracy = 0.5010\n",
            "Validation batch 546: Accuracy = 0.5013\n",
            "Validation batch 547: Accuracy = 0.5013\n",
            "Validation batch 548: Accuracy = 0.5015\n",
            "Validation batch 549: Accuracy = 0.5012\n",
            "Validation batch 550: Accuracy = 0.5009\n",
            "Validation batch 551: Accuracy = 0.5010\n",
            "Validation batch 552: Accuracy = 0.5010\n",
            "Validation batch 553: Accuracy = 0.5012\n",
            "Validation batch 554: Accuracy = 0.5011\n",
            "Validation batch 555: Accuracy = 0.5011\n",
            "Validation batch 556: Accuracy = 0.5008\n",
            "Validation batch 557: Accuracy = 0.5011\n",
            "Validation batch 558: Accuracy = 0.5011\n",
            "Validation batch 559: Accuracy = 0.5011\n",
            "Validation batch 560: Accuracy = 0.5012\n",
            "Validation batch 561: Accuracy = 0.5009\n",
            "Validation batch 562: Accuracy = 0.5011\n",
            "Validation batch 563: Accuracy = 0.5011\n",
            "Validation batch 564: Accuracy = 0.5011\n",
            "Validation batch 565: Accuracy = 0.5012\n",
            "Validation batch 566: Accuracy = 0.5014\n",
            "Validation batch 567: Accuracy = 0.5014\n",
            "Validation batch 568: Accuracy = 0.5014\n",
            "Validation batch 569: Accuracy = 0.5015\n",
            "Validation batch 570: Accuracy = 0.5015\n",
            "Validation batch 571: Accuracy = 0.5016\n",
            "Validation batch 572: Accuracy = 0.5017\n",
            "Validation batch 573: Accuracy = 0.5020\n",
            "Validation batch 574: Accuracy = 0.5018\n",
            "Validation batch 575: Accuracy = 0.5017\n",
            "Validation batch 576: Accuracy = 0.5017\n",
            "Validation batch 577: Accuracy = 0.5016\n",
            "Validation batch 578: Accuracy = 0.5015\n",
            "Validation batch 579: Accuracy = 0.5013\n",
            "Validation batch 580: Accuracy = 0.5012\n",
            "Validation batch 581: Accuracy = 0.5013\n",
            "Validation batch 582: Accuracy = 0.5013\n",
            "Validation batch 583: Accuracy = 0.5013\n",
            "Validation batch 584: Accuracy = 0.5012\n",
            "Validation batch 585: Accuracy = 0.5012\n",
            "Validation batch 586: Accuracy = 0.5010\n",
            "Validation batch 587: Accuracy = 0.5006\n",
            "Validation batch 588: Accuracy = 0.5005\n",
            "Validation batch 589: Accuracy = 0.5004\n",
            "Validation batch 590: Accuracy = 0.5003\n",
            "Validation batch 591: Accuracy = 0.5003\n",
            "Validation batch 592: Accuracy = 0.5006\n",
            "Validation batch 593: Accuracy = 0.5005\n",
            "Validation batch 594: Accuracy = 0.5004\n",
            "Validation batch 595: Accuracy = 0.5005\n",
            "Validation batch 596: Accuracy = 0.5004\n",
            "Validation batch 597: Accuracy = 0.5006\n",
            "Validation batch 598: Accuracy = 0.5005\n",
            "Validation batch 599: Accuracy = 0.5003\n",
            "Validation batch 600: Accuracy = 0.5003\n",
            "Validation batch 601: Accuracy = 0.5004\n",
            "Validation batch 602: Accuracy = 0.5003\n",
            "Validation batch 603: Accuracy = 0.5003\n",
            "Validation batch 604: Accuracy = 0.5005\n",
            "Validation batch 605: Accuracy = 0.5006\n",
            "Validation batch 606: Accuracy = 0.5007\n",
            "Validation batch 607: Accuracy = 0.5007\n",
            "Validation batch 608: Accuracy = 0.5007\n",
            "Validation batch 609: Accuracy = 0.5005\n",
            "Validation batch 610: Accuracy = 0.5004\n",
            "Validation batch 611: Accuracy = 0.5003\n",
            "Validation batch 612: Accuracy = 0.5003\n",
            "Validation batch 613: Accuracy = 0.5001\n",
            "Validation batch 614: Accuracy = 0.5001\n",
            "Validation batch 615: Accuracy = 0.4999\n",
            "Validation batch 616: Accuracy = 0.4999\n",
            "Validation batch 617: Accuracy = 0.4997\n",
            "Validation batch 618: Accuracy = 0.4997\n",
            "Validation batch 619: Accuracy = 0.4998\n",
            "Validation batch 620: Accuracy = 0.4998\n",
            "Validation batch 621: Accuracy = 0.4999\n",
            "Validation batch 622: Accuracy = 0.4999\n",
            "Validation batch 623: Accuracy = 0.5000\n",
            "Validation batch 624: Accuracy = 0.5001\n",
            "Validation batch 625: Accuracy = 0.5000\n",
            "100/100 - 1191s - loss: 8.5781e-32 - accuracy: 1.0000 - val_loss: 130.7415 - val_accuracy: 0.5000 - 1191s/epoch - 12s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "\n",
        "checkpoint = ModelCheckpoint('/content/drive/MyDrive/Image/Model_checkpoint1.h5', save_best_only=False, save_weights_only=True, overwrite=True)\n"
      ],
      "metadata": {
        "id": "-BA8s8pfmDqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnDBxQPqmewS",
        "outputId": "96da3acb-e5af-4ddd-c2ed-ea2dace94576"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Model.fit of <keras.src.engine.sequential.Sequential object at 0x7a33380edae0>>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Assuming your model is defined as 'model'\n",
        "model.save_weights(\"/content/drive/MyDrive/Image/model_weights.h5\")  # Replace with your desired path\n"
      ],
      "metadata": {
        "id": "QhojHOPHmivH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQf_UwP8vWQM",
        "outputId": "ab4635f2-d52e-4a26-e1f9-33018dcd542f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 111, 111, 32)      0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 109, 109, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 54, 54, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 186624)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                11944000  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11963457 (45.64 MB)\n",
            "Trainable params: 11963457 (45.64 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# Create the model architecture\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),  # Assuming input shape is (224, 224, 3)\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Load the weights from the .h5 file\n",
        "model.load_weights(\"/content/drive/MyDrive/Image/model_final_weights.h5\")\n",
        "\n",
        "# The model is now ready to use for predictions or other tasks"
      ],
      "metadata": {
        "id": "Vkc0zG19xqzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess_input = tf.keras.preprocessing.image.ImageDataGenerator"
      ],
      "metadata": {
        "id": "xwHTyzXd9-H_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gwJzW6VczEPK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}